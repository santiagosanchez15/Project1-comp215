{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJPNI2U0nJUNbgo1XRFkF4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagosanchez15/Project1-comp215/blob/main/Comp_215_prject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 comp 215\n",
        "\n",
        "**Author:** Santiago Sanchez Covarrubias\n",
        "\n",
        "**resources**: *Think python, Claude.ai*\n",
        "  - https://allendowney.github.io/ThinkPython/. Think python URL\n",
        "\n",
        "\n",
        "**Objectives**\n",
        "- The creation of a SLM capable of to predict the third word\n",
        "\n",
        "**Project description**\n",
        "\n",
        "The project will develop a SLM capable of predicting the third word.\n",
        "\n",
        "This project will be focus not only on developing the SLM but also on documenting the process.\n",
        "Starting by adding different sections, that at the end of different sections will join all the pieces together.\n",
        "\n",
        "After the SLM has been built with feeded data, the final SLM will be created by inhereting everything from the first one, the difference is tyhat this final version will not only take the feeded data through files but aslo through the Wikimedia REST API, the perfect source for thousand of wirtten texts.\n",
        "\n",
        "At the end of all the documentation the full code will be available.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4B-5Ynb7MuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from collections import Counter"
      ],
      "metadata": {
        "id": "XJQVWReTwtlr"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsed and clean function\n",
        "\n",
        "  - get_text:\n",
        "    - will get the text from the file\n",
        "\n",
        "  - clean_text\n",
        "    - will iterate through all the text, check if there are punctuations signs, remove and create a new list of words\n",
        "\n",
        "  - bigrams -> words\n",
        "    - check the anount aof times a word repeats after an specific word, then added to dictionary\n",
        "      \"Hello how are you\"\n",
        "      1 - (Hello how)\n",
        "      2- (how are)\n",
        "      3- (are you)\n",
        "      amount of times the second word will come after the first one\n",
        "      {\"Hello\", {\"how\": 2, \"this\": 4}} etc.\n",
        "\n",
        "\n",
        "  - trigrams -> 3 words\n",
        "    - same like bigrams but instead teh combination of 3 words\n",
        "      next two words plus the word checking such as\n",
        "      \"The castle is big and made of stone\"\n",
        "      1 - (the castle is)\n",
        "      2- (castle is big)\n",
        "      3- (is big and)\n",
        "      aount of times the next two words will come after the first one\n",
        "      {'The': {\"castle is\", 3}\n",
        "      {\"The': {\"red carpet\", 2}\n",
        "      etc, next two words following the first one there fore key can be tuple"
      ],
      "metadata": {
        "id": "_Ic4JweXDpLz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "jDhAz7987LpL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text_from_file(file_name: str) -> list:\n",
        "  '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "  with open(file_name, 'r') as text: #open file given\n",
        "    cleaned_word = [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)] #iterate through each word and strip to get clean word\n",
        "\n",
        "  return cleaned_word\n",
        "\n",
        "assert clean_text_from_file('sample.txt')[:2] == ['hello', 'world']\n",
        "assert clean_text_from_file('sample.txt')[-1] == 'wonderful'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(string: str) -> list:\n",
        "  '''Returns list of word cleaned '''\n",
        "\n",
        "  new_string = string.split().strip(string.punctuation).lower()"
      ],
      "metadata": {
        "id": "Tb73VLIR01mV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get bigram\n",
        "get the bigram from the given list return bigram"
      ],
      "metadata": {
        "id": "fVzHTxGC5r39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigrams(list_word: list) -> list:\n",
        "  '''Returns a list of tuple of bigrams from a given list '''\n",
        "\n",
        "  return list(zip(list_word[:-1], list_word[1:]))"
      ],
      "metadata": {
        "id": "K-WZBz0BtBzJ"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_word = ['hello', 'how', 'are', 'you', 'my', 'friend']\n",
        "#expected output = (hello, how), (how, are)\n",
        "for item in get_bigrams(list_word):\n",
        "  print(item)\n",
        "\n",
        "#Testing with previous function\n",
        "assert get_bigrams(clean_text_from_file('sample.txt'))[:2] == [('hello', 'world'), ('world', 'how')]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_8gUkj1-m0b",
        "outputId": "f7f025a4-bb06-48a0-ea30-7487dd28f175"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('hello', 'how')\n",
            "('how', 'are')\n",
            "('are', 'you')\n",
            "('you', 'my')\n",
            "('my', 'friend')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge_dictionaries\n",
        "\n",
        "function that will take two dictionaries and merge the two of them adding the elements and counting the bigrams"
      ],
      "metadata": {
        "id": "cOskLr1qoZhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "  '''Returns dictionary with updated values '''\n",
        "\n",
        "  counter1, counter2 = 0,0\n",
        "\n",
        "  all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "  result = {}\n",
        "\n",
        "  for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "    counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "    counter2 = Counter(new_dict.get(key, {}))\n",
        "    result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "PYODKO_mojSR"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {\"hello\": {\"this\": 1, \"how\": 2}, \"apple\": {\"a\": 1, \"are\": 2}}\n",
        "dict2 = {\"hello\": {\"how\": 3}, \"pear\": {\"yummy\": 1}}\n",
        "new_dict = merge_dictionaries(dict1, dict2)\n",
        "print(new_dict)"
      ],
      "metadata": {
        "id": "01oTqBwmpOmN",
        "outputId": "96e97185-ea48-46f4-c6af-5710dc490895",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'apple': {'a': 1, 'are': 2}, 'hello': {'this': 1, 'how': 5}, 'pear': {'yummy': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word_frequency\n",
        "this function will take a dictionary and a given list of bigrams to update the dictionary given with the values corresponding to the frequency of the words appearance"
      ],
      "metadata": {
        "id": "oYjUE6SpYJTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency(bigrams:list) -> dict:\n",
        "  '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "  new_dict = {}\n",
        "  for key, value in bigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "    if key not in new_dict: new_dict[key] = {} #create a new key if the key doenst exist\n",
        "    if value not in new_dict[key]: new_dict[key][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "    else: new_dict[key][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "  return new_dict\n",
        "#try function\n",
        "\n"
      ],
      "metadata": {
        "id": "wCNE24uFZUQ-"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try function above\n",
        "\n",
        "bigrams1  = get_bigrams(clean_text_from_file('sample.txt'))\n",
        "new_dict = word_frequency(get_bigrams(clean_text_from_file('sample.txt')))\n",
        "print(new_dict)"
      ],
      "metadata": {
        "id": "0k1ioSL7lzKM",
        "outputId": "7fb16950-8130-4f01-bf91-ba32196a9a2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'hello': {'world': 1}, 'world': {'how': 1}, 'how': {'are': 1}, 'are': {'you': 1}, 'you': {'today': 1}, 'today': {\"i'm\": 1}, \"i'm\": {'doing': 1}, 'doing': {'great': 1}, 'great': {\"let's\": 1}, \"let's\": {'explore': 1}, 'explore': {'coding': 1}, 'coding': {'writing': 1}, 'writing': {\"creativity—it's\": 1}, \"creativity—it's\": {'wonderful': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word_frequency_from_file\n",
        "\n",
        "Lets join all the functions together into a single function\n",
        "it will take a file name as a paramter and return the dictionary that will be used to feed the model"
      ],
      "metadata": {
        "id": "C_tTtTWftG2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency_from_file(file_name: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "  text = clean_text_from_file(file_name) #get the clean text as a list\n",
        "  bigrams = get_bigrams(text) #get bigrams form the zip function\n",
        "  frequency = word_frequency(bigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary\n"
      ],
      "metadata": {
        "id": "NinGAW10tgBG"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test function\n",
        "new_dict = {}\n",
        "list_files = ['text1.txt', 'text2.txt']\n",
        "for file in list_files:\n",
        "  new_dict = word_frequency_from_file(file, new_dict)\n",
        "\n",
        "print(new_dict)"
      ],
      "metadata": {
        "id": "vZAbH4Q9uqkn",
        "outputId": "638e92df-a347-48d5-e2fb-a583ce8d62bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': {'is': 1}, 'friend': {'is': 1}, 'hello': {'my': 2}, 'my': {'name': 1, 'friend': 1}, 'is': {'santigo': 1, 'you': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word_frequency_from text\n",
        "Ofcourse at this point of the project we can get the word frequency from file, bu twhat if we just want to copy and paste. well that is easy"
      ],
      "metadata": {
        "id": "3JIOmJkWy2_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freqeuncy_from_text(string: str, old_dict: dict) -> str:\n",
        "  '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "  new_list = text.\n",
        "  bigrams = get_bigrams(string) #get bigrams form the zip function\n",
        "  frequency = word_frequency(bigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary"
      ],
      "metadata": {
        "id": "3VB58C0dzaSZ",
        "outputId": "b17e14ce-010a-4b6c-b2c1-5d112b775ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-3555548006.py, line 4)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-3555548006.py\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    new_list = text.\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['hello my friend is you', 'hello my name is santigo']\n",
        "dict1 = {}\n",
        "for string in list1:\n",
        "  dict1 = word_freqeuncy_from_text(string, dict1)\n",
        "\n",
        "dict1"
      ],
      "metadata": {
        "id": "BexleW3Xz4Nw",
        "outputId": "11f2d423-bfcf-4aef-e2ed-bd150da78b80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'l': {'l': 2, 'o': 2},\n",
              " ' ': {'m': 2, 'f': 1, 'i': 2, 'y': 1, 'n': 1, 's': 1},\n",
              " 'r': {'i': 1},\n",
              " 's': {' ': 2, 'a': 1},\n",
              " 'y': {' ': 2, 'o': 1},\n",
              " 'd': {' ': 1},\n",
              " 't': {'i': 1},\n",
              " 'e': {'l': 2, 'n': 1, ' ': 1},\n",
              " 'o': {' ': 2, 'u': 1},\n",
              " 'f': {'r': 1},\n",
              " 'h': {'e': 2},\n",
              " 'm': {'y': 2, 'e': 1},\n",
              " 'i': {'e': 1, 's': 2, 'g': 1},\n",
              " 'a': {'m': 1, 'n': 1},\n",
              " 'g': {'o': 1},\n",
              " 'n': {'d': 1, 'a': 1, 't': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    }
  ]
}