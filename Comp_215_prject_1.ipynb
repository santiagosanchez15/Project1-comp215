{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNIal+t5SkpcI2FWZbr6jmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagosanchez15/Project1-comp215/blob/main/Comp_215_prject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 comp 215\n",
        "\n",
        "**Author:** Santiago Sanchez Covarrubias\n",
        "\n",
        "**resources**: *Think python, Claude.ai*\n",
        "  - https://allendowney.github.io/ThinkPython/. Think python URL\n",
        "\n",
        "\n",
        "**Objectives**\n",
        "- The creation of a SLM capable of to predict the third word\n",
        "\n",
        "**Project description**\n",
        "\n",
        "The project will develop a SLM capable of predicting the third word.\n",
        "\n",
        "This project will be focus not only on developing the SLM but also on documenting the process.\n",
        "Starting by adding different sections, that at the end of different sections will join all the pieces together.\n",
        "\n",
        "After the SLM has been built with feeded data, the final SLM will be created by inhereting everything from the first one, the difference is tyhat this final version will not only take the feeded data through files but aslo through the Wikimedia REST API, the perfect source for thousand of wirtten texts.\n",
        "\n",
        "At the end of all the documentation the full code will be available.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4B-5Ynb7MuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string #used for punctuation signs\n",
        "from collections import Counter #used to merge and join two dictionaries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XJQVWReTwtlr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsed and clean function\n",
        "\n",
        "  - get_text:\n",
        "    - will get the text from the file\n",
        "\n",
        "  - clean_text\n",
        "    - will iterate through all the text, check if there are punctuations signs, remove and create a new list of words\n",
        "\n",
        "  - bigrams -> words\n",
        "    - check the anount aof times a word repeats after an specific word, then added to dictionary\n",
        "      \"Hello how are you\"\n",
        "      1 - (Hello how)\n",
        "      2- (how are)\n",
        "      3- (are you)\n",
        "      amount of times the second word will come after the first one\n",
        "      {\"Hello\", {\"how\": 2, \"this\": 4}} etc.\n",
        "\n",
        "\n",
        "  - trigrams -> 3 words\n",
        "    - same like bigrams but instead teh combination of 3 words\n",
        "      next two words plus the word checking such as\n",
        "      \"The castle is big and made of stone\"\n",
        "      1 - (the castle is)\n",
        "      2- (castle is big)\n",
        "      3- (is big and)\n",
        "      aount of times the next two words will come after the first one\n",
        "      {'The': {\"castle is\", 3}\n",
        "      {\"The': {\"red carpet\", 2}\n",
        "      etc, next two words following the first one there fore key can be tuple"
      ],
      "metadata": {
        "id": "_Ic4JweXDpLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean text\n",
        "two functions, clean a text from a file and another one to clean the text from a string"
      ],
      "metadata": {
        "id": "J2hEw9E_NIoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "jDhAz7987LpL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text_from_file(file_name: str) -> list:\n",
        "  '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "  with open(file_name, 'r') as text: #open file given\n",
        "    return [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)] #iterate through each word and strip to get clean word\n",
        "\n",
        "assert clean_text_from_file('sample.txt')[:2] == ['hello', 'world']\n",
        "assert clean_text_from_file('sample.txt')[-1] == 'wonderful'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(string_text: str) -> list:\n",
        "  '''Returns list of word cleaned '''\n",
        "  return [word.strip(string.punctuation).lower() for word in string_text.split() if word.strip(string.punctuation)]"
      ],
      "metadata": {
        "id": "Tb73VLIR01mV"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = \"Hello! my? friend is you!!!!!\"\n",
        "print(clean_text(list1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH8aKXuE19RA",
        "outputId": "1b76315a-daf8-475e-8df4-48545f8896e8"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'my', 'friend', 'is', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_bigram\n",
        "get Bigram from given word so for example if input is: hello my name is santiago then the output would be (hello, my), (my, name), (name, is), (is, santiago)"
      ],
      "metadata": {
        "id": "mQNLcVebixVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigram(list_word: list) -> list:\n",
        "  '''Return list of bigrams '''\n",
        "\n",
        "  return list(zip(list_word[:-1], list_word[1:]))"
      ],
      "metadata": {
        "id": "_CNGk9Zti7kb"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "assert get_bigram(['hello', 'my', 'name', 'is', 'santiago']) == [('hello', 'my'), ('my', 'name'), ('name', 'is'), ('is', 'santiago')]"
      ],
      "metadata": {
        "id": "XYyJsdNhjNE8"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_trigram\n",
        "get trigram from given word\n",
        "so for example if input is:\n",
        "hello my name is santiago\n",
        "then the output would be\n",
        "(hello, my, name), (my, name, is), (name, is, santiago)"
      ],
      "metadata": {
        "id": "wwk3vmqIABDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trigrams(list_word: list) -> list:\n",
        "  '''Returns list of trigrams '''\n",
        "\n",
        "  return list(zip(list_word[:-2], list_word[1:-1], list_word[2:]))"
      ],
      "metadata": {
        "id": "V3BYqtMYAVMB"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing unit\n",
        "\n",
        "print(get_trigrams('hello my name is santiago'.split()))\n",
        "assert get_trigrams('hello my name is santiago'.split()) == [('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aSbAYqNArP9",
        "outputId": "58caf0b9-1a08-44b4-b12b-2fe69065e913"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge_dictionaries\n",
        "\n",
        "function that will take two dictionaries and merge the two of them adding the elements and counting the bigrams"
      ],
      "metadata": {
        "id": "cOskLr1qoZhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "  '''Returns dictionary with updated values '''\n",
        "\n",
        "  all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "  result = {}\n",
        "\n",
        "  for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "    counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "    counter2 = Counter(new_dict.get(key, {}))\n",
        "    result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "PYODKO_mojSR"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {(\"hello\", 'how'): {\"are\": 1, \"is\": 2}, (\"apple\", 'is'): {\"a\": 1, \"healthy\": 2}, (\"apples\", \"are\"): {\"my\": 1, \"taste\": 2}}\n",
        "dict2 = {(\"hello\", 'how'): {\"are\": 3}, \"pear\": {\"yummy\": 1}}\n",
        "new_dict = merge_dictionaries(dict1, dict2)\n",
        "print(new_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01oTqBwmpOmN",
        "outputId": "6999abff-784b-4107-af67-96ca39180bc7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pear': {'yummy': 1}, ('apple', 'is'): {'a': 1, 'healthy': 2}, ('apples', 'are'): {'my': 1, 'taste': 2}, ('hello', 'how'): {'are': 4, 'is': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word_frequency\n",
        "this function will take a dictionary and a given list of bigrams to update the dictionary given with the values corresponding to the frequency of the words appearance"
      ],
      "metadata": {
        "id": "oYjUE6SpYJTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency(trigrams:list) -> dict:\n",
        "  '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "  new_dict = {}\n",
        "  for key1, key2, value in trigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "    if (key1, key2) not in new_dict: new_dict[(key1, key2)] = {} #create a new key if the key doenst exist\n",
        "    if value not in new_dict[(key1, key2)]: new_dict[(key1, key2)][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "    else: new_dict[(key1, key2)][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "  return new_dict\n",
        "#try function\n",
        "\n"
      ],
      "metadata": {
        "id": "wCNE24uFZUQ-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try function above\n",
        "tuple_t = ((1,2,3), (4,3,2))\n",
        "print(word_frequency(tuple_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k1ioSL7lzKM",
        "outputId": "841995bb-7690-4a18-ce75-5aa14493ce86"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(1, 2): {3: 1}, (4, 3): {2: 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word_frequency_from_file\n",
        "\n",
        "Lets join all the functions together into a single function\n",
        "it will take a file name as a paramter and return the dictionary that will be used to feed the model"
      ],
      "metadata": {
        "id": "C_tTtTWftG2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency_from_file(file_name: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "  text = clean_text_from_file(file_name) #get the clean text as a list\n",
        "  trigrams = get_trigrams(text) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary\n"
      ],
      "metadata": {
        "id": "NinGAW10tgBG"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test function\n",
        "new_dict = {}\n",
        "list_files = ['text1.txt', 'text2.txt']\n",
        "for file in list_files:\n",
        "  new_dict = word_frequency_from_file(file, new_dict)\n",
        "\n",
        "print(new_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZAbH4Q9uqkn",
        "outputId": "87c0048c-cc15-4e80-dda2-8442e2e1d1a9"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('name', 'is'): {'santigo': 1}, ('hello', 'my'): {'name': 1, 'friend': 1}, ('my', 'name'): {'is': 1}, ('my', 'friend'): {'is': 1}, ('friend', 'is'): {'you': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets test the function with more complex files"
      ],
      "metadata": {
        "id": "zIprjybf57A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test function complex files\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6jmI3i5-LR",
        "outputId": "dd2e1c04-a4f5-40b8-d8d3-b97b53814fa2"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word_frequency_from text\n",
        "Ofcourse at this point of the project we can get the word frequency from file, bu twhat if we just want to copy and paste. well that is easy"
      ],
      "metadata": {
        "id": "3JIOmJkWy2_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freqeuncy_from_text(given_string: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "  new_list = clean_text(given_string)\n",
        "  trigrams = get_trigrams(new_list) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary"
      ],
      "metadata": {
        "id": "3VB58C0dzaSZ"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['The blue car drives fast. The blue truck drives slow. The red car drives carefully, but the red truck drives wildly. My friend likes the blue car. My sister likes the red truck.', 'The cat sat on the mat. The dog sat on the floor. The cat sat on the chair, and the dog sat on the bed. I saw the cat sit down. I saw the dog lie down.']\n",
        "dict1 = {}\n",
        "for text in list1:\n",
        "  dict1 = word_freqeuncy_from_text(text, dict1)\n",
        "dict1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexleW3Xz4Nw",
        "outputId": "a68918a9-e5c1-4185-ce03-3388c700b171"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#what next?\n",
        "since we are able to get the frequency of the word and what comes next, we need to do a couple of more things to....\n",
        "Next fucntions will be:\n",
        "  - list of possible next word -> returns a list of key of the trigram\n",
        "\n",
        "  - get_probability -> get weight word and divide by total weight -> probability\n",
        "\n",
        "  - get_weight_word -> weight / total weight using numpy to assign weight return dicitonary key = word, value = probability\n",
        "\n",
        "  - get_word -> using NumPy pseduo-random numbers, get word based on the different possibilites\n"
      ],
      "metadata": {
        "id": "vu1uLxVdLMlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#List_possible_words\n",
        "\n",
        "returns a list of all the possible word that can be chosen independently from the weight"
      ],
      "metadata": {
        "id": "tqCy-llKQoJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_possible_words(dict_weights: dict, bigram: tuple) -> list:\n",
        "  '''Returns all possible word based on bigram '''\n",
        "\n",
        "  return list(dict_weights[bigram].keys())"
      ],
      "metadata": {
        "id": "eIHOsYwWQ3qY"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict\n",
        "get_all_possible_words(new_dict, ('on', 'the') )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGCYMZUkVilU",
        "outputId": "f42a90db-3a7b-4498-917a-b34719d6067c"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mat', 'floor', 'chair', 'bed']"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_probability function\n",
        "based on the total of weight return the proability of the word occurring\n",
        "for example if total weight = 25 and my word occurece 5 times that 5/25 = 0.2"
      ],
      "metadata": {
        "id": "57fOI9uVYh4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probability(num_appearance: int, total_weight: int) -> int:\n",
        "  '''Returns probability of the word to appear '''\n",
        "  return num_appearance / total_weight"
      ],
      "metadata": {
        "id": "_6zoxrfTZN3_"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test function above\n",
        "assert round(get_probability(5, 140), 5) == 0.03571\n",
        "assert round(get_probability(0, 150), 5) == 0\n",
        "assert round(get_probability(10, 10), 5) == 1\n",
        "assert round(get_probability(20, 154), 5) == 0.12987"
      ],
      "metadata": {
        "id": "lxTSKSN8aNbD"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_total_weight\n",
        "iterate trhough each value to get the toal weight, return int of weight"
      ],
      "metadata": {
        "id": "qF41y-HngG7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_weight(dictionary : dict, key: tuple) -> int:\n",
        "  '''return total weight for given key '''\n",
        "\n",
        "  return sum((value for value in dictionary[key].values()))"
      ],
      "metadata": {
        "id": "19GVi9RWgNcy"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing unit\n",
        "\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_total_weight(dictionary, ('hello', 'how')) == 8\n",
        "assert get_total_weight(dictionary, ('i', 'am')) == 14"
      ],
      "metadata": {
        "id": "z79SZ1VbgwRy"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_weighted_words\n",
        "returns list of probability of the values given, respect to the key"
      ],
      "metadata": {
        "id": "JbhfSNdYd1Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "I304cV-WblFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_words(dictionary: dict, key: tuple) -> list:\n",
        "  '''Returns a list of tuple word, dictionary '''\n",
        "\n",
        "  total_weight = get_total_weight(dictionary, key) #get total sum of the weight\n",
        "\n",
        "  #generator expression to get a list of tuples that will hold the word and the total weight\n",
        "  return list(((word, get_probability(weight, total_weight)) for word, weight in dictionary[key].items() ))"
      ],
      "metadata": {
        "id": "asWj4Aw8fKe5"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing units\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_weighted_words(dictionary, ('hello', 'how')) == [('you', 0.625), ('are', 0.375)]\n",
        "assert get_weighted_words(dictionary, ('i', 'am')) == [('your', 0.35714285714285715), ('santiago', 0.21428571428571427), ('my', 0.42857142857142855 )]"
      ],
      "metadata": {
        "id": "iAItCbN6flG5"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#predict_word\n",
        "form the list given, return the word by given probability"
      ],
      "metadata": {
        "id": "VnG-sdGTmhKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(dictionary: dict, key: tuple) -> str:\n",
        "  '''Returns string for given probability '''\n",
        "\n",
        "  if key not in dictionary: return None #handle case where input is not valid\n",
        "  words, probability = zip(*get_weighted_words(dictionary, key)) # unoack the values with * given each index to each variable\n",
        "  return str(np.random.default_rng().choice(words, p = probability))"
      ],
      "metadata": {
        "id": "3zp7PWf7mrS3"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit test\n",
        "\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "print(predict_word(new_dict, ('on', 'the')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVJAqMNBcGV4",
        "outputId": "a903c0da-def2-4731-83e3-0975b7e3c49c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From input to list\n",
        "get string from input and get trigram, so it can be looked later\n",
        "by the word frequency"
      ],
      "metadata": {
        "id": "tsDIMZsThjxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_to_prediction(dictionary: dict, input: str) -> str:\n",
        "  '''get input and return prediction '''\n",
        "\n",
        "  input_clean = clean_text(input)\n",
        "  if len(input_clean) <= 1: return None #handle case where not enough information is given\n",
        "  bigram = get_bigram(input_clean)[-1] #in case the user gives more than two words only get the last two from the input\n",
        "\n",
        "  return predict_word(dictionary, bigram)\n"
      ],
      "metadata": {
        "id": "ju-SC_QjiXiM"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "print(input_to_prediction(new_dict, ('on the')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd08eLQhlv7I",
        "outputId": "9b0a89c3-cf49-46d3-ad01-1775cc3d5bf0"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now what\n",
        "now that that im able to predict my thrid word, whats next, well, in that case i have first to be able to feed my SLM, since i will be limited to only the words that are saved, lets create a class that will use the functions, and will be easier to use"
      ],
      "metadata": {
        "id": "lkrcEpgngzMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Small_Language_Model\n",
        "\n",
        "Lest join all the previous functions together and create a small language model object"
      ],
      "metadata": {
        "id": "gfl7rcwNhJWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Small_Language_Model:\n",
        "  '''Class to predict the third word of a sentence (last one) '''\n",
        "\n",
        "  def __init__(self, name = 'model'):\n",
        "    '''Initialize attributes of the instance '''\n",
        "\n",
        "    self.name = name\n",
        "    self.dictionary_weight = {}\n",
        "\n",
        "  def __repr__(self):\n",
        "    '''print representation of model '''\n",
        "\n",
        "    return f\"{self.name} is a small languge model that holds {len(self.dictionary_weight.keys())} keys, feed the model more to have better predictions\"\n",
        "\n",
        "  def get_dict(self):\n",
        "    '''returns dictionary of weights '''\n",
        "\n",
        "    return self.dictionary_weight\n",
        "\n",
        "  #Functions to clean and parse the text\n",
        "\n",
        "  @staticmethod\n",
        "  def clean_text_from_file(file_name: str) -> list:\n",
        "    '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "    with open(file_name, 'r') as text: #open file given\n",
        "      #iterate through each word and strip to get clean word\n",
        "      return [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)]\n",
        "\n",
        "  @staticmethod\n",
        "  def clean_text(string_text: str) -> list:\n",
        "    '''Returns list of word cleaned '''\n",
        "\n",
        "    return [word.strip(string.punctuation).lower() for word in string_text.split() if word.strip(string.punctuation)]\n",
        "\n",
        "\n",
        "  #Functions to get trigrams and bigrams\n",
        "\n",
        "  @staticmethod\n",
        "  def get_bigram(list_word: list) -> list:\n",
        "    '''Return list of bigrams '''\n",
        "\n",
        "    return list(zip(list_word[:-1], list_word[1:]))\n",
        "\n",
        "  @staticmethod\n",
        "  def get_trigrams(list_word: list) -> list:\n",
        "    '''Returns list of trigrams '''\n",
        "\n",
        "    return list(zip(list_word[:-2], list_word[1:-1], list_word[2:]))\n",
        "\n",
        "\n",
        "  #function to merge the dictionaries\n",
        "\n",
        "  @staticmethod\n",
        "  def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "    '''Returns dictionary with updated values '''\n",
        "\n",
        "    all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "    result = {}\n",
        "\n",
        "    for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "      counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "      counter2 = Counter(new_dict.get(key, {}))\n",
        "      result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "  #Function to get the word frequency\n",
        "\n",
        "  @staticmethod\n",
        "  def word_frequency(trigrams:list) -> dict:\n",
        "    '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "    new_dict = {}\n",
        "    for key1, key2, value in trigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "      if (key1, key2) not in new_dict: new_dict[(key1, key2)] = {} #create a new key if the key doenst exist\n",
        "      if value not in new_dict[(key1, key2)]: new_dict[(key1, key2)][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "      else: new_dict[(key1, key2)][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "    return new_dict\n",
        "\n",
        "  def word_frequency_from_file(self, file_name: str):\n",
        "    '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "    text = self.clean_text_from_file(file_name) #get the clean text as a list\n",
        "    trigrams = self.get_trigrams(text) #get bigrams form the zip function\n",
        "    frequency = self.word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "    self.dictionary_weight = self.merge_dictionaries(self.dictionary_weight, frequency) #returns the updated dictionary\n",
        "\n",
        "  def word_freqeuncy_from_text(self, given_string: str):\n",
        "    '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "    new_list = self.clean_text(given_string)\n",
        "    trigrams = self.get_trigrams(new_list) #get bigrams form the zip function\n",
        "    frequency = self.word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "    self.dictionary_weight = self.merge_dictionaries(self.dictionary_weight, frequency) #returns the updated dictionary\n",
        "\n",
        "\n",
        "  #Function of possible outcomes\n",
        "\n",
        "\n",
        "  def get_all_possible_words(self, bigram: tuple) -> list:\n",
        "    '''Returns all possible word based on bigram '''\n",
        "\n",
        "    return list(self.dictionary_weight[bigram].keys())\n",
        "\n",
        "\n",
        "  #Probability functions\n",
        "\n",
        "  @staticmethod\n",
        "  def get_probability(num_appearance: int, total_weight: int) -> int:\n",
        "    '''Returns probability of the word to appear '''\n",
        "    return num_appearance / total_weight\n",
        "\n",
        "  def get_total_weight(self, key: tuple) -> int:\n",
        "    '''return total weight for given key '''\n",
        "\n",
        "    return sum((value for value in self.dictionary_weight[key].values()))\n",
        "\n",
        "  def get_weighted_words(self, key: tuple) -> list:\n",
        "    '''Returns a list of tuple word, dictionary '''\n",
        "\n",
        "    total_weight = self.get_total_weight(key) #get total sum of the weight\n",
        "\n",
        "    #generator expression to get a list of tuples that will hold the word and the total weight\n",
        "    return list(((word, self.get_probability(weight, total_weight)) for word, weight in self.dictionary_weight[key].items() ))\n",
        "\n",
        "\n",
        "  #Functions to predict the third word\n",
        "\n",
        "\n",
        "  def input_to_prediction(self, key: tuple) -> str:\n",
        "    '''Returns string for given probability '''\n",
        "\n",
        "    if key not in self.dictionary_weight: return None #handle case where input is not valid\n",
        "    words, probability = zip(*self.get_weighted_words(key)) # unoack the values with * given each index to each variable\n",
        "    return str(np.random.default_rng().choice(words, p = probability))\n",
        "\n",
        "  def predict_word(self, input: str) -> str:\n",
        "    '''get input and return prediction '''\n",
        "\n",
        "    input_clean = self.clean_text(input)\n",
        "    if len(input_clean) <= 1: return None #handle case where not enough information is given\n",
        "    bigram = self.get_bigram(input_clean)[-1] #in case the user gives more than two words only get the last two from the input\n",
        "\n",
        "    return self.input_to_prediction( bigram)\n"
      ],
      "metadata": {
        "id": "stoDPgfzmps0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "chatgpt = Small_Language_Model('Guerra')\n",
        "files = ['feeding_and_evaluating_models.txt', 'neural_network_fundamentals.txt', 'probability_and_statistics.txt', 'text_preprocessing_nlp.txt', 'training_language_models.txt']\n",
        "\n",
        "for _ in files:\n",
        "  chatgpt.word_frequency_from_file(_)\n",
        "\n",
        "print(chatgpt)\n",
        "print(chatgpt.get_dict())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6K4gaVqHQI",
        "outputId": "29cedf14-a06f-495e-f61c-6c78ef232d45"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guerra is a small languge model that holds 4152 keys, feed the model more to have better predictions\n",
            "{('meaning', 'for'): {'example': 1}, ('represents', 'millions'): {'of': 18}, ('network', 'efficiently'): {'encodes': 1, 'learns': 2, 'updates': 1, 'reduces': 1, 'diverges': 1, 'calculates': 1}, ('automatically', 'feeding'): {'diverse': 3}, ('rapidly', 'computes'): {'syntactic': 1, 'the': 3, 'language': 1, 'word': 1}, ('loss', 'efficiently'): {'the': 7, 'word': 1, 'however': 1, 'a': 6, 'specifically': 1, 'for': 1, 'tokenization': 1}, ('corpus', 'captures'): {'millions': 1, 'the': 4, 'word': 1, 'syntactic': 1}, ('function', 'significantly'): {'generates': 1, 'the': 3, 'predicts': 2, 'converges': 1, 'learns': 1, 'a': 1, 'represents': 2, 'samples': 2, 'increases': 1, 'fine-tunes': 1}, ('efficiently', 'a'): {'statistical': 7, 'transformer-based': 6, 'neural': 3, 'recurrent': 7, 'deep': 5, 'fine-tuned': 6, 'pre-trained': 8, 'scalable': 6, 'efficient': 6, 'robust': 7, 'bidirectional': 11, 'autoregressive': 5, 'powerful': 6, 'accurate': 5, 'large': 3, 'lightweight': 1, 'language': 4, 'shallow': 9, 'small': 3, 'generative': 2, 'discriminative': 1}, ('iteratively', 'word'): {'embeddings': 5}, ('perplexity', 'increases'): {'large': 1, 'syntactic': 1, 'language': 1, 'statistical': 2, 'the': 3}, ('dataset', 'models'): {'the': 5, 'statistical': 1, 'large': 1}, ('vocabulary', 'successfully'): {'reduces': 1, 'represents': 1, 'captures': 1}, ('prediction', 'efficiently'): {'maximizes': 1, 'learns': 1, 'generates': 1, 'models': 1, 'represents': 1, 'updates': 1, 'fine-tunes': 1, 'adjusts': 1, 'decodes': 1}, ('parameters', 'word'): {'embeddings': 2}, ('frequencies', 'furthermore'): {'backpropagation': 1, 'the': 3}, ('generates', 'large'): {'amounts': 15}, ('ability', 'meanwhile'): {'the': 2}, ('tokenizer', 'fine-tunes'): {'the': 3, 'contextual': 1, 'linguistic': 2, 'semantic': 1, 'large': 1}, ('generalizes', 'sentence'): {'structure': 14}, ('algorithm', 'tokenizes'): {'the': 9, 'millions': 1, 'semantic': 1, 'word': 1}, ('reduces', 'co-occurrence'): {'matrices': 11}, ('loss', 'as'): {'a': 3}, ('gradient', 'predicts'): {'the': 9, 'large': 1, 'syntactic': 2, 'word': 1, 'statistical': 1}, ('perplexity', 'optimizes'): {'the': 6, 'co-occurrence': 1, 'semantic': 1, 'millions': 1}, ('meaning', 'tokenization'): {'is': 2}, ('perplexity', 'iteratively'): {'trains': 1, 'encodes': 1, 'updates': 1, 'improves': 1, 'evaluates': 1, 'diverges': 1}, ('adjusts', 'contextual'): {'information': 20}, ('text', 'in'): {'contrast': 4, 'addition': 3}, ('layer', 'automatically'): {'decodes': 1, 'trains': 2, 'minimizes': 1}, ('correctly', 'additionally'): {'the': 4}, ('and', 'trigram'): {'models': 104}, ('decodes', 'co-occurrence'): {'matrices': 15}, ('data', 'subsequently'): {'the': 2}, ('loss', 'for'): {'example': 6}, ('mechanism', 'captures'): {'the': 3, 'co-occurrence': 2, 'linguistic': 1, 'contextual': 1, 'language': 1}, ('model', 'predicts'): {'a': 104, 'the': 23, 'token': 3, 'co-occurrence': 2, 'word': 2, 'contextual': 1, 'linguistic': 3, 'language': 1, 'millions': 1, 'large': 1}, ('text', 'rapidly'): {'a': 4, 'the': 6, 'updates': 1, 'additionally': 1, 'feeding': 1, 'evaluates': 1}, ('gradually', 'as'): {'a': 7}, ('prediction', 'as'): {'a': 4}, ('adjusts', 'the'): {'loss': 15, 'bias': 18, 'hidden': 14, 'corpus': 14, 'activation': 8, 'vocabulary': 13, 'cross': 19, 'next': 16, 'batch': 14, 'gradient': 15, 'probability': 17, 'training': 12, 'softmax': 8, 'weight': 9, 'learning': 11}, ('minimizes', 'contextual'): {'information': 5}, ('patterns', 'meanwhile'): {'the': 7, 'backpropagation': 1}, ('algorithm', 'learns'): {'from': 11}, ('errors', 'as'): {'a': 1}, ('frequencies', 'effectively'): {'the': 9, 'a': 1, 'training': 1, 'smoothing': 1, 'specifically': 1, 'consequently': 1}, ('value', 'accurately'): {'the': 6, 'training': 1, 'feeding': 1, 'consequently': 1, 'meanwhile': 1, 'subsequently': 1, 'a': 1}, ('dataset', 'sequentially'): {'decodes': 1, 'optimizes': 1, 'captures': 2, 'converges': 1, 'improves': 1, 'reduces': 1}, ('meaning', 'gradient'): {'descent': 5}, ('gradually', 'for'): {'example': 6}, ('correctly', 'cross'): {'entropy': 6}, ('probability', 'successfully'): {'overfits': 1, 'learns': 2, 'maximizes': 1, 'outputs': 1, 'minimizes': 1, 'encodes': 2, 'decodes': 2, 'evaluates': 1, 'processes': 1, 'adjusts': 2, 'increases': 1}, ('prediction', 'for'): {'example': 2}, ('system', 'diverges'): {'token': 1, 'syntactic': 1, 'language': 1, 'the': 2}, ('errors', 'for'): {'example': 3}, ('output', 'furthermore'): {'the': 1}, ('embeddings', 'data'): {'preprocessing': 1}, ('descent', 'the'): {'weight': 4, 'loss': 5, 'dataset': 5, 'attention': 2, 'model': 4, 'optimizer': 3, 'architecture': 6, 'perplexity': 3, 'corpus': 4, 'n-gram': 5, 'context': 5, 'system': 2, 'vocabulary': 5, 'neural': 2, 'text': 4, 'input': 2, 'probability': 2, 'sequence': 2, 'gradient': 2, 'output': 2, 'language': 1, 'frequency': 2, 'algorithm': 3, 'prediction': 1, 'training': 1, 'bigram': 1, 'softmax': 1, 'evaluation': 1, 'trigram': 1, 'researcher': 1, 'embedding': 1, 'tokenizer': 1}, ('tokenizes', 'co-occurrence'): {'matrices': 12}, ('effectively', 'converges'): {'the': 2, 'syntactic': 1, 'large': 1}, ('modeling', 'in'): {'contrast': 1}, ('from', 'semantic'): {'meaning': 10}, ('captures', 'contextual'): {'information': 9}, ('vocabulary', 'updates'): {'word': 2, 'millions': 2, 'the': 4, 'contextual': 1, 'statistical': 1}, ('efficiently', 'similarly'): {'the': 7}, ('probabilistically', 'backpropagation'): {'reduces': 1, 'optimizes': 1, 'successfully': 1, 'overfits': 1}, ('structure', 'subsequently'): {'the': 2}, ('captures', 'the'): {'softmax': 11, 'cross': 14, 'weight': 15, 'hidden': 16, 'learning': 10, 'corpus': 15, 'batch': 16, 'loss': 7, 'activation': 12, 'gradient': 18, 'vocabulary': 7, 'probability': 9, 'training': 10, 'bias': 13, 'next': 11}, ('output', 'effectively'): {'the': 4, 'a': 2, 'nevertheless': 1, 'minimizes': 1, 'decodes': 1}, ('input', 'recursively'): {'optimizes': 2, 'updates': 1, 'overfits': 1}, ('value', 'data'): {'preprocessing': 1}, ('weight', 'significantly'): {'decodes': 1, 'samples': 1, 'diverges': 1, 'tokenizes': 1, 'learns': 1}, ('gradually', 'tokenization'): {'is': 3}, ('space', 'furthermore'): {'the': 3}, ('reduces', 'semantic'): {'meaning': 13}, ('rules', 'a'): {'shallow': 2, 'efficient': 3, 'autoregressive': 4, 'robust': 4, 'accurate': 4, 'pre-trained': 2, 'bidirectional': 3, 'neural': 4, 'deep': 4, 'small': 2, 'statistical': 1, 'recurrent': 2, 'transformer-based': 1, 'lightweight': 2, 'generative': 1}, ('matrix', 'subsequently'): {'the': 5}, ('loss', 'gradient'): {'descent': 2}, ('text', 'additionally'): {'the': 5}, ('decodes', 'semantic'): {'meaning': 11}, ('window', 'determines'): {'how': 90}, ('vocabulary', 'diverges'): {'the': 6, 'statistical': 1, 'word': 2, 'sentence': 1}, ('process', 'learns'): {'from': 9}, ('embeddings', 'furthermore'): {'backpropagation': 1, 'the': 5}, ('patterns', 'iteratively'): {'similarly': 1, 'furthermore': 1, 'cross': 1, 'the': 10, 'a': 6, 'word': 1, 'meanwhile': 1, 'bigram': 1, 'regularization': 1, 'as': 1, 'subsequently': 1, 'backpropagation': 1, 'however': 1}, ('process', 'generates'): {'the': 10, 'word': 2, 'semantic': 1}, ('data', 'as'): {'a': 1}, ('probability', 'updates'): {'millions': 3, 'syntactic': 2, 'the': 3, 'semantic': 2, 'word': 1, 'token': 1}, ('corpus', 'generalizes'): {'syntactic': 1, 'the': 6, 'language': 1}, ('network', 'learns'): {'from': 11}, ('architecture', 'generalizes'): {'the': 6, 'word': 1, 'linguistic': 1}, ('network', 'generates'): {'sentence': 2, 'the': 9, 'co-occurrence': 1, 'contextual': 1}, ('recursively', 'overfitting'): {'occurs': 5}, ('states', 'meanwhile'): {'the': 2}, ('layer', 'rapidly'): {'captures': 2, 'processes': 1, 'generates': 1, 'converges': 1}, ('distribution', 'correctly'): {'specifically': 1, 'the': 9, 'subsequently': 1, 'a': 3, 'moreover': 2, 'additionally': 1}, ('features', 'automatically'): {'meanwhile': 2, 'a': 4, 'however': 1, 'moreover': 2, 'the': 6, 'nevertheless': 1, 'transfer': 1, 'cleaning': 1, 'similarly': 1, 'gradient': 1}, ('accurately', 'furthermore'): {'the': 4}, ('meaning', 'accurately'): {'the': 8, 'a': 2, 'data': 1, 'perplexity': 1, 'overfitting': 1, 'therefore': 1, 'for': 1, 'meanwhile': 1}, ('prediction', 'learns'): {'from': 7}, ('gradually', 'generates'): {'language': 1, 'semantic': 1, 'the': 4, 'statistical': 1, 'millions': 1}, ('prediction', 'generates'): {'large': 1, 'the': 7, 'statistical': 1, 'millions': 1, 'sentence': 1}, ('embeddings', 'probabilistically'): {'regularization': 1, 'the': 12, 'perplexity': 1, 'a': 2, 'in': 1, 'for': 1}, ('efficiently', 'calculates'): {'the': 4, 'millions': 2, 'contextual': 1}, ('dataset', 'encodes'): {'the': 3, 'word': 2, 'contextual': 1, 'sentence': 1}, ('a', 'language'): {'model': 318}, ('recursively', 'maximizes'): {'the': 4, 'word': 1, 'language': 1, 'linguistic': 1}, ('word', 'training'): {'a': 2}, ('minimizes', 'token'): {'sequences': 9}, ('allows', 'pre-trained'): {'models': 104}, ('architecture', 'effectively'): {'learns': 1, 'optimizes': 1, 'generates': 1, 'calculates': 1, 'samples': 1, 'diverges': 1, 'outputs': 1, 'computes': 1}, ('encodes', 'word'): {'frequencies': 13, 'embeddings': 18}, ('word', 'therefore'): {'the': 3}, ('matrices', 'correctly'): {'the': 7, 'a': 3, 'therefore': 1}, ('mechanism', 'generalizes'): {'the': 9, 'linguistic': 2, 'millions': 1, 'contextual': 1, 'statistical': 1, 'large': 1}, ('statistically', 'decodes'): {'the': 2, 'word': 1, 'linguistic': 1, 'language': 1, 'semantic': 1}, ('dataset', 'minimizes'): {'the': 3, 'large': 2, 'word': 1, 'linguistic': 1, 'sentence': 1}, ('value', 'probabilistically'): {'the': 3, 'a': 2, 'as': 1, 'smoothing': 1, 'word': 1, 'cleaning': 1}, ('significantly', 'tokenizes'): {'the': 4, 'sentence': 1, 'semantic': 1, 'word': 1, 'language': 1}, ('process', 'accurately'): {'tokenizes': 1, 'learns': 1, 'models': 1, 'maximizes': 1, 'generates': 1, 'predicts': 1, 'calculates': 1, 'updates': 1, 'converges': 1, 'increases': 1}, ('structure', 'for'): {'example': 2}, ('layer', 'statistically'): {'tokenizes': 1, 'trains': 1, 'converges': 1, 'learns': 1}, ('significantly', 'therefore'): {'the': 3}, ('probabilistically', 'feeding'): {'diverse': 3}, ('rules', 'similarly'): {'the': 3}, ('metric', 'sequentially'): {'maximizes': 1, 'processes': 1, 'generates': 1, 'increases': 1, 'represents': 1, 'outputs': 1}, ('feeding', 'diverse'): {'text': 121}, ('fine-tunes', 'token'): {'sequences': 13}, ('network', 'accurately'): {'outputs': 1, 'improves': 1, 'reduces': 1, 'optimizes': 1, 'predicts': 1, 'models': 1, 'fine-tunes': 1, 'calculates': 1}, ('matrix', 'as'): {'a': 3}, ('recursively', 'captures'): {'the': 4, 'word': 1, 'linguistic': 1}, ('loss', 'accurately'): {'the': 3, 'a': 5, 'regularization': 1, 'data': 1}, ('to', 'new'): {'tasks': 104}, ('researcher', 'computes'): {'the': 2, 'contextual': 1}, ('from', 'contextual'): {'information': 14}, ('corpus', 'samples'): {'word': 1, 'the': 3, 'semantic': 1, 'linguistic': 2}, ('matrix', 'for'): {'example': 2}, ('significantly', 'learns'): {'from': 8}, ('architecture', 'samples'): {'the': 8, 'millions': 2, 'linguistic': 1, 'contextual': 1, 'sentence': 1}, ('effectively', 'predicts'): {'the': 4, 'contextual': 1, 'millions': 2, 'linguistic': 1, 'language': 1, 'word': 1}, ('bigram', 'reduces'): {'the': 6, 'sentence': 2, 'semantic': 1, 'contextual': 2, 'linguistic': 1, 'syntactic': 1}, ('gradient', 'processes'): {'large': 1, 'millions': 1, 'the': 4, 'statistical': 1, 'syntactic': 3, 'contextual': 1, 'language': 1}, ('accurately', 'samples'): {'contextual': 1, 'syntactic': 1, 'statistical': 1, 'word': 1}, ('patterns', 'cleaning'): {'and': 4}, ('mechanism', 'converges'): {'the': 5, 'statistical': 1, 'token': 1, 'large': 1}, ('states', 'iteratively'): {'consequently': 1, 'however': 1, 'the': 8, 'a': 3, 'specifically': 1}, ('probability', 'correctly'): {'predicts': 1, 'samples': 1, 'fine-tunes': 1, 'encodes': 1}, ('from', 'the'): {'softmax': 15, 'gradient': 12, 'next': 17, 'loss': 10, 'learning': 18, 'probability': 14, 'activation': 10, 'corpus': 18, 'batch': 13, 'bias': 16, 'vocabulary': 16, 'cross': 19, 'training': 10, 'hidden': 13, 'weight': 12}, ('bigram', 'tokenizes'): {'the': 4, 'contextual': 1, 'large': 1, 'language': 1, 'linguistic': 1, 'sentence': 1, 'word': 1}, ('corpus', 'the'): {'context': 6, 'architecture': 10, 'researcher': 2, 'vocabulary': 5, 'sequence': 11, 'probability': 4, 'text': 3, 'optimizer': 4, 'algorithm': 4, 'input': 5, 'tokenizer': 6, 'training': 9, 'n-gram': 4, 'output': 3, 'trigram': 5, 'model': 6, 'attention': 4, 'prediction': 4, 'evaluation': 4, 'gradient': 8, 'weight': 6, 'neural': 7, 'loss': 5, 'bigram': 1, 'perplexity': 7, 'language': 3, 'embedding': 3, 'system': 2, 'corpus': 1, 'dataset': 1}, ('prediction', 'accurately'): {'outputs': 1, 'decodes': 1, 'minimizes': 1, 'optimizes': 1, 'learns': 1}, ('model', 'processes'): {'co-occurrence': 2, 'contextual': 1, 'language': 1, 'the': 6, 'statistical': 1, 'word': 1, 'token': 1, 'large': 1}, ('iteratively', 'captures'): {'the': 3, 'large': 1, 'word': 3, 'language': 2, 'co-occurrence': 1}, ('modeling', 'moreover'): {'the': 1}, ('system', 'predicts'): {'syntactic': 1, 'word': 1, 'the': 7, 'statistical': 1, 'semantic': 2}, ('reduces', 'contextual'): {'information': 17}, ('states', 'transfer'): {'learning': 2}, ('in', 'contrast'): {'the': 171, 'backpropagation': 7}, ('continuously', 'represents'): {'statistical': 1, 'sentence': 4, 'the': 5, 'semantic': 1, 'millions': 1}, ('the', 'input'): {'statistically': 6, 'decodes': 9, 'adjusts': 10, 'improves': 8, 'rapidly': 5, 'updates': 6, 'increases': 8, 'recursively': 4, 'trains': 7, 'encodes': 10, 'samples': 10, 'maximizes': 12, 'fine-tunes': 11, 'reduces': 3, 'minimizes': 14, 'learns': 12, 'models': 13, 'predicts': 19, 'gradually': 4, 'generalizes': 11, 'iteratively': 3, 'automatically': 7, 'captures': 6, 'outputs': 6, 'processes': 7, 'represents': 13, 'converges': 11, 'calculates': 10, 'overfits': 11, 'sequentially': 7, 'efficiently': 7, 'accurately': 7, 'successfully': 5, 'tokenizes': 6, 'continuously': 4, 'correctly': 5, 'significantly': 3, 'effectively': 8, 'generates': 11, 'diverges': 7, 'computes': 6, 'optimizes': 5, 'evaluates': 5, 'probabilistically': 2}, ('new', 'tasks'): {'efficiently': 104}, ('statistically', 'specifically'): {'the': 2}, ('sequences', 'a'): {'scalable': 1, 'neural': 4, 'recurrent': 3, 'discriminative': 2, 'powerful': 3, 'autoregressive': 2, 'large': 2, 'transformer-based': 2, 'fine-tuned': 2, 'language': 2, 'shallow': 1, 'robust': 5, 'lightweight': 3, 'small': 3, 'pre-trained': 1, 'efficient': 1, 'accurate': 2, 'deep': 1}, ('backpropagation', 'reduces'): {'statistical': 1, 'the': 7, 'millions': 2, 'sentence': 1, 'word': 1, 'syntactic': 1, 'large': 1}, ('distribution', 'backpropagation'): {'samples': 1, 'gradually': 1, 'correctly': 1, 'statistically': 1, 'diverges': 1}, ('reduces', 'the'): {'softmax': 13, 'hidden': 17, 'gradient': 11, 'activation': 9, 'probability': 20, 'cross': 15, 'learning': 20, 'corpus': 20, 'next': 17, 'loss': 13, 'vocabulary': 13, 'weight': 12, 'training': 18, 'batch': 12, 'bias': 11}, ('corpus', 'improves'): {'the': 4, 'sentence': 1, 'word': 1}, ('corpus', 'overfits'): {'large': 2, 'linguistic': 1, 'word': 1, 'contextual': 1, 'the': 1}, ('size', 'specifically'): {'the': 3}, ('architecture', 'improves'): {'the': 4}, ('algorithm', 'probabilistically'): {'learns': 1, 'fine-tunes': 2, 'evaluates': 1}, ('architecture', 'overfits'): {'the': 4, 'token': 2, 'sentence': 1, 'contextual': 1, 'word': 1}, ('accurately', 'improves'): {'sentence': 1, 'the': 2}, ('a', 'scalable'): {'the': 141, 'backpropagation': 3}, ('window', 'captures'): {'language': 1, 'word': 1, 'the': 5, 'statistical': 1, 'sentence': 1, 'token': 1}, ('decodes', 'the'): {'probability': 17, 'weight': 15, 'activation': 15, 'next': 20, 'learning': 10, 'hidden': 9, 'cross': 14, 'softmax': 17, 'batch': 16, 'loss': 15, 'bias': 12, 'corpus': 7, 'training': 12, 'vocabulary': 15, 'gradient': 5}, ('dataset', 'maximizes'): {'token': 1, 'language': 1, 'the': 3, 'statistical': 1, 'syntactic': 1, 'millions': 1}, ('ability', 'additionally'): {'the': 2}, ('matrices', 'a'): {'small': 2, 'robust': 3, 'bidirectional': 4, 'discriminative': 2, 'powerful': 3, 'accurate': 2, 'transformer-based': 2, 'neural': 2, 'deep': 2, 'large': 3, 'autoregressive': 4, 'scalable': 2, 'pre-trained': 1, 'lightweight': 1, 'generative': 2, 'statistical': 3, 'efficient': 1, 'fine-tuned': 1, 'language': 1}, ('output', 'evaluates'): {'contextual': 1, 'the': 3, 'co-occurrence': 1, 'token': 1}, ('dataset', 'continuously'): {'generates': 2, 'increases': 1, 'trains': 1}, ('frequencies', 'meanwhile'): {'the': 4}, ('terms', 'specifically'): {'the': 4}, ('automatically', 'trains'): {'on': 6}, ('features', 'however'): {'the': 7}, ('rate', 'correctly'): {'training': 1, 'therefore': 2, 'a': 3, 'the': 5, 'cross': 2, 'subsequently': 1, 'consequently': 1, 'backpropagation': 1, 'bigram': 1, 'gradient': 1}, ('patterns', 'additionally'): {'the': 6}, ('researcher', 'successfully'): {'outputs': 1, 'encodes': 1, 'trains': 2, 'learns': 2, 'tokenizes': 1, 'evaluates': 2, 'predicts': 1}, ('meaning', 'probabilistically'): {'cleaning': 1, 'a': 1, 'the': 6, 'meanwhile': 1, 'bigram': 1, 'similarly': 1, 'feeding': 1, 'moreover': 1}, ('features', 'nevertheless'): {'the': 2}, ('descent', 'automatically'): {'the': 4, 'cleaning': 1, 'perplexity': 1, 'a': 2, 'meanwhile': 1}, ('size', 'sequentially'): {'moreover': 1, 'the': 11, 'transfer': 1, 'gradient': 1, 'a': 3, 'tokenization': 1, 'as': 1, 'for': 1, 'nevertheless': 1, 'perplexity': 1}, ('continuously', 'a'): {'robust': 7, 'fine-tuned': 4, 'discriminative': 1, 'bidirectional': 2, 'pre-trained': 3, 'transformer-based': 4, 'shallow': 2, 'neural': 3, 'autoregressive': 2, 'accurate': 3, 'recurrent': 4, 'efficient': 5, 'deep': 5, 'large': 4, 'language': 1, 'scalable': 3, 'powerful': 3, 'lightweight': 3, 'statistical': 2, 'small': 3, 'generative': 2}, ('tokenizes', 'the'): {'bias': 8, 'batch': 18, 'activation': 14, 'softmax': 19, 'corpus': 11, 'training': 23, 'vocabulary': 11, 'gradient': 12, 'probability': 11, 'hidden': 11, 'weight': 12, 'loss': 12, 'learning': 7, 'next': 13, 'cross': 15}, ('states', 'in'): {'contrast': 5}, ('mechanism', 'overfits'): {'the': 5, 'token': 1, 'sentence': 1, 'word': 1}, ('automatically', 'models'): {'linguistic': 1, 'the': 1, 'contextual': 1, 'statistical': 1, 'word': 1}, ('sequences', 'gradually'): {'the': 7, 'overfitting': 2, 'a': 4, 'regularization': 1, 'therefore': 1, 'subsequently': 1, 'nevertheless': 1, 'furthermore': 1, 'word': 1, 'in': 1}, ('states', 'rapidly'): {'the': 3, 'a': 5, 'however': 1, 'consequently': 1}, ('successfully', 'bigram'): {'and': 2}, ('word', 'data'): {'preprocessing': 1}, ('terms', 'sequentially'): {'the': 11, 'in': 2, 'backpropagation': 1, 'meanwhile': 1, 'a': 2, 'subsequently': 1, 'perplexity': 1}, ('perplexity', 'adjusts'): {'the': 4, 'millions': 1, 'word': 2, 'token': 1, 'contextual': 1}, ('states', 'cleaning'): {'and': 3}, ('before', 'feeding'): {'text': 99}, ('output', 'meanwhile'): {'the': 1}, ('metric', 'encodes'): {'the': 10, 'statistical': 1, 'contextual': 1, 'word': 1}, ('model', 'nevertheless'): {'the': 7, 'backpropagation': 1}, ('bigram', 'and'): {'trigram': 104}, ('significantly', 'data'): {'preprocessing': 1}, ('sequentially', 'represents'): {'the': 3, 'large': 1, 'contextual': 1, 'token': 1}, ('process', 'probabilistically'): {'encodes': 1, 'samples': 1, 'optimizes': 1, 'fine-tunes': 2, 'increases': 1, 'predicts': 1}, ('descent', 'transfer'): {'learning': 1}, ('input', 'decodes'): {'word': 2, 'token': 1, 'the': 3, 'millions': 1, 'statistical': 1, 'contextual': 1}, ('discriminative', 'the'): {'trigram': 4, 'dataset': 5, 'training': 5, 'perplexity': 3, 'neural': 5, 'evaluation': 4, 'corpus': 3, 'bigram': 3, 'tokenizer': 2, 'probability': 4, 'prediction': 2, 'input': 4, 'loss': 8, 'algorithm': 4, 'attention': 6, 'researcher': 5, 'system': 3, 'optimizer': 5, 'output': 4, 'weight': 4, 'language': 4, 'sequence': 3, 'embedding': 3, 'architecture': 3, 'vocabulary': 1, 'text': 2, 'context': 3, 'n-gram': 2, 'gradient': 4}, ('gradient', 'significantly'): {'models': 1, 'calculates': 1, 'fine-tunes': 1, 'samples': 1, 'improves': 1}, ('sequences', 'similarly'): {'the': 1}, ('metric', 'minimizes'): {'token': 1, 'word': 1, 'the': 5, 'syntactic': 1}, ('n-gram', 'decodes'): {'the': 2, 'contextual': 1, 'large': 1, 'semantic': 1, 'language': 1, 'linguistic': 1}, ('rapidly', 'backpropagation'): {'calculates': 1, 'rapidly': 1, 'optimizes': 1, 'samples': 1, 'reduces': 1}, ('on', 'sentence'): {'structure': 8}, ('network', 'probabilistically'): {'increases': 1, 'converges': 1, 'learns': 1, 'generates': 1, 'decodes': 1}, ('loss', 'probabilistically'): {'a': 4, 'data': 1, 'the': 7, 'additionally': 1, 'for': 1, 'therefore': 1}, ('model', 'significantly'): {'calculates': 1, 'fine-tunes': 1, 'generalizes': 3, 'generates': 1, 'samples': 1, 'adjusts': 1, 'predicts': 1, 'decodes': 1, 'represents': 1, 'increases': 1, 'diverges': 1}, ('frequencies', 'iteratively'): {'consequently': 2, 'furthermore': 1, 'the': 4, 'moreover': 1, 'a': 1}, ('accurately', 'evaluates'): {'co-occurrence': 1, 'the': 5, 'linguistic': 1, 'contextual': 1, 'sentence': 1, 'syntactic': 1}, ('sequence', 'correctly'): {'models': 1, 'outputs': 1, 'evaluates': 1, 'learns': 2, 'adjusts': 2}, ('efficiently', 'consequently'): {'the': 5}, ('recursively', 'generalizes'): {'syntactic': 1, 'large': 1, 'the': 2, 'word': 1}, ('distribution', 'feeding'): {'diverse': 2}, ('how', 'well'): {'a': 104}, ('correctly', 'gradient'): {'descent': 2}, ('automatically', 'word'): {'embeddings': 2}, ('semantic', 'meaning'): {'gradient': 5, 'accurately': 16, 'efficiently': 18, 'rapidly': 15, 'the': 97, 'sequentially': 15, 'overfitting': 2, 'moreover': 2, 'specifically': 2, 'perplexity': 6, 'a': 36, 'probabilistically': 13, 'significantly': 14, 'automatically': 13, 'therefore': 2, 'continuously': 19, 'successfully': 17, 'nevertheless': 4, 'gradually': 6, 'backpropagation': 5, 'correctly': 12, 'recursively': 14, 'additionally': 4, 'meanwhile': 3, 'bigram': 2, 'statistically': 10, 'consequently': 4, 'iteratively': 13, 'feeding': 1, 'tokenization': 2, 'transfer': 3, 'effectively': 6, 'training': 1, 'data': 1, 'furthermore': 3, 'subsequently': 1, 'similarly': 3, 'word': 2, 'as': 2, 'however': 1, 'cleaning': 1, 'in': 2, 'for': 1}, ('prediction', 'probabilistically'): {'computes': 1, 'fine-tunes': 1, 'calculates': 1}, ('successfully', 'perplexity'): {'measures': 1}, ('word', 'furthermore'): {'the': 1}, ('correctly', 'tokenizes'): {'word': 1, 'the': 2, 'language': 1}, ('n-gram', 'trains'): {'on': 16}, ('a', 'pre-trained'): {'the': 122, 'backpropagation': 4}, ('output', 'increases'): {'the': 2, 'syntactic': 1}, ('iteratively', 'generalizes'): {'co-occurrence': 1, 'word': 1, 'statistical': 1, 'the': 2}, ('distribution', 'recursively'): {'the': 5, 'feeding': 1, 'a': 7, 'overfitting': 1}, ('successfully', 'calculates'): {'the': 4, 'semantic': 1, 'contextual': 1}, ('states', 'additionally'): {'the': 2}, ('when', 'a'): {'model': 104}, ('function', 'captures'): {'millions': 1, 'the': 4, 'token': 2, 'linguistic': 1}, ('continuously', 'similarly'): {'the': 5}, ('sequentially', 'a'): {'large': 6, 'lightweight': 5, 'robust': 6, 'generative': 6, 'scalable': 6, 'statistical': 5, 'transformer-based': 1, 'pre-trained': 4, 'bidirectional': 5, 'powerful': 5, 'deep': 1, 'recurrent': 4, 'shallow': 3, 'neural': 2, 'autoregressive': 4, 'fine-tuned': 3, 'discriminative': 3, 'small': 4, 'efficient': 1}, ('recursively', 'converges'): {'millions': 1, 'the': 3, 'statistical': 1}, ('output', 'optimizes'): {'token': 2, 'word': 2, 'syntactic': 2, 'millions': 1, 'the': 4}, ('correctly', 'learns'): {'from': 6}, ('output', 'iteratively'): {'generalizes': 1, 'perplexity': 1, 'word': 1, 'gradient': 1, 'the': 7, 'a': 2, 'tokenizes': 1, 'predicts': 1}, ('correctly', 'generates'): {'large': 1, 'the': 5, 'linguistic': 1, 'word': 1}, ('descent', 'in'): {'addition': 4, 'contrast': 2}, ('n-gram', 'models'): {'large': 2, 'co-occurrence': 1, 'statistical': 1, 'the': 3, 'millions': 1, 'semantic': 1}, ('accurately', 'meanwhile'): {'the': 5}, ('continuously', 'bigram'): {'and': 3}, ('perplexity', 'efficiently'): {'improves': 1, 'updates': 1, 'overfits': 1, 'samples': 1, 'adjusts': 1}, ('metric', 'computes'): {'the': 4}, ('window', 'generalizes'): {'contextual': 1, 'token': 3, 'the': 10, 'sentence': 1, 'statistical': 1}, ('statistically', 'encodes'): {'the': 4, 'contextual': 1}, ('descent', 'rapidly'): {'the': 6, 'a': 6, 'meanwhile': 1, 'consequently': 1, 'in': 1, 'bigram': 1}, ('effectively', 'processes'): {'the': 4, 'linguistic': 1, 'large': 1, 'millions': 1}, ('word', 'probabilistically'): {'the': 6, 'training': 2, 'a': 4, 'therefore': 1, 'subsequently': 1, 'gradient': 1}, ('matrices', 'recursively'): {'smoothing': 1, 'moreover': 3, 'subsequently': 1, 'the': 7, 'overfitting': 1, 'word': 1, 'in': 1, 'a': 2, 'therefore': 2, 'additionally': 1}, ('encodes', 'co-occurrence'): {'matrices': 16}, ('value', 'gradually'): {'a': 2, 'cleaning': 1, 'specifically': 1, 'the': 4, 'regularization': 1, 'as': 1, 'in': 1, 'tokenization': 1}, ('statistically', 'minimizes'): {'word': 1, 'co-occurrence': 1, 'the': 4}, ('be', 'adapted'): {'to': 104}, ('system', 'processes'): {'word': 1, 'semantic': 1, 'language': 1, 'large': 1, 'the': 3, 'contextual': 1}, ('computes', 'token'): {'sequences': 10}, ('efficiently', 'subsequently'): {'the': 8}, ('preprocessing', 'is'): {'a': 99}, ('descent', 'however'): {'the': 1, 'backpropagation': 1}, ('evaluates', 'statistical'): {'patterns': 14}, ('input', 'sequentially'): {'minimizes': 1, 'represents': 1, 'trains': 2, 'updates': 1, 'evaluates': 1, 'maximizes': 1}, ('embeddings', 'bigram'): {'and': 1}, ('trigram', 'generalizes'): {'the': 4, 'linguistic': 1}, ('window', 'converges'): {'the': 5, 'word': 2, 'token': 1, 'statistical': 1, 'sentence': 1, 'co-occurrence': 1}, ('frequencies', 'cleaning'): {'and': 1}, ('dataset', 'diverges'): {'semantic': 1, 'the': 9, 'language': 1, 'millions': 1, 'word': 1, 'contextual': 1, 'large': 1}, ('the', 'prediction'): {'captures': 8, 'significantly': 9, 'decodes': 11, 'encodes': 12, 'reduces': 11, 'effectively': 7, 'generates': 11, 'statistically': 1, 'learns': 7, 'calculates': 12, 'predicts': 29, 'updates': 5, 'processes': 7, 'efficiently': 9, 'models': 14, 'overfits': 7, 'diverges': 8, 'represents': 8, 'outputs': 7, 'correctly': 16, 'fine-tunes': 12, 'rapidly': 9, 'generalizes': 10, 'optimizes': 7, 'increases': 8, 'samples': 12, 'gradually': 8, 'improves': 8, 'computes': 5, 'recursively': 2, 'evaluates': 9, 'continuously': 3, 'adjusts': 6, 'tokenizes': 5, 'iteratively': 10, 'successfully': 6, 'converges': 6, 'trains': 9, 'minimizes': 5, 'automatically': 5, 'sequentially': 7, 'probabilistically': 3, 'accurately': 5, 'maximizes': 7}, ('text', 'training'): {'a': 4}, ('text', 'tokenizes'): {'the': 4, 'linguistic': 1}, ('corpus', 'automatically'): {'the': 5, 'for': 1, 'bigram': 1, 'reduces': 1, 'a': 2, 'predicts': 1, 'processes': 1, 'improves': 1}, ('bigram', 'effectively'): {'fine-tunes': 1, 'calculates': 2, 'computes': 1, 'increases': 1, 'models': 1}, ('rapidly', 'feeding'): {'diverse': 6}, ('iteratively', 'samples'): {'contextual': 2, 'word': 1, 'the': 2}, ('text', 'therefore'): {'the': 7}, ('accurately', 'increases'): {'language': 1, 'linguistic': 1, 'the': 2}, ('continuously', 'perplexity'): {'measures': 4}, ('researcher', 'correctly'): {'captures': 1, 'generalizes': 1, 'trains': 1, 'converges': 1}, ('value', 'similarly'): {'the': 2}, ('probability', 'recursively'): {'computes': 1, 'converges': 1, 'generates': 1, 'samples': 1, 'minimizes': 1, 'overfits': 1}, ('probabilistically', 'decodes'): {'the': 5, 'sentence': 1}, ('descent', 'statistically'): {'furthermore': 1, 'the': 9, 'nevertheless': 1, 'additionally': 1, 'in': 1, 'a': 2, 'for': 1, 'moreover': 1, 'backpropagation': 1}, ('represents', 'word'): {'frequencies': 18, 'embeddings': 14}, ('network', 'represents'): {'word': 2, 'token': 1, 'language': 1, 'the': 3, 'co-occurrence': 1, 'syntactic': 1}, ('states', 'moreover'): {'the': 2}, ('iteratively', 'the'): {'loss': 5, 'architecture': 5, 'bigram': 6, 'dataset': 6, 'vocabulary': 7, 'optimizer': 10, 'output': 8, 'algorithm': 6, 'training': 8, 'trigram': 3, 'context': 7, 'attention': 4, 'text': 5, 'embedding': 2, 'prediction': 6, 'weight': 8, 'researcher': 2, 'sequence': 4, 'softmax': 3, 'perplexity': 5, 'probability': 2, 'system': 3, 'language': 3, 'tokenizer': 1, 'neural': 4, 'evaluation': 4, 'n-gram': 3, 'frequency': 2, 'gradient': 5, 'model': 2, 'input': 3, 'corpus': 2}, ('meaning', 'a'): {'large': 2, 'fine-tuned': 2, 'lightweight': 4, 'pre-trained': 2, 'powerful': 3, 'efficient': 1, 'autoregressive': 3, 'deep': 1, 'scalable': 1, 'generative': 3, 'accurate': 2, 'recurrent': 1, 'statistical': 1, 'discriminative': 1, 'language': 1, 'transformer-based': 3, 'small': 2, 'robust': 1, 'shallow': 1, 'neural': 1}, ('successfully', 'outputs'): {'the': 4, 'token': 1, 'word': 1, 'millions': 1}, ('continuously', 'calculates'): {'language': 1, 'the': 5, 'token': 1}, ('rules', 'consequently'): {'the': 3}, ('value', 'bigram'): {'and': 1}, ('resources', 'as'): {'a': 2}, ('optimizer', 'tokenizes'): {'syntactic': 3, 'large': 1, 'the': 4, 'linguistic': 1}, ('parameters', 'the'): {'corpus': 6, 'output': 4, 'training': 4, 'system': 2, 'researcher': 2, 'tokenizer': 4, 'vocabulary': 4, 'softmax': 3, 'frequency': 3, 'attention': 2, 'model': 5, 'weight': 1, 'loss': 3, 'neural': 5, 'bigram': 3, 'gradient': 2, 'prediction': 2, 'sequence': 3, 'optimizer': 4, 'language': 5, 'algorithm': 1, 'context': 2, 'n-gram': 5, 'input': 3, 'trigram': 3, 'probability': 2, 'text': 2, 'evaluation': 2, 'perplexity': 1, 'embedding': 2}, ('backpropagation', 'effectively'): {'decodes': 2, 'maximizes': 1, 'generates': 1, 'converges': 1, 'reduces': 1}, ('gradually', 'represents'): {'the': 2, 'token': 1}, ('sequentially', 'similarly'): {'the': 5}, ('resources', 'for'): {'example': 2}, ('metric', 'successfully'): {'tokenizes': 1, 'diverges': 1, 'trains': 1, 'overfits': 1, 'generalizes': 2, 'outputs': 1, 'fine-tunes': 1}, ('prediction', 'represents'): {'the': 4, 'co-occurrence': 1, 'token': 1, 'contextual': 1, 'syntactic': 1}, ('probabilistically', 'trains'): {'on': 2}, ('outputs', 'syntactic'): {'rules': 11}, ('output', 'cleaning'): {'and': 2}, ('algorithm', 'gradually'): {'encodes': 1, 'generates': 1, 'evaluates': 1, 'decodes': 1, 'samples': 1, 'learns': 1}, ('corpus', 'transfer'): {'learning': 2}, ('generates', 'language'): {'patterns': 19}, ('overfits', 'token'): {'sequences': 13}, ('contextual', 'information'): {'the': 87, 'a': 40, 'gradually': 10, 'effectively': 13, 'efficiently': 12, 'iteratively': 16, 'probabilistically': 17, 'correctly': 18, 'statistically': 13, 'automatically': 13, 'accurately': 13, 'in': 5, 'recursively': 15, 'rapidly': 24, 'overfitting': 3, 'backpropagation': 5, 'consequently': 4, 'sequentially': 14, 'meanwhile': 4, 'successfully': 16, 'perplexity': 3, 'significantly': 11, 'additionally': 5, 'similarly': 4, 'word': 1, 'therefore': 3, 'bigram': 5, 'smoothing': 2, 'moreover': 1, 'cross': 4, 'specifically': 3, 'continuously': 7, 'for': 1, 'however': 3, 'regularization': 2, 'training': 2, 'furthermore': 2, 'transfer': 2, 'nevertheless': 3, 'data': 1, 'cleaning': 1, 'gradient': 2, 'subsequently': 1}, ('iteratively', 'improves'): {'linguistic': 1, 'the': 3, 'token': 1, 'syntactic': 1}, ('iteratively', 'overfits'): {'the': 1}, ('statistically', 'smoothing'): {'techniques': 1}, ('embeddings', 'perplexity'): {'measures': 1}, ('accurately', 'transfer'): {'learning': 2}, ('optimizer', 'learns'): {'from': 8}, ('modeling', 'therefore'): {'the': 2}, ('samples', 'large'): {'amounts': 16}, ('mechanism', 'automatically'): {'generates': 1, 'improves': 1, 'updates': 1, 'computes': 1, 'predicts': 1, 'increases': 1, 'models': 1, 'encodes': 1, 'generalizes': 1}, ('statistically', 'maximizes'): {'word': 2, 'linguistic': 2, 'co-occurrence': 1, 'the': 3}, ('optimizer', 'generates'): {'the': 6, 'large': 1, 'sentence': 1, 'linguistic': 1, 'statistical': 1, 'token': 1}, ('tokenizer', 'correctly'): {'overfits': 1, 'outputs': 2, 'increases': 1, 'encodes': 1}, ('effectively', 'nevertheless'): {'the': 6}, ('size', 'smoothing'): {'techniques': 2}, ('correctly', 'data'): {'preprocessing': 2}, ('frequencies', 'additionally'): {'the': 4}, ('successfully', 'cross'): {'entropy': 4}, ('probabilistically', 'models'): {'the': 7, 'large': 1, 'millions': 2, 'semantic': 1, 'word': 1}, ('space', 'in'): {'contrast': 1, 'addition': 1}, ('trigram', 'samples'): {'large': 1, 'the': 5, 'semantic': 1, 'statistical': 1}, ('however', 'the'): {'attention': 7, 'perplexity': 10, 'probability': 6, 'training': 8, 'bigram': 8, 'evaluation': 9, 'weight': 6, 'trigram': 6, 'language': 9, 'n-gram': 9, 'input': 8, 'loss': 10, 'corpus': 11, 'output': 4, 'text': 7, 'architecture': 7, 'algorithm': 7, 'vocabulary': 14, 'gradient': 3, 'context': 6, 'sequence': 9, 'embedding': 9, 'neural': 3, 'optimizer': 2, 'model': 5, 'researcher': 5, 'dataset': 4, 'system': 2, 'prediction': 8, 'tokenizer': 3}, ('processes', 'token'): {'sequences': 10}, ('terms', 'smoothing'): {'techniques': 2}, ('backpropagation', 'samples'): {'semantic': 2, 'the': 6, 'co-occurrence': 1, 'syntactic': 2}, ('rate', 'recursively'): {'the': 6, 'however': 1, 'nevertheless': 1, 'additionally': 2, 'gradient': 1, 'for': 1, 'in': 1, 'a': 3}, ('window', 'overfits'): {'the': 3, 'co-occurrence': 1, 'word': 3, 'statistical': 1, 'large': 1, 'syntactic': 1, 'semantic': 1}, ('value', 'perplexity'): {'measures': 3}, ('loss', 'a'): {'lightweight': 12, 'autoregressive': 3, 'small': 2, 'bidirectional': 8, 'pre-trained': 5, 'generative': 5, 'shallow': 5, 'transformer-based': 2, 'discriminative': 4, 'deep': 4, 'powerful': 3, 'accurate': 3, 'recurrent': 2, 'large': 3, 'statistical': 4, 'efficient': 4, 'robust': 2, 'neural': 2, 'fine-tuned': 4}, ('meaning', 'gradually'): {'the': 3, 'therefore': 1, 'cleaning': 1, 'for': 1}, ('automatically', 'overfitting'): {'occurs': 5}, ('function', 'generalizes'): {'linguistic': 1, 'the': 2, 'contextual': 1, 'sentence': 1}, ('frequencies', 'cross'): {'entropy': 3}, ('recursively', 'predicts'): {'the': 7, 'semantic': 2, 'millions': 1, 'contextual': 1, 'sentence': 1, 'word': 1}, ('statistically', 'regularization'): {'techniques': 2}, ('gradually', 'a'): {'powerful': 3, 'fine-tuned': 4, 'efficient': 6, 'bidirectional': 2, 'recurrent': 2, 'robust': 6, 'pre-trained': 4, 'generative': 4, 'lightweight': 6, 'accurate': 5, 'statistical': 3, 'small': 5, 'autoregressive': 7, 'neural': 5, 'shallow': 4, 'transformer-based': 5, 'discriminative': 3, 'deep': 5, 'scalable': 3, 'large': 1}, ('prediction', 'a'): {'bidirectional': 1, 'fine-tuned': 4, 'accurate': 2, 'transformer-based': 4, 'deep': 1, 'efficient': 1, 'shallow': 1, 'robust': 2, 'discriminative': 1, 'lightweight': 1}, ('data', 'correctly'): {'a': 3, 'in': 1, 'the': 10, 'therefore': 1, 'nevertheless': 1, 'for': 1}, ('updates', 'large'): {'amounts': 16}, ('errors', 'a'): {'small': 3, 'neural': 3, 'fine-tuned': 2, 'large': 3, 'shallow': 1, 'statistical': 1, 'scalable': 2, 'powerful': 1, 'generative': 1, 'pre-trained': 1, 'autoregressive': 1, 'discriminative': 3, 'robust': 2, 'bidirectional': 1, 'accurate': 2, 'deep': 1, 'efficient': 1}, ('layer', 'reduces'): {'contextual': 1, 'the': 6, 'syntactic': 1, 'word': 1}, ('the', 'memory'): {'requirements': 108}, ('system', 'significantly'): {'improves': 1, 'models': 1, 'minimizes': 1, 'predicts': 1, 'adjusts': 1, 'learns': 2}, ('embeddings', 'cleaning'): {'and': 3}, ('perplexity', 'learns'): {'from': 10}, ('corpus', 'in'): {'addition': 1, 'contrast': 3}, ('continuously', 'outputs'): {'the': 3, 'statistical': 1, 'syntactic': 1}, ('perplexity', 'generates'): {'the': 6, 'co-occurrence': 1, 'syntactic': 2, 'large': 1}, ('input', 'encodes'): {'the': 6, 'linguistic': 1, 'word': 1, 'co-occurrence': 1, 'large': 1}, ('layer', 'tokenizes'): {'syntactic': 1, 'the': 8, 'linguistic': 1, 'statistical': 1, 'co-occurrence': 1}, ('words', 'nevertheless'): {'the': 4}, ('trigram', 'improves'): {'word': 1, 'sentence': 1, 'the': 4, 'co-occurrence': 1, 'language': 2, 'token': 1}, ('output', 'additionally'): {'the': 2}, ('trigram', 'overfits'): {'the': 4, 'large': 2}, ('metric', 'updates'): {'contextual': 1, 'the': 9, 'statistical': 2, 'co-occurrence': 1, 'millions': 1, 'word': 1}, ('automatically', 'maximizes'): {'the': 2}, ('accurately', 'in'): {'addition': 7, 'contrast': 1}, ('descent', 'moreover'): {'the': 2}, ('language', 'model'): {'the': 95, 'consequently': 6, 'fine-tunes': 11, 'requires': 109, 'improves': 131, 'predicts': 131, 'maximizes': 11, 'statistically': 7, 'overfits': 6, 'a': 57, 'generalizes': 11, 'rapidly': 6, 'assigns': 93, 'processes': 11, 'outputs': 4, 'sequentially': 7, 'increases': 14, 'samples': 10, 'computes': 7, 'optimizes': 12, 'diverges': 11, 'generates': 14, 'however': 3, 'continuously': 7, 'calculates': 9, 'successfully': 7, 'evaluates': 15, 'nevertheless': 6, 'probabilistically': 4, 'adjusts': 12, 'therefore': 6, 'gradually': 6, 'represents': 9, 'minimizes': 9, 'furthermore': 3, 'decodes': 11, 'captures': 11, 'additionally': 5, 'updates': 12, 'encodes': 5, 'in': 7, 'tokenizes': 13, 'automatically': 8, 'converges': 10, 'effectively': 3, 'trains': 7, 'significantly': 7, 'models': 10, 'subsequently': 3, 'learns': 9, 'backpropagation': 1, 'similarly': 2, 'specifically': 3, 'reduces': 7, 'correctly': 7, 'for': 3, 'efficiently': 7, 'as': 4, 'accurately': 8, 'iteratively': 4, 'moreover': 1, 'meanwhile': 2, 'recursively': 2}, ('meaning', 'similarly'): {'the': 3}, ('corpus', 'rapidly'): {'a': 4, 'the': 7, 'in': 1, 'subsequently': 1, 'specifically': 1, 'for': 1, 'increases': 1, 'improves': 1, 'cleaning': 1, 'similarly': 1}, ('rules', 'specifically'): {'the': 3}, ('backpropagation', 'improves'): {'the': 3, 'semantic': 2, 'contextual': 1, 'large': 1}, ('words', 'based'): {'on': 93}, ('architecture', 'rapidly'): {'fine-tunes': 1, 'samples': 1, 'trains': 1, 'decodes': 1, 'models': 1, 'generalizes': 1}, ('optimizer', 'accurately'): {'generates': 1, 'fine-tunes': 1, 'minimizes': 1, 'outputs': 2, 'adjusts': 1}, ('process', 'gradually'): {'processes': 1, 'samples': 1, 'reduces': 1, 'learns': 1, 'predicts': 1, 'converges': 1, 'maximizes': 1, 'updates': 1, 'outputs': 1}, ('sufficient', 'computational'): {'resources': 109}, ('accurately', 'cleaning'): {'and': 3}, ('input', 'minimizes'): {'semantic': 1, 'contextual': 2, 'the': 5, 'sentence': 2, 'syntactic': 2, 'millions': 1, 'large': 1}, ('size', 'successfully'): {'the': 18, 'a': 10, 'overfitting': 1, 'data': 1, 'in': 1, 'cross': 1, 'transfer': 1, 'additionally': 1, 'therefore': 1, 'nevertheless': 1}, ('network', 'gradually'): {'evaluates': 1, 'computes': 1, 'calculates': 1, 'diverges': 1, 'predicts': 1}, ('output', 'cross'): {'entropy': 2}, ('loss', 'gradually'): {'a': 3, 'additionally': 1, 'the': 5, 'word': 1, 'perplexity': 1, 'as': 1, 'moreover': 3, 'backpropagation': 1, 'feeding': 1}, ('sequence', 'recursively'): {'generates': 1, 'predicts': 2, 'processes': 1, 'minimizes': 2}, ('text', 'data'): {'ensures': 98, 'preprocessing': 6}, ('corpus', 'however'): {'the': 9}, ('optimizes', 'syntactic'): {'rules': 14}, ('terms', 'successfully'): {'the': 6, 'moreover': 1, 'a': 2}, ('automatically', 'captures'): {'the': 2, 'millions': 1, 'token': 1, 'syntactic': 1, 'sentence': 1}, ('metric', 'diverges'): {'linguistic': 1, 'co-occurrence': 1, 'the': 1, 'language': 1, 'large': 1, 'word': 1}, ('structure', 'correctly'): {'similarly': 1, 'word': 1, 'the': 5, 'subsequently': 1, 'a': 1, 'meanwhile': 1}, ('space', 'additionally'): {'the': 1}, ('prediction', 'gradually'): {'models': 1, 'increases': 1, 'adjusts': 2, 'diverges': 1, 'represents': 1, 'trains': 1, 'computes': 1}, ('algorithm', 'calculates'): {'millions': 1, 'the': 1, 'co-occurrence': 1, 'word': 1}, ('on', 'millions'): {'of': 18}, ('rules', 'sequentially'): {'cross': 1, 'the': 5, 'subsequently': 1, 'additionally': 1, 'similarly': 1, 'meanwhile': 1}, ('sequences', 'consequently'): {'the': 3}, ('ability', 'therefore'): {'the': 4}, ('information', 'significantly'): {'transfer': 1, 'a': 1, 'in': 1, 'the': 6, 'bigram': 1, 'moreover': 1}, ('function', 'samples'): {'co-occurrence': 2, 'semantic': 2, 'linguistic': 1, 'millions': 1, 'the': 2, 'sentence': 1}, ('improves', 'its'): {'generalization': 121}, ('corpus', 'statistically'): {'meanwhile': 2, 'the': 7, 'a': 3, 'computes': 1, 'adjusts': 1, 'evaluates': 1, 'diverges': 1}, ('system', 'trains'): {'on': 12}, ('successfully', 'adjusts'): {'token': 1, 'the': 6, 'large': 1, 'semantic': 1, 'sentence': 1, 'language': 2, 'word': 1}, ('loss', 'similarly'): {'the': 6}, ('architecture', 'statistically'): {'overfits': 1, 'models': 1, 'computes': 1, 'outputs': 2, 'predicts': 1}, ('matrix', 'correctly'): {'a': 4, 'the': 5, 'meanwhile': 1, 'however': 1, 'additionally': 1, 'furthermore': 1}, ('function', 'the'): {'optimizer': 3, 'system': 4, 'perplexity': 3, 'evaluation': 4, 'vocabulary': 4, 'text': 2, 'sequence': 2, 'algorithm': 4, 'architecture': 3, 'model': 1, 'researcher': 3, 'context': 4, 'embedding': 2, 'neural': 3, 'tokenizer': 3, 'training': 1, 'n-gram': 4, 'bigram': 4, 'dataset': 3, 'corpus': 1, 'output': 1, 'probability': 3, 'softmax': 1, 'loss': 2, 'trigram': 1, 'attention': 3, 'language': 2, 'prediction': 1, 'frequency': 2, 'weight': 1, 'gradient': 1}, ('patterns', 'gradient'): {'descent': 4}, ('perplexity', 'accurately'): {'computes': 1, 'overfits': 2, 'trains': 2, 'predicts': 1, 'represents': 1}, ('bigram', 'evaluates'): {'the': 4, 'sentence': 1, 'syntactic': 1, 'large': 2, 'contextual': 1, 'word': 1, 'linguistic': 1, 'co-occurrence': 1}, ('dataset', 'predicts'): {'linguistic': 1, 'the': 10, 'language': 3, 'millions': 1, 'syntactic': 1, 'large': 2, 'token': 1, 'co-occurrence': 1, 'contextual': 1, 'word': 1}, ('patterns', 'therefore'): {'the': 8, 'backpropagation': 2}, ('weight', 'generalizes'): {'token': 1, 'large': 2, 'syntactic': 1, 'word': 1, 'semantic': 1, 'the': 5, 'sentence': 1}, ('gradually', 'similarly'): {'the': 6}, ('prediction', 'similarly'): {'backpropagation': 1, 'the': 4}, ('errors', 'similarly'): {'the': 1}, ('accurately', 'additionally'): {'the': 8}, ('embeddings', 'cross'): {'entropy': 3}, ('statistically', 'updates'): {'the': 1, 'millions': 1}, ('successfully', 'subsequently'): {'the': 1}, ('sample', 'of'): {'text': 104}, ('function', 'improves'): {'co-occurrence': 2, 'contextual': 1, 'the': 2, 'statistical': 1, 'word': 1, 'large': 1}, ('function', 'overfits'): {'semantic': 1, 'the': 3, 'word': 1, 'millions': 1, 'language': 1, 'linguistic': 1}, ('input', 'maximizes'): {'the': 8, 'contextual': 1, 'semantic': 1, 'large': 1, 'token': 1}, ('training', 'loop'): {'updates': 104}, ('vocabulary', 'decodes'): {'sentence': 2, 'word': 2, 'contextual': 1, 'syntactic': 1, 'co-occurrence': 1, 'the': 1, 'large': 1}, ('the', 'system'): {'statistically': 7, 'outputs': 8, 'maximizes': 13, 'probabilistically': 13, 'trains': 12, 'rapidly': 8, 'significantly': 7, 'generates': 5, 'generalizes': 11, 'encodes': 11, 'accurately': 8, 'reduces': 10, 'effectively': 9, 'converges': 9, 'models': 9, 'represents': 12, 'samples': 10, 'updates': 8, 'predicts': 12, 'improves': 6, 'processes': 8, 'captures': 11, 'decodes': 15, 'optimizes': 12, 'calculates': 12, 'successfully': 7, 'tokenizes': 11, 'iteratively': 10, 'evaluates': 11, 'gradually': 3, 'correctly': 7, 'learns': 7, 'adjusts': 5, 'computes': 6, 'minimizes': 13, 'continuously': 5, 'diverges': 5, 'automatically': 4, 'increases': 4, 'recursively': 7, 'fine-tunes': 5, 'efficiently': 5, 'overfits': 5, 'sequentially': 6}, ('n-gram', 'maximizes'): {'token': 1, 'the': 4, 'contextual': 1}, ('language', 'models'): {'from': 92, 'handle': 88}, ('continuously', 'consequently'): {'the': 8}, ('improves', 'millions'): {'of': 15}, ('n-gram', 'continuously'): {'improves': 1, 'encodes': 1, 'reduces': 1, 'represents': 1, 'calculates': 1, 'decodes': 1, 'optimizes': 2}, ('mechanism', 'statistically'): {'predicts': 2, 'models': 1, 'generates': 1, 'trains': 1, 'calculates': 1, 'reduces': 1, 'represents': 1, 'tokenizes': 1}, ('reduces', 'statistical'): {'patterns': 10}, ('weight', 'effectively'): {'increases': 1, 'encodes': 3, 'models': 1, 'generates': 1, 'optimizes': 1, 'processes': 1}, ('evaluates', 'linguistic'): {'features': 10}, ('decodes', 'statistical'): {'patterns': 13}, ('successfully', 'fine-tunes'): {'linguistic': 2, 'syntactic': 1, 'the': 5, 'language': 1}, ('process', 'calculates'): {'the': 4, 'syntactic': 1, 'contextual': 1}, ('sequences', 'subsequently'): {'the': 5}, ('vocabulary', 'trains'): {'on': 7}, ('statistically', 'diverges'): {'the': 3, 'semantic': 1, 'linguistic': 1}, ('structure', 'a'): {'autoregressive': 3, 'small': 2, 'shallow': 3, 'lightweight': 2, 'efficient': 4, 'deep': 2, 'discriminative': 1, 'pre-trained': 4, 'generative': 7, 'statistical': 3, 'language': 1, 'large': 3, 'transformer-based': 1, 'recurrent': 2, 'bidirectional': 3, 'fine-tuned': 1, 'robust': 2, 'powerful': 1, 'scalable': 1, 'accurate': 1}, ('word', 'bigram'): {'and': 2}, ('text', 'probabilistically'): {'trains': 1, 'the': 4, 'fine-tunes': 1, 'computes': 2, 'therefore': 1, 'additionally': 1, 'maximizes': 1, 'a': 3, 'increases': 1, 'tokenizes': 1, 'models': 1}, ('effectively', 'word'): {'embeddings': 3}, ('maximizes', 'millions'): {'of': 13}, ('algorithm', 'outputs'): {'the': 7}, ('modeling', 'furthermore'): {'the': 2}, ('network', 'calculates'): {'the': 4, 'sentence': 1, 'linguistic': 1, 'millions': 2, 'token': 2, 'word': 1}, ('efficiently', 'computes'): {'statistical': 1, 'the': 6, 'millions': 1, 'semantic': 1, 'linguistic': 1}, ('n-gram', 'captures'): {'the': 6, 'language': 2, 'sentence': 1, 'word': 2, 'co-occurrence': 1}, ('researcher', 'recursively'): {'outputs': 1, 'predicts': 1, 'generalizes': 1, 'represents': 1, 'generates': 1, 'diverges': 1, 'adjusts': 1}, ('a', 'recurrent'): {'the': 105, 'backpropagation': 3}, ('probabilistically', 'minimizes'): {'the': 4, 'co-occurrence': 1}, ('sequences', 'specifically'): {'the': 2}, ('probability', 'decodes'): {'the': 9, 'co-occurrence': 1, 'sentence': 1}, ('represents', 'co-occurrence'): {'matrices': 8}, ('significantly', 'bigram'): {'and': 4}, ('parameters', 'automatically'): {'therefore': 2, 'a': 2, 'the': 2, 'backpropagation': 1, 'furthermore': 1, 'however': 1}, ('continuously', 'adjusts'): {'the': 5, 'sentence': 1, 'linguistic': 1, 'word': 1, 'contextual': 1, 'millions': 1}, ('penalizes', 'the'): {'model': 111}, ('matrix', 'a'): {'shallow': 3, 'scalable': 4, 'small': 2, 'efficient': 3, 'powerful': 2, 'bidirectional': 2, 'pre-trained': 2, 'transformer-based': 4, 'discriminative': 3, 'robust': 2, 'autoregressive': 1, 'language': 1, 'fine-tuned': 1, 'accurate': 2, 'statistical': 1, 'neural': 1, 'large': 3, 'recurrent': 1, 'deep': 1}, ('optimizer', 'probabilistically'): {'adjusts': 1, 'optimizes': 1, 'represents': 1, 'decodes': 1, 'fine-tunes': 1, 'trains': 1}, ('vocabulary', 'models'): {'token': 1, 'millions': 1, 'the': 2, 'linguistic': 1, 'syntactic': 1}, ('map', 'tokens'): {'to': 88}, ('weight', 'samples'): {'the': 5, 'sentence': 1, 'statistical': 1, 'language': 1, 'word': 1, 'semantic': 1}, ('tokenizes', 'statistical'): {'patterns': 15}, ('prediction', 'calculates'): {'co-occurrence': 1, 'linguistic': 2, 'the': 7, 'sentence': 1, 'millions': 1}, ('rapidly', 'decodes'): {'the': 7, 'word': 1}, ('corpus', 'moreover'): {'the': 5}, ('matrices', 'specifically'): {'the': 1}, ('patterns', 'accurately'): {'specifically': 1, 'a': 6, 'the': 14, 'feeding': 1, 'similarly': 1, 'meanwhile': 1, 'in': 1, 'overfitting': 1, 'regularization': 1, 'additionally': 1, 'transfer': 1}, ('input', 'successfully'): {'minimizes': 2, 'fine-tunes': 1, 'decodes': 1, 'reduces': 1}, ('window', 'automatically'): {'processes': 1, 'predicts': 1, 'increases': 1}, ('states', 'training'): {'a': 4}, ('distribution', 'sequentially'): {'a': 4, 'the': 7, 'subsequently': 1}, ('states', 'therefore'): {'the': 2}, ('recursively', 'processes'): {'the': 4, 'token': 1, 'large': 1, 'semantic': 1}, ('probability', 'trains'): {'on': 6}, ('bigram', 'increases'): {'the': 1, 'co-occurrence': 1, 'millions': 1}, ('iteratively', 'transfer'): {'learning': 4}, ('continuously', 'subsequently'): {'the': 4}, ('tokenizer', 'recursively'): {'encodes': 1, 'represents': 3, 'optimizes': 1, 'diverges': 1, 'evaluates': 1, 'minimizes': 1}, ('model', 'captures'): {'millions': 1, 'language': 1, 'the': 6, 'token': 1, 'word': 2, 'semantic': 1}, ('successfully', 'as'): {'a': 8}, ('word', 'perplexity'): {'measures': 1}, ('parameters', 'transfer'): {'learning': 2}, ('automatically', 'generalizes'): {'semantic': 1, 'the': 4}, ('sequentially', 'consequently'): {'the': 3}, ('weight', 'improves'): {'the': 6, 'sentence': 1, 'linguistic': 1, 'large': 1}, ('bigram', 'optimizes'): {'the': 6, 'word': 1, 'sentence': 1, 'syntactic': 1, 'large': 1, 'statistical': 1}, ('successfully', 'for'): {'example': 8}, ('a', 'powerful'): {'the': 119, 'backpropagation': 7}, ('weight', 'overfits'): {'the': 7, 'co-occurrence': 2, 'word': 1, 'token': 1}, ('generates', 'syntactic'): {'rules': 13}, ('bigram', 'iteratively'): {'models': 1, 'adjusts': 1, 'represents': 1, 'decodes': 1, 'trains': 1}, ('trigram', 'automatically'): {'evaluates': 1, 'generalizes': 1, 'trains': 1, 'updates': 1}, ('probability', 'models'): {'the': 6, 'contextual': 2, 'linguistic': 1, 'sentence': 1}, ('matrices', 'sequentially'): {'a': 4, 'as': 1, 'however': 2, 'the': 5, 'consequently': 1, 'in': 1}, ('significantly', 'perplexity'): {'measures': 3}, ('backpropagation', 'increases'): {'co-occurrence': 2, 'linguistic': 1, 'the': 6, 'syntactic': 1, 'millions': 1}, ('smoothing', 'techniques'): {'help': 88}, ('continuously', 'fine-tunes'): {'the': 2, 'large': 1}, ('information', 'word'): {'embeddings': 1}, ('perplexity', 'probabilistically'): {'minimizes': 1, 'generalizes': 1, 'reduces': 1, 'diverges': 1}, ('patterns', 'data'): {'preprocessing': 5}, ('process', 'outputs'): {'the': 5, 'language': 2, 'large': 1, 'word': 1, 'millions': 1}, ('probabilistically', 'smoothing'): {'techniques': 3}, ('words', 'influence'): {'the': 90}, ('output', 'efficiently'): {'a': 6, 'training': 1, 'the': 4, 'feeding': 1, 'overfits': 2, 'additionally': 1, 'generalizes': 1, 'similarly': 1, 'subsequently': 1, 'learns': 1, 'moreover': 1, 'predicts': 2, 'however': 1, 'decodes': 1}, ('significantly', 'calculates'): {'linguistic': 1, 'millions': 1, 'the': 4, 'word': 1}, ('probabilistically', 'maximizes'): {'the': 3, 'language': 1, 'word': 1}, ('feeding', 'text'): {'into': 99}, ('shallow', 'backpropagation'): {'reduces': 1, 'captures': 1, 'minimizes': 1, 'tokenizes': 1, 'diverges': 1, 'learns': 1, 'represents': 1}, ('data', 'recursively'): {'training': 1, 'the': 2, 'a': 2, 'in': 1, 'cleaning': 1}, ('automatically', 'converges'): {'the': 4}, ('layer', 'effectively'): {'generates': 1, 'predicts': 1, 'decodes': 1}, ('influence', 'the'): {'next': 90}, ('backpropagation', 'iteratively'): {'trains': 3, 'adjusts': 1}, ('input', 'updates'): {'linguistic': 1, 'the': 4, 'large': 1}, ('iteratively', 'in'): {'contrast': 4, 'addition': 3}, ('value', 'subsequently'): {'the': 3}, ('successfully', 'tokenization'): {'is': 2}, ('the', 'sequence'): {'recursively': 6, 'sequentially': 7, 'rapidly': 8, 'gradually': 6, 'samples': 7, 'efficiently': 7, 'maximizes': 5, 'predicts': 19, 'processes': 15, 'increases': 10, 'effectively': 6, 'represents': 18, 'generalizes': 11, 'successfully': 8, 'adjusts': 7, 'decodes': 7, 'diverges': 17, 'overfits': 13, 'converges': 6, 'probabilistically': 7, 'trains': 10, 'captures': 9, 'calculates': 10, 'evaluates': 4, 'statistically': 4, 'models': 10, 'fine-tunes': 10, 'accurately': 2, 'updates': 7, 'generates': 10, 'improves': 13, 'computes': 8, 'tokenizes': 11, 'iteratively': 7, 'outputs': 9, 'significantly': 3, 'optimizes': 2, 'learns': 11, 'minimizes': 8, 'continuously': 9, 'correctly': 7, 'reduces': 8, 'automatically': 7, 'encodes': 4}, ('parameters', 'in'): {'contrast': 3, 'addition': 3}, ('recursively', 'however'): {'the': 5, 'backpropagation': 1}, ('parameters', 'rapidly'): {'the': 8, 'a': 3, 'nevertheless': 1}, ('descent', 'training'): {'a': 2}, ('dataset', 'processes'): {'the': 4, 'co-occurrence': 1, 'syntactic': 1, 'word': 1}, ('recursively', 'nevertheless'): {'the': 5}, ('rate', 'specifically'): {'the': 3}, ('meaning', 'consequently'): {'the': 3, 'backpropagation': 1}, ('the', 'model'): {'significantly': 6, 'the': 40, 'probabilistically': 10, 'for': 112, 'represents': 7, 'a': 17, 'outputs': 8, 'converges': 7, 'tokenizes': 6, 'fine-tunes': 1, 'automatically': 5, 'increases': 2, 'adjusts': 4, 'models': 7, 'decodes': 5, 'accurately': 9, 'efficiently': 7, 'maximizes': 10, 'however': 2, 'sequentially': 4, 'recursively': 6, 'diverges': 8, 'generalizes': 11, 'correctly': 7, 'improves': 4, 'trains': 10, 'furthermore': 2, 'generates': 5, 'samples': 2, 'predicts': 10, 'in': 3, 'reduces': 9, 'minimizes': 7, 'continuously': 4, 'overfits': 5, 'updates': 3, 'calculates': 7, 'processes': 3, 'as': 2, 'effectively': 3, 'encodes': 7, 'computes': 5, 'iteratively': 3, 'evaluates': 6, 'similarly': 2, 'gradually': 3, 'successfully': 6, 'nevertheless': 2, 'backpropagation': 2, 'consequently': 2, 'learns': 3, 'statistically': 3, 'optimizes': 4, 'therefore': 3, 'rapidly': 3, 'moreover': 2, 'additionally': 2, 'captures': 1}, ('continuously', 'as'): {'a': 1}, ('iteratively', 'however'): {'the': 6}, ('embeddings', 'efficiently'): {'transfer': 1, 'the': 12, 'overfitting': 1, 'a': 1, 'furthermore': 2, 'training': 1, 'for': 1}, ('input', 'diverges'): {'the': 4, 'statistical': 1, 'linguistic': 1, 'co-occurrence': 1}, ('structure', 'recursively'): {'a': 4, 'additionally': 1, 'overfitting': 1, 'the': 5, 'however': 1, 'in': 1, 'furthermore': 1}, ('algorithm', 'adjusts'): {'syntactic': 1, 'word': 1, 'the': 3, 'linguistic': 1, 'co-occurrence': 1, 'millions': 1, 'language': 1, 'semantic': 1}, ('parameters', 'however'): {'the': 3}, ('scalable', 'backpropagation'): {'learns': 1, 'predicts': 1, 'calculates': 1}, ('sequentially', 'specifically'): {'the': 4}, ('function', 'automatically'): {'the': 4, 'a': 4, 'improves': 2, 'in': 1, 'consequently': 1, 'however': 1, 'meanwhile': 1, 'increases': 1, 'data': 1}, ('perplexity', 'measures'): {'how': 104}, ('frequencies', 'gradient'): {'descent': 2}, ('size', 'backpropagation'): {'learns': 1, 'probabilistically': 1, 'effectively': 1}, ('matrix', 'recursively'): {'a': 5, 'specifically': 1, 'the': 7, 'for': 1, 'additionally': 1, 'gradient': 1, 'data': 1}, ('significantly', 'outputs'): {'the': 6, 'syntactic': 2}, ('value', 'efficiently'): {'the': 6, 'for': 1, 'in': 1, 'data': 1, 'a': 7, 'nevertheless': 1, 'regularization': 1, 'subsequently': 2}, ('patterns', 'probabilistically'): {'however': 1, 'the': 14, 'backpropagation': 1, 'a': 4, 'meanwhile': 1, 'for': 1, 'additionally': 1}, ('states', 'data'): {'preprocessing': 2}, ('statistically', 'predicts'): {'the': 3, 'linguistic': 1, 'statistical': 1, 'syntactic': 3, 'large': 2, 'contextual': 1, 'semantic': 1}, ('rate', 'sequentially'): {'the': 4, 'additionally': 1, 'a': 2, 'backpropagation': 1}, ('output', 'tokenization'): {'is': 3}, ('trigram', 'rapidly'): {'improves': 2, 'maximizes': 2, 'models': 1, 'optimizes': 1, 'computes': 1, 'trains': 2}, ('embeddings', 'as'): {'a': 4}, ('parameters', 'statistically'): {'training': 1, 'a': 3, 'the': 8, 'cross': 1}, ('capture', 'local'): {'word': 104}, ('backpropagation', 'rapidly'): {'decodes': 1, 'reduces': 1, 'increases': 1, 'generates': 1, 'trains': 1, 'captures': 1, 'maximizes': 1}, ('correctly', 'similarly'): {'the': 6}, ('gradient', 'generalizes'): {'the': 2, 'millions': 1, 'sentence': 1}, ('help', 'language'): {'models': 88}, ('n-gram', 'converges'): {'sentence': 1, 'word': 1, 'linguistic': 1, 'co-occurrence': 3, 'millions': 1, 'syntactic': 1, 'large': 1, 'the': 1}, ('embeddings', 'for'): {'example': 3}, ('perplexity', 'represents'): {'the': 8, 'sentence': 1, 'word': 2}, ('correctly', 'bigram'): {'and': 7}, ('loss', 'consequently'): {'the': 5}, ('window', 'statistically'): {'computes': 1, 'tokenizes': 1, 'improves': 1, 'predicts': 1, 'maximizes': 1}, ('rules', 'successfully'): {'the': 5, 'therefore': 1, 'regularization': 1, 'however': 1, 'furthermore': 1}, ('model', 'generalizes'): {'linguistic': 1, 'sentence': 2, 'the': 14, 'statistical': 2, 'language': 1, 'contextual': 1, 'word': 1}, ('function', 'transfer'): {'learning': 1}, ('word', 'cross'): {'entropy': 2}, ('output', 'gradient'): {'descent': 3}, ('features', 'effectively'): {'the': 5, 'specifically': 1, 'a': 5, 'cross': 1, 'bigram': 1, 'furthermore': 1}, ('value', 'as'): {'a': 5}, ('algorithm', 'fine-tunes'): {'linguistic': 1, 'the': 7, 'large': 1, 'token': 1}, ('output', 'tokenizes'): {'token': 1, 'the': 4, 'co-occurrence': 1, 'contextual': 2, 'syntactic': 1}, ('gradually', 'consequently'): {'the': 3}, ('meaning', 'subsequently'): {'the': 1}, ('prediction', 'consequently'): {'the': 1}, ('distribution', 'overfitting'): {'occurs': 2}, ('significantly', 'cross'): {'entropy': 2}, ('errors', 'consequently'): {'the': 1}, ('value', 'for'): {'example': 1}, ('evaluates', 'semantic'): {'meaning': 20}, ('process', 'adjusts'): {'linguistic': 1, 'the': 7, 'token': 1, 'semantic': 1, 'co-occurrence': 1}, ('continuous', 'space'): {'a': 20, 'the': 44, 'nevertheless': 3, 'for': 4, 'moreover': 1, 'however': 3, 'therefore': 2, 'furthermore': 3, 'in': 2, 'subsequently': 4, 'additionally': 1, 'backpropagation': 1}, ('states', 'furthermore'): {'the': 3}, ('effectively', 'captures'): {'linguistic': 1, 'syntactic': 1, 'large': 1, 'the': 1}, ('trigram', 'statistically'): {'represents': 1, 'decodes': 1, 'generalizes': 1, 'adjusts': 2, 'tokenizes': 1, 'encodes': 1, 'reduces': 1}, ('output', 'learns'): {'from': 13}, ('output', 'generates'): {'the': 5, 'co-occurrence': 1, 'word': 2, 'large': 1, 'statistical': 1}, ('attention', 'mechanism'): {'models': 14, 'reduces': 12, 'efficiently': 9, 'maximizes': 9, 'evaluates': 8, 'fine-tunes': 11, 'converges': 8, 'computes': 8, 'tokenizes': 14, 'gradually': 6, 'successfully': 5, 'minimizes': 7, 'generates': 18, 'generalizes': 15, 'improves': 11, 'probabilistically': 6, 'adjusts': 5, 'predicts': 17, 'accurately': 8, 'outputs': 8, 'captures': 8, 'automatically': 9, 'statistically': 9, 'trains': 7, 'updates': 6, 'calculates': 9, 'encodes': 3, 'rapidly': 4, 'processes': 11, 'effectively': 8, 'overfits': 8, 'decodes': 7, 'optimizes': 2, 'sequentially': 9, 'continuously': 5, 'significantly': 6, 'iteratively': 7, 'diverges': 6, 'represents': 9, 'samples': 7, 'learns': 5, 'increases': 6, 'recursively': 3, 'correctly': 1}, ('automatically', 'predicts'): {'syntactic': 2, 'the': 10, 'sentence': 1, 'linguistic': 1, 'semantic': 2, 'statistical': 1, 'word': 2, 'language': 1}, ('converges', 'large'): {'amounts': 17}, ('algorithm', 'efficiently'): {'converges': 1, 'diverges': 1, 'predicts': 1, 'minimizes': 1, 'maximizes': 1, 'evaluates': 1, 'outputs': 1, 'trains': 1}, ('embeddings', 'tokenization'): {'is': 3}, ('sequence', 'sequentially'): {'maximizes': 1, 'converges': 1, 'minimizes': 1, 'learns': 2, 'evaluates': 1, 'encodes': 1}, ('distribution', 'smoothing'): {'techniques': 2}, ('rapidly', 'encodes'): {'the': 1}, ('researcher', 'decodes'): {'the': 7, 'contextual': 1, 'co-occurrence': 2, 'word': 1, 'sentence': 1, 'large': 1}, ('correctly', 'perplexity'): {'measures': 3}, ('diverges', 'large'): {'amounts': 16}, ('system', 'captures'): {'language': 1, 'word': 2, 'token': 1, 'the': 6, 'sentence': 1}, ('optimizer', 'gradually'): {'fine-tunes': 1, 'increases': 1, 'converges': 1, 'adjusts': 2, 'optimizes': 2, 'predicts': 1, 'samples': 1, 'processes': 1, 'minimizes': 1}, ('probability', 'minimizes'): {'the': 5, 'token': 1, 'millions': 2, 'word': 1, 'language': 1}, ('dataset', 'significantly'): {'samples': 1, 'reduces': 1, 'decodes': 1}, ('the', 'optimizer'): {'samples': 11, 'minimizes': 10, 'improves': 7, 'gradually': 11, 'fine-tunes': 10, 'optimizes': 16, 'maximizes': 9, 'automatically': 8, 'decodes': 9, 'updates': 15, 'encodes': 7, 'iteratively': 8, 'outputs': 11, 'rapidly': 5, 'overfits': 10, 'increases': 5, 'efficiently': 8, 'diverges': 11, 'continuously': 7, 'correctly': 5, 'predicts': 17, 'probabilistically': 6, 'tokenizes': 9, 'calculates': 6, 'models': 2, 'processes': 11, 'generates': 11, 'effectively': 4, 'learns': 8, 'recursively': 6, 'converges': 13, 'significantly': 4, 'trains': 8, 'accurately': 6, 'adjusts': 8, 'reduces': 12, 'captures': 5, 'represents': 6, 'computes': 6, 'sequentially': 6, 'generalizes': 7, 'successfully': 9, 'statistically': 8, 'evaluates': 5}, ('distribution', 'continuously'): {'however': 1, 'for': 1, 'the': 6, 'a': 3, 'backpropagation': 1, 'cross': 1, 'in': 1, 'data': 1}, ('space', 'therefore'): {'the': 1, 'backpropagation': 1}, ('frequencies', 'accurately'): {'a': 3, 'similarly': 1, 'the': 8, 'consequently': 1, 'additionally': 1, 'nevertheless': 1}, ('features', 'the'): {'dataset': 2, 'context': 4, 'optimizer': 5, 'loss': 4, 'language': 4, 'model': 4, 'weight': 2, 'prediction': 4, 'researcher': 2, 'softmax': 3, 'output': 4, 'trigram': 1, 'evaluation': 1, 'vocabulary': 4, 'attention': 5, 'tokenizer': 6, 'text': 5, 'gradient': 5, 'system': 3, 'perplexity': 2, 'n-gram': 2, 'architecture': 2, 'sequence': 3, 'training': 2, 'neural': 1, 'algorithm': 2, 'input': 1, 'frequency': 1, 'bigram': 2, 'embedding': 1, 'probability': 2, 'corpus': 1}, ('tokenizes', 'linguistic'): {'features': 18}, ('increases', 'millions'): {'of': 17}, ('correctly', 'calculates'): {'the': 4, 'word': 1}, ('function', 'in'): {'contrast': 1, 'addition': 1}, ('gradient', 'samples'): {'the': 3, 'co-occurrence': 1, 'contextual': 2, 'syntactic': 1}, ('embeddings', 'gradient'): {'descent': 1}, ('rapidly', 'minimizes'): {'the': 6, 'language': 1}, ('probabilistically', 'diverges'): {'sentence': 1, 'language': 1, 'statistical': 1, 'co-occurrence': 1, 'word': 1}, ('embeddings', 'map'): {'tokens': 88}, ('layer', 'evaluates'): {'word': 2, 'token': 1, 'the': 5, 'large': 1}, ('statistically', 'feeding'): {'diverse': 6}, ('states', 'probabilistically'): {'the': 8, 'a': 3, 'transfer': 1, 'subsequently': 1}, ('function', 'rapidly'): {'decodes': 1, 'overfits': 2, 'reduces': 2, 'therefore': 1, 'the': 7, 'trains': 1, 'a': 1, 'in': 1, 'feeding': 1, 'updates': 1, 'minimizes': 1, 'generates': 1, 'evaluates': 1, 'specifically': 2, 'computes': 1, 'maximizes': 1, 'subsequently': 1, 'adjusts': 1}, ('iteratively', 'moreover'): {'the': 3}, ('value', 'tokenization'): {'is': 2}, ('loss', 'subsequently'): {'the': 2}, ('trains', 'on'): {'the': 190, 'syntactic': 18, 'statistical': 19, 'word': 29, 'token': 14, 'language': 12, 'large': 13, 'millions': 18, 'sentence': 8, 'co-occurrence': 13, 'semantic': 14, 'linguistic': 17, 'contextual': 12}, ('text', 'bigram'): {'and': 2}, ('model', 'samples'): {'semantic': 1, 'the': 5, 'co-occurrence': 1, 'sentence': 1, 'contextual': 1, 'millions': 1, 'token': 1, 'language': 1}, ('size', 'feeding'): {'diverse': 7}, ('vocabulary', 'maximizes'): {'contextual': 2, 'millions': 1, 'statistical': 1, 'sentence': 1, 'the': 1}, ('parameters', 'moreover'): {'the': 3, 'backpropagation': 1}, ('corpus', 'reduces'): {'the': 3, 'statistical': 1, 'large': 1}, ('architecture', 'reduces'): {'the': 10, 'contextual': 1}, ('resources', 'a'): {'autoregressive': 4, 'small': 4, 'generative': 2, 'discriminative': 3, 'efficient': 2, 'statistical': 1, 'powerful': 1, 'robust': 2, 'large': 1, 'transformer-based': 1, 'recurrent': 1, 'deep': 1, 'scalable': 1}, ('process', 'fine-tunes'): {'the': 5, 'contextual': 1, 'linguistic': 1}, ('vocabulary', 'continuously'): {'predicts': 1, 'models': 1}, ('model', 'the'): {'model': 6, 'loss': 7, 'system': 8, 'n-gram': 1, 'attention': 3, 'context': 6, 'architecture': 3, 'weight': 4, 'perplexity': 4, 'input': 4, 'sequence': 4, 'text': 10, 'language': 3, 'gradient': 11, 'probability': 6, 'neural': 4, 'prediction': 4, 'algorithm': 7, 'tokenizer': 2, 'evaluation': 7, 'trigram': 5, 'researcher': 5, 'training': 2, 'output': 5, 'corpus': 3, 'embedding': 3, 'vocabulary': 2, 'dataset': 3, 'optimizer': 2, 'bigram': 1}, ('text', 'optimizes'): {'the': 4, 'contextual': 1, 'syntactic': 1, 'semantic': 1}, ('accurately', 'training'): {'a': 4}, ('architecture', 'tokenizes'): {'the': 4, 'contextual': 1, 'syntactic': 1, 'token': 1}, ('furthermore', 'the'): {'language': 7, 'training': 8, 'loss': 6, 'trigram': 6, 'perplexity': 7, 'context': 4, 'dataset': 6, 'researcher': 6, 'system': 12, 'evaluation': 3, 'probability': 6, 'corpus': 4, 'neural': 11, 'gradient': 7, 'algorithm': 8, 'prediction': 7, 'weight': 11, 'output': 6, 'model': 8, 'tokenizer': 5, 'embedding': 11, 'architecture': 8, 'bigram': 9, 'optimizer': 1, 'vocabulary': 5, 'text': 4, 'sequence': 8, 'n-gram': 7, 'attention': 2, 'input': 1}, ('accurately', 'tokenizes'): {'the': 1, 'statistical': 1, 'token': 1}, ('terms', 'feeding'): {'diverse': 1}, ('accurately', 'therefore'): {'the': 4}, ('function', 'however'): {'the': 2}, ('network', 'fine-tunes'): {'token': 1, 'language': 1, 'large': 2, 'the': 3, 'syntactic': 2, 'contextual': 1}, ('output', 'accurately'): {'represents': 1, 'the': 6, 'a': 2, 'backpropagation': 1, 'moreover': 1, 'smoothing': 1, 'increases': 1}, ('frequencies', 'data'): {'preprocessing': 1}, ('gradient', 'improves'): {'contextual': 1, 'the': 8, 'language': 1, 'word': 1, 'co-occurrence': 1, 'large': 1, 'linguistic': 1}, ('gradient', 'overfits'): {'language': 2, 'word': 1, 'linguistic': 3, 'the': 3, 'syntactic': 1, 'contextual': 1, 'semantic': 1, 'millions': 1}, ('probabilistically', 'converges'): {'sentence': 2, 'millions': 1, 'the': 2, 'word': 1, 'language': 1, 'co-occurrence': 1}, ('gradually', 'specifically'): {'the': 8}, ('sequences', 'regularization'): {'techniques': 1}, ('perplexity', 'gradually'): {'processes': 1, 'updates': 1, 'predicts': 1, 'represents': 1, 'encodes': 1, 'adjusts': 1, 'converges': 1, 'improves': 1, 'increases': 1}, ('rapidly', 'overfitting'): {'occurs': 4}, ('subsequently', 'backpropagation'): {'captures': 1, 'models': 1, 'fine-tunes': 1, 'optimizes': 1, 'trains': 1, 'outputs': 1}, ('model', 'improves'): {'sentence': 1, 'the': 9, 'its': 121, 'millions': 1, 'statistical': 1, 'co-occurrence': 1, 'word': 1}, ('sequentially', 'encodes'): {'the': 4, 'co-occurrence': 1, 'linguistic': 1}, ('model', 'overfits'): {'the': 5, 'co-occurrence': 1, 'word': 1, 'token': 1, 'sentence': 1, 'semantic': 1, 'large': 1}, ('vocabulary', 'captures'): {'the': 5, 'contextual': 1, 'semantic': 1, 'token': 1}, ('significantly', 'adjusts'): {'token': 1, 'the': 5, 'millions': 1, 'syntactic': 1}, ('dataset', 'trains'): {'on': 6}, ('prediction', 'fine-tunes'): {'semantic': 1, 'the': 6, 'word': 1, 'millions': 1, 'linguistic': 1, 'syntactic': 2}, ('function', 'statistically'): {'evaluates': 1, 'maximizes': 1, 'backpropagation': 1, 'training': 1, 'however': 1, 'overfits': 1, 'therefore': 1, 'increases': 1, 'in': 2, 'computes': 1, 'the': 1, 'represents': 1, 'consequently': 1, 'a': 2, 'bigram': 1, 'encodes': 1}, ('matrices', 'regularization'): {'techniques': 2}, ('probability', 'maximizes'): {'the': 5, 'large': 1}, ('descent', 'furthermore'): {'the': 1}, ('mechanism', 'reduces'): {'word': 1, 'large': 1, 'the': 8, 'linguistic': 1, 'millions': 1}, ('input', 'predicts'): {'the': 7, 'word': 2, 'millions': 1, 'co-occurrence': 1, 'sentence': 1, 'token': 2, 'large': 1, 'statistical': 1, 'linguistic': 2, 'language': 1}, ('updates', 'language'): {'patterns': 15}, ('text', 'perplexity'): {'measures': 4}, ('gracefully', 'specifically'): {'the': 2}, ('n-gram', 'predicts'): {'the': 10, 'word': 1, 'linguistic': 1, 'sentence': 1, 'syntactic': 1, 'semantic': 1}, ('probability', 'continuously'): {'represents': 1, 'converges': 1, 'samples': 1, 'learns': 1, 'minimizes': 1}, ('sequences', 'successfully'): {'meanwhile': 1, 'a': 3, 'the': 7, 'subsequently': 1, 'in': 1, 'therefore': 1}, ('rapidly', 'maximizes'): {'semantic': 1, 'linguistic': 1, 'the': 4, 'syntactic': 1}, ('text', 'calculates'): {'the': 10, 'syntactic': 2, 'sentence': 2, 'word': 2, 'language': 1}, ('weights', 'iteratively'): {'based': 104}, ('output', 'data'): {'preprocessing': 2}, ('significantly', 'subsequently'): {'the': 11}, ('correctly', 'outputs'): {'the': 4, 'statistical': 1, 'sentence': 1}, ('researcher', 'sequentially'): {'processes': 1, 'trains': 1, 'models': 1, 'improves': 1, 'overfits': 1, 'evaluates': 1, 'diverges': 1, 'increases': 1}, ('evaluates', 'contextual'): {'information': 17}, ('matrices', 'successfully'): {'the': 4, 'consequently': 1, 'as': 1, 'a': 1}, ('structure', 'consequently'): {'the': 2}, ('descent', 'effectively'): {'meanwhile': 1, 'a': 3, 'the': 3, 'additionally': 1}, ('efficiently', 'backpropagation'): {'learns': 1, 'correctly': 2, 'diverges': 2, 'models': 1, 'probabilistically': 1}, ('sequence', 'encodes'): {'statistical': 1, 'the': 3}, ('pre-trained', 'models'): {'to': 104}, ('embeddings', 'accurately'): {'a': 1, 'cleaning': 1, 'the': 5, 'additionally': 1, 'meanwhile': 1}, ('optimizer', 'calculates'): {'large': 1, 'word': 1, 'the': 2, 'millions': 1, 'co-occurrence': 1}, ('rules', 'correctly'): {'nevertheless': 1, 'the': 4, 'subsequently': 1, 'cross': 1}, ('evaluates', 'the'): {'corpus': 20, 'hidden': 8, 'bias': 12, 'cross': 11, 'batch': 11, 'gradient': 12, 'softmax': 10, 'probability': 15, 'next': 10, 'vocabulary': 8, 'loss': 17, 'weight': 7, 'learning': 7, 'activation': 11, 'training': 13}, ('statistically', 'processes'): {'large': 1, 'syntactic': 1, 'co-occurrence': 1, 'the': 1}, ('encodes', 'statistical'): {'patterns': 14}, ('weight', 'rapidly'): {'minimizes': 1, 'generalizes': 1, 'fine-tunes': 1, 'learns': 1, 'calculates': 1, 'decodes': 1, 'computes': 1}, ('layer', 'increases'): {'the': 5, 'language': 1, 'semantic': 2, 'word': 1}, ('matrix', 'consequently'): {'the': 2}, ('resources', 'similarly'): {'the': 2}, ('effectively', 'generalizes'): {'contextual': 1, 'word': 2, 'language': 2, 'the': 1}, ('significantly', 'fine-tunes'): {'the': 6, 'syntactic': 1, 'token': 1, 'large': 1}, ('sequence', 'minimizes'): {'the': 5, 'sentence': 1, 'syntactic': 2}, ('rapidly', 'regularization'): {'techniques': 3}, ('rate', 'smoothing'): {'techniques': 3}, ('carefully', 'curated'): {'datasets': 109}, ('word', 'efficiently'): {'the': 8, 'a': 2, 'as': 1, 'specifically': 1, 'data': 1, 'in': 1, 'word': 1, 'for': 1, 'meanwhile': 1}, ('algorithm', 'generates'): {'the': 7, 'token': 1, 'contextual': 1}, ('token', 'sequences'): {'the': 78, 'meanwhile': 2, 'sequentially': 6, 'successfully': 14, 'recursively': 12, 'gradually': 20, 'correctly': 9, 'probabilistically': 7, 'a': 40, 'statistically': 14, 'similarly': 1, 'effectively': 10, 'continuously': 11, 'accurately': 12, 'backpropagation': 2, 'automatically': 11, 'significantly': 8, 'feeding': 1, 'consequently': 3, 'iteratively': 11, 'nevertheless': 3, 'tokenization': 2, 'therefore': 2, 'efficiently': 12, 'transfer': 2, 'additionally': 3, 'rapidly': 8, 'as': 3, 'in': 7, 'cleaning': 1, 'perplexity': 2, 'cross': 2, 'training': 2, 'smoothing': 1, 'however': 4, 'for': 2, 'specifically': 2, 'bigram': 1, 'moreover': 3, 'subsequently': 5, 'regularization': 1, 'overfitting': 1, 'gradient': 1}, ('tokenizer', 'sequentially'): {'minimizes': 2, 'predicts': 1, 'outputs': 2, 'reduces': 1, 'maximizes': 1, 'improves': 1}, ('on', 'word'): {'frequencies': 12, 'embeddings': 17}, ('data', 'specifically'): {'the': 3}, ('layer', 'optimizes'): {'the': 4, 'language': 1, 'word': 2, 'semantic': 1, 'co-occurrence': 1}, ('many', 'previous'): {'words': 90}, ('system', 'generalizes'): {'the': 4, 'statistical': 4, 'co-occurrence': 1, 'contextual': 1, 'millions': 1}, ('layer', 'iteratively'): {'increases': 1, 'captures': 1, 'optimizes': 2, 'fine-tunes': 1}, ('than', 'learning'): {'patterns': 104}, ('frequencies', 'probabilistically'): {'a': 3, 'furthermore': 1, 'subsequently': 1, 'the': 3, 'bigram': 1, 'meanwhile': 1, 'gradient': 1, 'smoothing': 1}, ('sequentially', 'computes'): {'language': 3, 'the': 4, 'statistical': 1}, ('patterns', 'gradually'): {'smoothing': 1, 'the': 15, 'moreover': 1, 'cleaning': 1, 'a': 7, 'specifically': 1, 'therefore': 1, 'perplexity': 1, 'as': 1, 'furthermore': 2, 'in': 1}, ('calculates', 'millions'): {'of': 17}, ('language', 'patterns'): {'sequentially': 14, 'the': 86, 'iteratively': 14, 'word': 3, 'a': 44, 'gradually': 20, 'recursively': 9, 'correctly': 15, 'furthermore': 6, 'feeding': 2, 'meanwhile': 1, 'data': 4, 'effectively': 16, 'automatically': 14, 'successfully': 10, 'bigram': 3, 'continuously': 11, 'rapidly': 10, 'as': 4, 'moreover': 3, 'consequently': 2, 'smoothing': 1, 'perplexity': 1, 'in': 4, 'statistically': 10, 'accurately': 18, 'efficiently': 14, 'probabilistically': 11, 'subsequently': 4, 'significantly': 14, 'training': 2, 'additionally': 1, 'nevertheless': 1, 'gradient': 2, 'overfitting': 1, 'transfer': 5, 'cross': 3, 'therefore': 3, 'cleaning': 4, 'specifically': 2, 'similarly': 1, 'tokenization': 1, 'however': 2}, ('perplexity', 'calculates'): {'the': 7, 'contextual': 1, 'syntactic': 1}, ('its', 'generalization'): {'ability': 121}, ('dependencies', 'in'): {'natural': 104}, ('outputs', 'sentence'): {'structure': 12}, ('function', 'moreover'): {'the': 2}, ('word', 'as'): {'a': 2}, ('weight', 'statistically'): {'calculates': 1, 'encodes': 1, 'generalizes': 1, 'learns': 1, 'processes': 1}, ('automatically', 'processes'): {'the': 4, 'millions': 1, 'sentence': 1, 'token': 1}, ('features', 'meanwhile'): {'the': 4}, ('text', 'outputs'): {'the': 4, 'word': 1, 'language': 1, 'large': 1, 'sentence': 1}, ('accurately', 'data'): {'preprocessing': 5}, ('rate', 'regularization'): {'techniques': 2}, ('system', 'converges'): {'the': 6, 'word': 1, 'large': 1, 'sentence': 1}, ('data', 'sequentially'): {'the': 12, 'a': 2}, ('word', 'for'): {'example': 2}, ('bigram', 'efficiently'): {'learns': 2, 'generates': 1, 'computes': 1, 'trains': 1, 'fine-tunes': 1}, ('metric', 'decodes'): {'the': 6, 'statistical': 1, 'sentence': 1}, ('output', 'probabilistically'): {'the': 5, 'backpropagation': 1, 'diverges': 1, 'meanwhile': 1, 'computes': 1, 'a': 2, 'training': 1, 'improves': 1, 'adjusts': 1, 'generates': 1, 'processes': 1}, ('significantly', 'as'): {'a': 6}, ('sequence', 'computes'): {'the': 5, 'token': 1, 'syntactic': 1, 'contextual': 1}, ('moreover', 'backpropagation'): {'generates': 1, 'samples': 1, 'minimizes': 1, 'outputs': 1, 'learns': 1, 'represents': 1, 'generalizes': 1, 'fine-tunes': 1, 'computes': 1, 'updates': 1}, ('patterns', 'bigram'): {'and': 8}, ('probabilistically', 'predicts'): {'the': 5, 'semantic': 1, 'word': 2, 'token': 1, 'sentence': 1, 'large': 1}, ('structure', 'specifically'): {'the': 1}, ('improves', 'word'): {'embeddings': 11, 'frequencies': 9}, ('optimizer', 'outputs'): {'syntactic': 1, 'the': 7, 'sentence': 1, 'word': 1, 'statistical': 1}, ('sequentially', 'regularization'): {'techniques': 1}, ('significantly', 'for'): {'example': 3}, ('effectively', 'samples'): {'syntactic': 1, 'the': 1, 'contextual': 1, 'word': 1}, ('algorithm', 'accurately'): {'fine-tunes': 1, 'processes': 1, 'represents': 1, 'optimizes': 1}, ('rate', 'successfully'): {'the': 4, 'a': 2, 'for': 1, 'similarly': 1}, ('effectively', 'the'): {'trigram': 12, 'model': 3, 'neural': 1, 'architecture': 5, 'training': 7, 'context': 15, 'n-gram': 5, 'optimizer': 5, 'system': 3, 'bigram': 8, 'perplexity': 5, 'output': 6, 'attention': 5, 'gradient': 6, 'weight': 6, 'prediction': 4, 'vocabulary': 6, 'researcher': 5, 'sequence': 5, 'corpus': 2, 'probability': 6, 'tokenizer': 4, 'loss': 3, 'input': 2, 'evaluation': 3, 'frequency': 5, 'algorithm': 3, 'language': 4, 'dataset': 1, 'text': 3, 'softmax': 2, 'embedding': 4}, ('gradually', 'encodes'): {'linguistic': 1, 'the': 2, 'sentence': 2, 'contextual': 1, 'statistical': 1}, ('researcher', 'encodes'): {'linguistic': 2, 'the': 7, 'contextual': 3, 'sentence': 1, 'word': 2}, ('matrix', 'specifically'): {'the': 6}, ('efficiently', 'feeding'): {'diverse': 3}, ('metric', 'trains'): {'on': 12}, ('rules', 'backpropagation'): {'statistically': 1, 'trains': 1, 'outputs': 1, 'sequentially': 1}, ('the', 'weight'): {'improves': 9, 'models': 14, 'matrix': 401, 'generates': 12, 'converges': 9, 'effectively': 8, 'increases': 11, 'samples': 10, 'generalizes': 12, 'minimizes': 11, 'statistically': 5, 'predicts': 19, 'optimizes': 10, 'trains': 14, 'reduces': 14, 'successfully': 5, 'accurately': 10, 'rapidly': 7, 'probabilistically': 7, 'diverges': 8, 'represents': 9, 'captures': 13, 'maximizes': 9, 'adjusts': 10, 'decodes': 11, 'correctly': 6, 'significantly': 5, 'fine-tunes': 14, 'calculates': 7, 'outputs': 7, 'recursively': 5, 'evaluates': 13, 'efficiently': 9, 'tokenizes': 9, 'learns': 6, 'updates': 8, 'computes': 12, 'gradually': 6, 'sequentially': 5, 'iteratively': 8, 'encodes': 11, 'overfits': 11, 'processes': 10, 'continuously': 5, 'automatically': 2}, ('text', 'cross'): {'entropy': 2}, ('maximizes', 'word'): {'embeddings': 12, 'frequencies': 7}, ('evaluates', 'token'): {'sequences': 18}, ('corpus', 'furthermore'): {'the': 3}, ('rapidly', 'updates'): {'syntactic': 1, 'co-occurrence': 1, 'the': 2}, ('the', 'loss'): {'function': 378, 'value': 396}, ('researcher', 'minimizes'): {'the': 8, 'language': 1, 'statistical': 1}, ('structure', 'sequentially'): {'a': 2, 'the': 7, 'therefore': 1, 'smoothing': 1}, ('successfully', 'represents'): {'semantic': 1, 'the': 1, 'syntactic': 2}, ('effectively', 'improves'): {'the': 1, 'syntactic': 1, 'large': 1, 'millions': 2}, ('tokenizes', 'semantic'): {'meaning': 15}, ('effectively', 'overfits'): {'the': 7, 'language': 1, 'semantic': 1, 'word': 1}, ('modeling', 'additionally'): {'the': 5}, ('correctly', 'adjusts'): {'semantic': 1, 'the': 2, 'contextual': 1, 'statistical': 1}, ('adjusts', 'token'): {'sequences': 10}, ('metric', 'models'): {'the': 9, 'language': 1, 'word': 1}, ('vocabulary', 'converges'): {'millions': 1, 'the': 7, 'language': 1}, ('gradient', 'automatically'): {'updates': 2, 'computes': 1, 'adjusts': 1, 'predicts': 1}, ('cross', 'entropy'): {'loss': 546}, ('training', 'data'): {'the': 74, 'rapidly': 16, 'gradually': 11, 'significantly': 10, 'rather': 104, 'probabilistically': 10, 'effectively': 18, 'additionally': 7, 'for': 5, 'correctly': 17, 'continuously': 9, 'iteratively': 12, 'recursively': 7, 'perplexity': 3, 'training': 2, 'a': 44, 'moreover': 5, 'regularization': 2, 'gradient': 5, 'accurately': 18, 'furthermore': 4, 'nevertheless': 5, 'statistically': 11, 'sequentially': 14, 'as': 1, 'automatically': 8, 'similarly': 2, 'therefore': 2, 'in': 4, 'specifically': 3, 'subsequently': 2, 'successfully': 10, 'word': 3, 'efficiently': 8, 'cross': 2, 'consequently': 2, 'cleaning': 2, 'transfer': 1, 'tokenization': 3, 'however': 3, 'backpropagation': 2, 'smoothing': 2, 'feeding': 1, 'meanwhile': 1, 'bigram': 2}, ('sequences', 'correctly'): {'the': 3, 'consequently': 1, 'a': 1, 'moreover': 1, 'training': 1, 'overfitting': 1, 'similarly': 1}, ('significantly', 'tokenization'): {'is': 2}, ('patterns', 'perplexity'): {'measures': 3}, ('perplexity', 'outputs'): {'the': 5, 'statistical': 1, 'language': 1, 'syntactic': 1, 'co-occurrence': 1}, ('probability', 'diverges'): {'language': 2, 'millions': 1, 'the': 5, 'co-occurrence': 1, 'linguistic': 2, 'contextual': 1}, ('word', 'gradient'): {'descent': 2}, ('automatically', 'however'): {'the': 6}, ('tokenizer', 'encodes'): {'the': 3, 'millions': 1, 'large': 1, 'co-occurrence': 1, 'statistical': 1, 'language': 1}, ('matrix', 'sequentially'): {'a': 5, 'in': 2, 'word': 1, 'nevertheless': 1, 'additionally': 1, 'the': 1}, ('model', 'automatically'): {'tokenizes': 1, 'evaluates': 1, 'encodes': 1, 'learns': 1, 'predicts': 4, 'captures': 2, 'reduces': 2, 'converges': 1}, ('corpus', 'effectively'): {'the': 7, 'as': 1, 'outputs': 1, 'a': 6, 'transfer': 1, 'computes': 1, 'perplexity': 1, 'generates': 1, 'generalizes': 1, 'encodes': 1, 'learns': 1, 'data': 1, 'additionally': 1, 'cleaning': 1, 'adjusts': 1, 'samples': 1, 'subsequently': 1}, ('system', 'improves'): {'millions': 1, 'co-occurrence': 1, 'the': 3, 'sentence': 1}, ('system', 'overfits'): {'the': 4, 'large': 1}, ('terms', 'significantly'): {'moreover': 1, 'consequently': 1, 'similarly': 2, 'a': 4, 'perplexity': 1, 'the': 7, 'word': 1, 'however': 1, 'cross': 1}, ('input', 'processes'): {'the': 3, 'millions': 1, 'linguistic': 1, 'semantic': 2}, ('words', 'the'): {'loss': 4, 'weight': 4, 'optimizer': 2, 'gradient': 1, 'tokenizer': 3, 'n-gram': 2, 'probability': 3, 'context': 1, 'language': 3, 'output': 2, 'prediction': 2, 'attention': 2, 'embedding': 1, 'training': 2, 'bigram': 1, 'corpus': 1, 'input': 3, 'system': 3, 'sequence': 2, 'text': 1, 'model': 1, 'researcher': 1, 'perplexity': 2, 'algorithm': 2, 'dataset': 1}, ('automatically', 'nevertheless'): {'the': 4}, ('iteratively', 'reduces'): {'the': 6, 'word': 1, 'token': 2, 'co-occurrence': 1}, ('rapidly', 'diverges'): {'the': 1, 'large': 2, 'sentence': 1, 'semantic': 2, 'co-occurrence': 1}, ('evaluation', 'metric'): {'predicts': 19, 'correctly': 7, 'trains': 12, 'encodes': 13, 'captures': 10, 'improves': 12, 'maximizes': 8, 'updates': 15, 'represents': 9, 'overfits': 7, 'rapidly': 9, 'tokenizes': 9, 'optimizes': 13, 'continuously': 3, 'decodes': 8, 'significantly': 13, 'evaluates': 11, 'calculates': 8, 'computes': 4, 'outputs': 12, 'samples': 7, 'successfully': 8, 'generates': 8, 'converges': 7, 'learns': 15, 'minimizes': 8, 'effectively': 6, 'sequentially': 6, 'generalizes': 10, 'iteratively': 5, 'fine-tunes': 6, 'efficiently': 10, 'probabilistically': 6, 'processes': 7, 'gradually': 4, 'adjusts': 10, 'increases': 4, 'automatically': 8, 'recursively': 5, 'accurately': 6, 'models': 11, 'diverges': 6, 'reduces': 5, 'statistically': 5}, ('n-gram', 'processes'): {'the': 7, 'large': 3, 'contextual': 1, 'word': 2}, ('sequence', 'successfully'): {'fine-tunes': 2, 'diverges': 1, 'outputs': 1, 'predicts': 1, 'samples': 1, 'models': 1, 'improves': 1}, ('features', 'transfer'): {'learning': 4}, ('correctly', 'subsequently'): {'the': 6, 'backpropagation': 1}, ('optimizes', 'sentence'): {'structure': 11}, ('iteratively', 'training'): {'a': 5}, ('network', 'computes'): {'language': 1, 'the': 5, 'syntactic': 1}, ('tokenizer', 'minimizes'): {'the': 3, 'large': 1, 'co-occurrence': 1, 'token': 1, 'linguistic': 1}, ('parameters', 'training'): {'a': 3}, ('parameters', 'therefore'): {'the': 2}, ('information', 'the'): {'n-gram': 2, 'attention': 5, 'context': 6, 'vocabulary': 6, 'researcher': 7, 'training': 7, 'weight': 1, 'gradient': 3, 'perplexity': 2, 'probability': 3, 'evaluation': 5, 'system': 3, 'input': 2, 'optimizer': 2, 'algorithm': 1, 'language': 2, 'corpus': 3, 'embedding': 1, 'loss': 1, 'neural': 5, 'tokenizer': 2, 'sequence': 2, 'dataset': 4, 'softmax': 1, 'bigram': 2, 'prediction': 5, 'frequency': 2, 'text': 1, 'trigram': 1}, ('states', 'bigram'): {'and': 4}, ('samples', 'syntactic'): {'rules': 13}, ('probability', 'converges'): {'the': 4, 'token': 1, 'co-occurrence': 1}, ('training', 'corpus'): {'in': 1, 'a': 22, 'the': 44, 'therefore': 1, 'however': 3, 'additionally': 2, 'subsequently': 3, 'meanwhile': 3, 'for': 1, 'similarly': 1, 'as': 4, 'moreover': 2, 'nevertheless': 3, 'specifically': 2}, ('captures', 'token'): {'sequences': 13}, ('window', 'reduces'): {'the': 5, 'semantic': 1, 'co-occurrence': 1, 'syntactic': 1}, ('gradually', 'computes'): {'word': 2, 'the': 2, 'sentence': 1, 'token': 1}, ('prediction', 'computes'): {'the': 4, 'co-occurrence': 1}, ('successfully', 'a'): {'accurate': 4, 'deep': 3, 'large': 4, 'robust': 6, 'powerful': 4, 'bidirectional': 2, 'transformer-based': 3, 'discriminative': 2, 'pre-trained': 3, 'efficient': 7, 'neural': 4, 'shallow': 5, 'scalable': 5, 'autoregressive': 4, 'fine-tuned': 4, 'lightweight': 4, 'recurrent': 3, 'statistical': 7, 'generative': 4, 'small': 2, 'language': 2}, ('bidirectional', 'the'): {'language': 5, 'perplexity': 8, 'researcher': 4, 'tokenizer': 4, 'output': 6, 'weight': 7, 'training': 3, 'n-gram': 5, 'system': 4, 'gradient': 6, 'trigram': 3, 'optimizer': 5, 'loss': 4, 'context': 7, 'vocabulary': 3, 'text': 7, 'attention': 7, 'prediction': 4, 'embedding': 5, 'algorithm': 9, 'corpus': 3, 'neural': 3, 'dataset': 3, 'probability': 6, 'bigram': 3, 'input': 2, 'sequence': 3, 'evaluation': 3}, ('sequentially', 'updates'): {'word': 1, 'linguistic': 1, 'the': 7}, ('neural', 'backpropagation'): {'processes': 1, 'converges': 1, 'maximizes': 1, 'minimizes': 1, 'trains': 1, 'represents': 1}, ('correctly', 'fine-tunes'): {'the': 5, 'semantic': 1, 'word': 1}, ('statistically', 'trains'): {'on': 6}, ('significantly', 'generates'): {'syntactic': 1, 'token': 1, 'the': 3, 'large': 1, 'semantic': 1, 'sentence': 1}, ('researcher', 'maximizes'): {'the': 8, 'large': 1, 'linguistic': 2, 'word': 1}, ('mechanism', 'effectively'): {'models': 1, 'fine-tunes': 2, 'decodes': 1, 'tokenizes': 1, 'updates': 1, 'minimizes': 1, 'generalizes': 1}, ('a', 'sample'): {'of': 104}, ('maximizes', 'linguistic'): {'features': 11}, ('outputs', 'language'): {'patterns': 14}, ('researcher', 'continuously'): {'generalizes': 1, 'models': 1, 'maximizes': 1, 'generates': 1, 'adjusts': 1, 'updates': 1, 'optimizes': 1, 'calculates': 1, 'represents': 1, 'processes': 1}, ('text', 'adjusts'): {'contextual': 1, 'co-occurrence': 1, 'the': 2, 'sentence': 1, 'language': 1}, ('descent', 'meanwhile'): {'the': 5}, ('techniques', 'prevent'): {'language': 92}, ('trigram', 'reduces'): {'the': 4, 'language': 2, 'syntactic': 2, 'token': 1, 'semantic': 1}, ('optimization', 'algorithm'): {'used': 94}, ('rules', 'feeding'): {'diverse': 4}, ('statistically', 'models'): {'the': 3, 'semantic': 1}, ('features', 'in'): {'contrast': 1}, ('decodes', 'contextual'): {'information': 21}, ('predicts', 'large'): {'amounts': 22}, ('bigram', 'learns'): {'from': 8}, ('updates', 'syntactic'): {'rules': 13}, ('trigram', 'tokenizes'): {'token': 1, 'the': 9, 'syntactic': 1, 'millions': 1, 'large': 1, 'linguistic': 1}, ('bigram', 'generates'): {'the': 6, 'contextual': 1}, ('tokenizer', 'computes'): {'the': 5, 'contextual': 1, 'syntactic': 1, 'linguistic': 1}, ('features', 'rapidly'): {'the': 9, 'a': 4, 'word': 1, 'similarly': 2, 'meanwhile': 2, 'specifically': 1, 'perplexity': 1, 'in': 1}, ('backpropagation', 'tokenizes'): {'the': 3, 'semantic': 1, 'language': 1, 'contextual': 1}, ('occurs', 'when'): {'a': 104}, ('sequence', 'updates'): {'the': 6, 'word': 1}, ('optimizer', 'adjusts'): {'the': 6, 'millions': 1, 'token': 1}, ('states', 'perplexity'): {'measures': 2}, ('rules', 'recursively'): {'a': 4, 'the': 3, 'furthermore': 1, 'nevertheless': 1, 'transfer': 1, 'in': 1}, ('mechanism', 'samples'): {'large': 2, 'the': 3, 'syntactic': 1, 'millions': 1}, ('gradually', 'regularization'): {'techniques': 3}, ('requires', 'carefully'): {'curated': 109}, ('encodes', 'linguistic'): {'features': 18}, ('word', 'accurately'): {'meanwhile': 1, 'overfitting': 1, 'similarly': 1, 'feeding': 1, 'the': 5, 'furthermore': 1, 'a': 1, 'subsequently': 1}, ('sequences', 'backpropagation'): {'encodes': 1, 'correctly': 1}, ('gradient', 'rapidly'): {'fine-tunes': 1, 'overfits': 1, 'increases': 1, 'predicts': 1, 'tokenizes': 1}, ('model', 'in'): {'addition': 8, 'contrast': 2}, ('correctly', 'as'): {'a': 7}, ('generalizes', 'millions'): {'of': 10}, ('the', 'learning'): {'rate': 397}, ('model', 'rapidly'): {'minimizes': 3, 'generates': 1, 'maximizes': 1, 'calculates': 1, 'represents': 1, 'generalizes': 1, 'processes': 1}, ('tokenizes', 'contextual'): {'information': 13}, ('matrices', 'backpropagation'): {'predicts': 1, 'optimizes': 1, 'decodes': 1}, ('frequencies', 'gradually'): {'a': 4, 'the': 7, 'nevertheless': 1, 'gradient': 1}, ('correctly', 'for'): {'example': 4}, ('on', 'co-occurrence'): {'matrices': 13}, ('text', 'fine-tunes'): {'the': 8, 'token': 1, 'statistical': 1, 'large': 1, 'co-occurrence': 1, 'sentence': 1, 'linguistic': 1, 'semantic': 1, 'language': 1}, ('sequence', 'diverges'): {'semantic': 2, 'millions': 2, 'the': 8, 'sentence': 2, 'token': 1, 'word': 1, 'co-occurrence': 1}, ('pipeline', 'however'): {'the': 1}, ('probabilistically', 'processes'): {'word': 1, 'the': 3, 'millions': 1}, ('co-occurrences', 'forms'): {'the': 110}, ('input', 'significantly'): {'calculates': 1, 'models': 1, 'decodes': 1}, ('dataset', 'captures'): {'the': 11, 'word': 1, 'millions': 1}, ('mechanism', 'improves'): {'the': 7, 'linguistic': 1, 'token': 1, 'syntactic': 1, 'co-occurrence': 1}, ('data', 'smoothing'): {'techniques': 2}, ('vocabulary', 'predicts'): {'word': 3, 'language': 4, 'contextual': 2, 'sentence': 2, 'the': 6, 'linguistic': 1}, ('successfully', 'similarly'): {'the': 5}, ('n-gram', 'significantly'): {'generalizes': 1, 'overfits': 2}, ('features', 'statistically'): {'the': 2, 'moreover': 1, 'perplexity': 1, 'a': 1, 'in': 1, 'therefore': 1}, ('pipeline', 'nevertheless'): {'the': 2}, ('patterns', 'cross'): {'entropy': 5}, ('model', 'however'): {'the': 5}, ('represents', 'statistical'): {'patterns': 19}, ('optimizer', 'fine-tunes'): {'the': 7, 'statistical': 1, 'sentence': 1, 'co-occurrence': 1}, ('bigram', 'accurately'): {'converges': 1, 'optimizes': 1, 'generates': 1, 'predicts': 1, 'captures': 1, 'overfits': 1}, ('descent', 'iteratively'): {'the': 7, 'subsequently': 1, 'a': 3, 'as': 1, 'training': 1, 'however': 1}, ('frequencies', 'similarly'): {'the': 2}, ('gradient', 'statistically'): {'processes': 1, 'calculates': 1, 'diverges': 1, 'trains': 1, 'tokenizes': 1, 'optimizes': 1, 'decodes': 1, 'represents': 1}, ('text', 'efficiently'): {'cleaning': 1, 'subsequently': 1, 'a': 6, 'processes': 2, 'maximizes': 1, 'smoothing': 1, 'evaluates': 1, 'computes': 1, 'regularization': 1, 'perplexity': 1, 'the': 2, 'as': 1, 'calculates': 1}, ('a', 'deep'): {'the': 125, 'backpropagation': 1}, ('optimizes', 'language'): {'patterns': 13}, ('frequencies', 'bigram'): {'and': 3}, ('tokenizer', 'successfully'): {'converges': 1, 'maximizes': 1, 'samples': 1, 'increases': 2}, ('function', 'reduces'): {'the': 7, 'millions': 1, 'word': 2}, ('terms', 'word'): {'embeddings': 3}, ('output', 'gradually'): {'similarly': 1, 'the': 6, 'a': 1, 'feeding': 1, 'processes': 1, 'maximizes': 1, 'models': 1, 'specifically': 1, 'minimizes': 1}, ('model', 'statistically'): {'improves': 1, 'represents': 2, 'generates': 2, 'updates': 1, 'minimizes': 1, 'generalizes': 1, 'overfits': 1, 'increases': 1}, ('embeddings', 'a'): {'shallow': 7, 'deep': 4, 'language': 3, 'large': 1, 'lightweight': 1, 'generative': 2, 'efficient': 1, 'scalable': 4, 'accurate': 2, 'robust': 1, 'small': 2, 'recurrent': 2, 'discriminative': 2, 'bidirectional': 2, 'pre-trained': 3, 'transformer-based': 1, 'statistical': 1}, ('from', 'token'): {'sequences': 15}, ('generative', 'backpropagation'): {'samples': 1}, ('function', 'training'): {'a': 2}, ('correctly', 'tokenization'): {'is': 2}, ('small', 'language'): {'model': 109}, ('corpus', 'evaluates'): {'semantic': 1, 'co-occurrence': 2, 'the': 4, 'statistical': 1, 'word': 1}, ('optimizer', 'efficiently'): {'samples': 1, 'evaluates': 1, 'captures': 1, 'outputs': 1, 'improves': 1, 'calculates': 1, 'generates': 1, 'tokenizes': 1}, ('generates', 'sentence'): {'structure': 19}, ('data', 'regularization'): {'techniques': 2}, ('architecture', 'evaluates'): {'contextual': 1, 'sentence': 1, 'the': 2, 'semantic': 1, 'syntactic': 1, 'linguistic': 1}, ('improves', 'co-occurrence'): {'matrices': 17}, ('probability', 'predicts'): {'the': 9, 'token': 2, 'statistical': 2, 'language': 1}, ('statistical', 'patterns'): {'smoothing': 2, 'statistically': 9, 'recursively': 12, 'rapidly': 14, 'the': 93, 'probabilistically': 12, 'consequently': 4, 'feeding': 1, 'a': 42, 'efficiently': 13, 'iteratively': 13, 'automatically': 7, 'sequentially': 10, 'training': 1, 'significantly': 14, 'effectively': 10, 'correctly': 13, 'accurately': 11, 'successfully': 10, 'nevertheless': 3, 'continuously': 9, 'furthermore': 4, 'specifically': 4, 'however': 4, 'overfitting': 6, 'gradually': 12, 'transfer': 2, 'in': 8, 'word': 2, 'cross': 2, 'therefore': 2, 'bigram': 5, 'tokenization': 1, 'subsequently': 3, 'moreover': 2, 'data': 1, 'additionally': 2, 'gradient': 2, 'for': 2, 'meanwhile': 2, 'perplexity': 2, 'as': 1, 'backpropagation': 1}, ('generalization', 'ability'): {'a': 33, 'in': 3, 'the': 52, 'however': 5, 'specifically': 3, 'meanwhile': 2, 'as': 3, 'nevertheless': 3, 'consequently': 1, 'therefore': 4, 'additionally': 2, 'furthermore': 1, 'backpropagation': 4, 'similarly': 2, 'for': 2, 'subsequently': 1}, ('efficient', 'the'): {'optimizer': 4, 'weight': 6, 'researcher': 8, 'neural': 7, 'dataset': 4, 'architecture': 8, 'tokenizer': 4, 'probability': 3, 'corpus': 4, 'perplexity': 4, 'gradient': 5, 'training': 6, 'evaluation': 3, 'sequence': 7, 'n-gram': 6, 'embedding': 8, 'context': 2, 'output': 11, 'system': 4, 'bigram': 5, 'loss': 5, 'algorithm': 3, 'trigram': 6, 'attention': 3, 'prediction': 2, 'input': 2, 'vocabulary': 4, 'language': 4, 'text': 3}, ('text', 'as'): {'a': 6}, ('rapidly', 'predicts'): {'contextual': 1, 'the': 4, 'language': 1, 'semantic': 1, 'word': 1}, ('gradually', 'updates'): {'large': 1, 'the': 2}, ('researcher', 'updates'): {'contextual': 1, 'word': 1, 'co-occurrence': 1, 'linguistic': 2, 'the': 3}, ('input', 'trains'): {'on': 7}, ('value', 'a'): {'lightweight': 1, 'language': 3, 'transformer-based': 1, 'fine-tuned': 3, 'robust': 2, 'shallow': 4, 'pre-trained': 2, 'small': 1, 'autoregressive': 3, 'efficient': 2, 'large': 1, 'recurrent': 2, 'bidirectional': 1, 'generative': 1, 'accurate': 3, 'statistical': 4, 'neural': 1, 'discriminative': 1}, ('reduces', 'token'): {'sequences': 11}, ('output', 'similarly'): {'the': 3}, ('text', 'for'): {'example': 4}, ('system', 'automatically'): {'predicts': 1, 'tokenizes': 1, 'calculates': 1, 'trains': 1}, ('algorithm', 'represents'): {'contextual': 1, 'the': 6, 'millions': 1, 'linguistic': 1}, ('perplexity', 'fine-tunes'): {'word': 2, 'the': 5, 'contextual': 1, 'statistical': 1}, ('model', 'weights'): {'iteratively': 104}, ('decodes', 'token'): {'sequences': 13}, ('data', 'successfully'): {'the': 5, 'regularization': 1, 'as': 1, 'for': 1, 'gradient': 1, 'a': 1}, ('maximizes', 'co-occurrence'): {'matrices': 17}, ('resources', 'subsequently'): {'the': 2, 'backpropagation': 1}, ('output', 'bigram'): {'and': 3}, ('sequences', 'feeding'): {'diverse': 1}, ('text', 'corpora'): {'to': 121}, ('iteratively', 'furthermore'): {'the': 8, 'backpropagation': 1}, ('diverges', 'language'): {'patterns': 15}, ('syntactic', 'rules'): {'the': 102, 'tokenization': 1, 'recursively': 11, 'a': 39, 'however': 7, 'successfully': 9, 'feeding': 4, 'statistically': 16, 'subsequently': 2, 'gradually': 15, 'specifically': 3, 'automatically': 20, 'correctly': 7, 'sequentially': 10, 'iteratively': 7, 'probabilistically': 15, 'accurately': 14, 'nevertheless': 2, 'therefore': 3, 'backpropagation': 4, 'efficiently': 13, 'rapidly': 14, 'for': 3, 'similarly': 3, 'meanwhile': 4, 'transfer': 4, 'effectively': 13, 'as': 4, 'significantly': 9, 'in': 5, 'training': 4, 'continuously': 5, 'overfitting': 6, 'furthermore': 5, 'consequently': 3, 'cross': 2, 'word': 1, 'gradient': 2, 'moreover': 3, 'bigram': 1, 'data': 1}, ('meaning', 'correctly'): {'the': 5, 'as': 1, 'a': 2, 'however': 1, 'tokenization': 1, 'bigram': 1, 'for': 1}, ('in', 'a'): {'continuous': 88}, ('efficiently', 'decodes'): {'language': 1, 'syntactic': 1, 'the': 3, 'statistical': 1, 'millions': 1}, ('effectively', 'transfer'): {'learning': 1}, ('probabilistically', 'nevertheless'): {'the': 2}, ('parameters', 'furthermore'): {'the': 6}, ('input', 'models'): {'the': 6, 'semantic': 2, 'token': 1, 'statistical': 1, 'syntactic': 1, 'contextual': 1, 'millions': 1}, ('word', 'dependencies'): {'in': 104}, ('corpus', 'meanwhile'): {'the': 5}, ('rate', 'backpropagation'): {'calculates': 1, 'significantly': 1, 'improves': 1}, ('resources', 'specifically'): {'the': 5}, ('embeddings', 'gradually'): {'the': 3, 'a': 3, 'cleaning': 1, 'therefore': 1, 'cross': 1, 'perplexity': 1}, ('models', 'large'): {'amounts': 15}, ('increases', 'word'): {'frequencies': 12, 'embeddings': 13}, ('sequences', 'recursively'): {'the': 7, 'cleaning': 1, 'specifically': 2, 'transfer': 1, 'a': 1}, ('matrices', 'feeding'): {'diverse': 6}, ('researcher', 'diverges'): {'contextual': 5, 'language': 1, 'the': 4, 'word': 1, 'statistical': 1}, ('structure', 'regularization'): {'techniques': 3}, ('states', 'cross'): {'entropy': 2}, ('features', 'moreover'): {'the': 3}, ('tokenizer', 'updates'): {'contextual': 2, 'the': 5, 'statistical': 2, 'sentence': 1, 'co-occurrence': 1}, ('descent', 'cleaning'): {'and': 1}, ('descent', 'is'): {'the': 94}, ('modeling', 'for'): {'example': 1}, ('tokenizes', 'token'): {'sequences': 15}, ('metric', 'maximizes'): {'the': 6, 'sentence': 1, 'statistical': 1}, ('sequentially', 'backpropagation'): {'rapidly': 2, 'updates': 1, 'efficiently': 1, 'calculates': 1, 'minimizes': 1, 'recursively': 1}, ('ability', 'subsequently'): {'the': 1}, ('metric', 'continuously'): {'predicts': 1, 'samples': 2}, ('process', 'correctly'): {'predicts': 2, 'processes': 1, 'generates': 1}, ('parameters', 'effectively'): {'the': 6, 'consequently': 1, 'a': 3, 'therefore': 1, 'specifically': 1}, ('matrix', 'regularization'): {'techniques': 1}, ('information', 'automatically'): {'the': 4, 'gradient': 1, 'training': 1, 'subsequently': 3, 'for': 1, 'a': 1, 'in': 1, 'furthermore': 1}, ('layer', 'efficiently'): {'generates': 1, 'outputs': 1, 'predicts': 1, 'decodes': 1, 'trains': 1}, ('embeddings', 'similarly'): {'the': 5}, ('structure', 'successfully'): {'regularization': 1, 'the': 8, 'gradient': 1, 'bigram': 1, 'a': 3, 'as': 1}, ('for', 'assigning'): {'low': 111}, ('improves', 'semantic'): {'meaning': 14}, ('recursively', 'samples'): {'millions': 1, 'large': 1, 'the': 4, 'token': 1, 'syntactic': 1, 'word': 1}, ('output', 'perplexity'): {'measures': 3}, ('network', 'correctly'): {'increases': 1, 'converges': 1, 'captures': 1, 'generates': 1, 'minimizes': 1, 'updates': 1, 'predicts': 1}, ('weight', 'reduces'): {'sentence': 1, 'statistical': 1, 'linguistic': 2, 'word': 1, 'the': 7, 'millions': 1, 'language': 1}, ('result', 'the'): {'input': 7, 'weight': 9, 'system': 5, 'loss': 9, 'vocabulary': 11, 'context': 10, 'language': 9, 'attention': 5, 'architecture': 5, 'n-gram': 4, 'researcher': 7, 'corpus': 5, 'sequence': 9, 'output': 8, 'tokenizer': 8, 'gradient': 5, 'optimizer': 7, 'prediction': 2, 'bigram': 10, 'training': 4, 'probability': 7, 'perplexity': 6, 'embedding': 6, 'neural': 8, 'trigram': 6, 'model': 8, 'algorithm': 3, 'evaluation': 4, 'text': 2, 'dataset': 2}, ('model', 'moreover'): {'the': 3}, ('statistical', 'the'): {'n-gram': 3, 'vocabulary': 8, 'perplexity': 7, 'optimizer': 5, 'trigram': 5, 'architecture': 8, 'system': 6, 'language': 4, 'corpus': 3, 'attention': 7, 'weight': 4, 'text': 8, 'researcher': 6, 'output': 5, 'algorithm': 2, 'evaluation': 2, 'context': 8, 'input': 4, 'tokenizer': 2, 'neural': 4, 'embedding': 3, 'dataset': 3, 'sequence': 3, 'prediction': 4, 'bigram': 6, 'loss': 1, 'probability': 2, 'gradient': 2, 'training': 1}, ('loss', 'correctly'): {'a': 1, 'the': 6, 'therefore': 1, 'bigram': 1}, ('patterns', 'subsequently'): {'the': 9}, ('window', 'effectively'): {'reduces': 1, 'calculates': 3, 'overfits': 1, 'predicts': 1, 'trains': 1, 'fine-tunes': 1}, ('weight', 'tokenizes'): {'the': 5, 'sentence': 1, 'semantic': 1, 'language': 1, 'contextual': 1}, ('recursively', 'the'): {'sequence': 4, 'evaluation': 8, 'training': 8, 'gradient': 4, 'embedding': 4, 'tokenizer': 4, 'context': 10, 'loss': 7, 'language': 7, 'vocabulary': 9, 'neural': 4, 'attention': 5, 'input': 5, 'trigram': 4, 'researcher': 6, 'text': 5, 'output': 2, 'model': 5, 'dataset': 5, 'weight': 5, 'system': 6, 'frequency': 2, 'probability': 4, 'algorithm': 3, 'n-gram': 3, 'prediction': 4, 'softmax': 2, 'bigram': 4, 'perplexity': 4, 'optimizer': 2, 'architecture': 6, 'corpus': 1}, ('text', 'gradient'): {'descent': 2}, ('output', 'calculates'): {'the': 7, 'co-occurrence': 1, 'word': 1, 'contextual': 2, 'language': 1}, ('small', 'backpropagation'): {'models': 2, 'learns': 1, 'diverges': 1, 'overfits': 1, 'generates': 1, 'converges': 1, 'optimizes': 1, 'tokenizes': 1}, ('dataset', 'generalizes'): {'the': 3, 'syntactic': 2, 'sentence': 1, 'word': 2}, ('tokenizer', 'diverges'): {'the': 3, 'sentence': 1, 'statistical': 3, 'word': 1, 'contextual': 1, 'co-occurrence': 1}, ('prevent', 'language'): {'models': 92}, ('efficiently', 'specifically'): {'the': 4}, ('process', 'represents'): {'millions': 1, 'the': 1, 'large': 2, 'contextual': 1, 'semantic': 1, 'token': 1}, ('corpus', 'increases'): {'word': 2, 'semantic': 2, 'millions': 2, 'language': 2, 'the': 5, 'syntactic': 1}, ('matrix', 'successfully'): {'a': 5, 'the': 7, 'regularization': 1, 'nevertheless': 1, 'furthermore': 1, 'overfitting': 1}, ('metric', 'captures'): {'the': 4, 'token': 1, 'word': 1, 'contextual': 1, 'language': 1, 'sentence': 1, 'co-occurrence': 1}, ('architecture', 'increases'): {'the': 7, 'sentence': 1, 'syntactic': 1, 'word': 1, 'linguistic': 1, 'contextual': 1}, ('effectively', 'in'): {'addition': 5, 'contrast': 1}, ('prediction', 'correctly'): {'processes': 1, 'fine-tunes': 1, 'maximizes': 2, 'generalizes': 1, 'minimizes': 1, 'optimizes': 1, 'predicts': 1, 'learns': 1, 'decodes': 1, 'trains': 1, 'models': 1, 'generates': 1, 'converges': 1, 'evaluates': 1, 'adjusts': 1}, ('maximizes', 'semantic'): {'meaning': 18}, ('bigram', 'probabilistically'): {'models': 1, 'adjusts': 2, 'processes': 2, 'captures': 1, 'represents': 1, 'improves': 1}, ('accurately', 'bigram'): {'and': 4}, ('models', 'handle'): {'unseen': 88}, ('word', 'frequencies'): {'in': 6, 'effectively': 14, 'a': 47, 'efficiently': 13, 'subsequently': 4, 'continuously': 9, 'correctly': 14, 'significantly': 15, 'word': 2, 'iteratively': 9, 'the': 92, 'moreover': 3, 'probabilistically': 12, 'for': 2, 'successfully': 14, 'sequentially': 17, 'gradually': 13, 'recursively': 13, 'automatically': 13, 'as': 3, 'accurately': 15, 'furthermore': 4, 'rapidly': 9, 'gradient': 2, 'cross': 3, 'data': 1, 'bigram': 3, 'additionally': 4, 'statistically': 13, 'feeding': 2, 'nevertheless': 3, 'therefore': 2, 'similarly': 2, 'however': 3, 'backpropagation': 3, 'transfer': 2, 'cleaning': 1, 'meanwhile': 4, 'specifically': 2, 'tokenization': 2, 'regularization': 2}, ('statistically', 'overfitting'): {'occurs': 5}, ('recursively', 'improves'): {'semantic': 1, 'the': 1}, ('corpus', 'optimizes'): {'semantic': 1, 'the': 4, 'word': 1, 'sentence': 1, 'statistical': 1, 'syntactic': 1}, ('recursively', 'overfits'): {'the': 3, 'linguistic': 1, 'syntactic': 1}, ('text', 'learns'): {'from': 6}, ('corpus', 'iteratively'): {'improves': 1, 'a': 4, 'computes': 1, 'the': 2, 'generalizes': 1, 'for': 1, 'minimizes': 1, 'similarly': 1, 'diverges': 1, 'in': 1, 'tokenizes': 1, 'models': 1}, ('architecture', 'optimizes'): {'the': 7, 'large': 2, 'statistical': 2, 'contextual': 2, 'linguistic': 1, 'word': 2}, ('accurately', 'optimizes'): {'the': 4, 'syntactic': 1, 'co-occurrence': 1}, ('trigram', 'effectively'): {'overfits': 2, 'reduces': 1, 'adjusts': 2}, ('text', 'generates'): {'the': 7, 'language': 2, 'statistical': 1, 'semantic': 1, 'millions': 2, 'sentence': 1, 'co-occurrence': 1, 'token': 1}, ('size', 'overfitting'): {'occurs': 3}, ('architecture', 'iteratively'): {'evaluates': 1}, ('descent', 'additionally'): {'the': 3}, ('system', 'rapidly'): {'diverges': 1, 'generates': 1, 'decodes': 1, 'models': 3, 'learns': 2}, ('window', 'samples'): {'the': 7, 'word': 2, 'language': 1, 'statistical': 1, 'syntactic': 1}, ('dataset', 'converges'): {'linguistic': 1, 'contextual': 1, 'the': 4, 'co-occurrence': 1, 'token': 1, 'millions': 1}, ('bias', 'terms'): {'statistically': 16, 'the': 93, 'a': 37, 'efficiently': 13, 'iteratively': 16, 'cross': 3, 'smoothing': 2, 'subsequently': 2, 'sequentially': 19, 'gradually': 14, 'probabilistically': 12, 'continuously': 12, 'accurately': 10, 'rapidly': 14, 'training': 1, 'significantly': 19, 'recursively': 14, 'in': 4, 'therefore': 7, 'data': 1, 'correctly': 8, 'as': 3, 'however': 2, 'tokenization': 2, 'specifically': 4, 'gradient': 3, 'effectively': 11, 'meanwhile': 4, 'cleaning': 4, 'automatically': 13, 'bigram': 3, 'nevertheless': 5, 'word': 3, 'successfully': 9, 'perplexity': 2, 'moreover': 3, 'feeding': 1, 'similarly': 1, 'furthermore': 2, 'backpropagation': 1, 'overfitting': 1, 'consequently': 1, 'additionally': 3}, ('backpropagation', 'probabilistically'): {'tokenizes': 1, 'computes': 1, 'updates': 1}, ('effectively', 'however'): {'the': 1, 'backpropagation': 1}, ('and', 'sufficient'): {'computational': 109}, ('similarly', 'the'): {'n-gram': 8, 'context': 6, 'vocabulary': 4, 'embedding': 8, 'input': 5, 'tokenizer': 5, 'perplexity': 5, 'text': 4, 'prediction': 5, 'evaluation': 9, 'researcher': 8, 'architecture': 7, 'language': 8, 'corpus': 4, 'gradient': 6, 'attention': 4, 'algorithm': 7, 'bigram': 7, 'output': 3, 'loss': 9, 'optimizer': 4, 'trigram': 5, 'training': 4, 'sequence': 8, 'neural': 4, 'probability': 6, 'dataset': 5, 'system': 6, 'weight': 7, 'model': 7}, ('meaning', 'backpropagation'): {'efficiently': 2, 'calculates': 1, 'computes': 1, 'iteratively': 1}, ('tokens', 'to'): {'dense': 88}, ('vocabulary', 'processes'): {'word': 2, 'the': 4}, ('terms', 'overfitting'): {'occurs': 1}, ('mechanism', 'increases'): {'the': 3, 'millions': 1, 'statistical': 1, 'co-occurrence': 1}, ('impacts', 'the'): {'memory': 108}, ('patterns', 'efficiently'): {'a': 6, 'the': 12, 'smoothing': 1, 'as': 2, 'nevertheless': 2, 'feeding': 1, 'similarly': 1, 'perplexity': 1, 'moreover': 1}, ('encodes', 'semantic'): {'meaning': 13}, ('models', 'capture'): {'local': 104}, ('rate', 'feeding'): {'diverse': 5}, ('ability', 'as'): {'a': 3}, ('size', 'continuously'): {'the': 16, 'a': 7, 'tokenization': 2, 'perplexity': 1}, ('therefore', 'backpropagation'): {'evaluates': 1, 'learns': 3, 'decodes': 1, 'reduces': 1, 'generalizes': 1, 'maximizes': 1, 'adjusts': 1, 'trains': 1, 'optimizes': 1}, ('value', 'recursively'): {'the': 5, 'additionally': 1, 'furthermore': 1, 'a': 2, 'gradient': 1, 'meanwhile': 1, 'word': 1}, ('accurately', 'perplexity'): {'measures': 5}, ('softmax', 'output'): {'the': 91, 'statistically': 21, 'a': 37, 'significantly': 17, 'furthermore': 1, 'continuously': 14, 'gradient': 3, 'automatically': 16, 'tokenization': 3, 'therefore': 2, 'probabilistically': 10, 'rapidly': 16, 'successfully': 17, 'correctly': 6, 'iteratively': 12, 'recursively': 13, 'perplexity': 3, 'overfitting': 2, 'sequentially': 13, 'moreover': 3, 'efficiently': 17, 'gradually': 10, 'feeding': 4, 'in': 6, 'as': 5, 'effectively': 7, 'word': 2, 'data': 2, 'regularization': 1, 'accurately': 11, 'however': 2, 'bigram': 3, 'similarly': 3, 'cross': 2, 'meanwhile': 1, 'training': 2, 'cleaning': 2, 'smoothing': 1, 'subsequently': 2, 'consequently': 1, 'transfer': 1, 'additionally': 2, 'nevertheless': 1, 'specifically': 1, 'for': 1}, ('ability', 'for'): {'example': 2}, ('window', 'improves'): {'the': 5, 'millions': 1}, ('mechanism', 'iteratively'): {'optimizes': 1, 'generalizes': 1, 'calculates': 1, 'increases': 1, 'generates': 1, 'learns': 1, 'overfits': 1}, ('sequentially', 'feeding'): {'diverse': 2}, ('recurrent', 'the'): {'language': 2, 'corpus': 3, 'probability': 5, 'tokenizer': 4, 'training': 5, 'neural': 4, 'gradient': 2, 'text': 3, 'n-gram': 4, 'trigram': 3, 'prediction': 4, 'weight': 6, 'perplexity': 2, 'evaluation': 2, 'attention': 5, 'architecture': 5, 'bigram': 6, 'vocabulary': 5, 'algorithm': 4, 'loss': 1, 'system': 6, 'output': 3, 'input': 5, 'context': 4, 'embedding': 3, 'researcher': 3, 'sequence': 2, 'dataset': 2, 'optimizer': 2}, ('accurately', 'calculates'): {'syntactic': 1, 'the': 6, 'co-occurrence': 1, 'word': 1}, ('output', 'outputs'): {'the': 5, 'language': 1}, ('terms', 'continuously'): {'the': 4, 'training': 1, 'consequently': 1, 'for': 1, 'backpropagation': 1, 'however': 1, 'feeding': 1, 'nevertheless': 1, 'tokenization': 1}, ('patterns', 'as'): {'a': 6}, ('system', 'statistically'): {'generates': 1, 'generalizes': 1, 'represents': 4, 'captures': 1}, ('function', 'furthermore'): {'the': 3, 'backpropagation': 1}, ('statistically', 'captures'): {'the': 1, 'contextual': 1}, ('raw', 'text'): {'into': 82}, ('probability', 'processes'): {'statistical': 1, 'the': 6, 'token': 1, 'linguistic': 1, 'millions': 1, 'contextual': 1}, ('significantly', 'represents'): {'token': 2, 'contextual': 1, 'the': 5, 'syntactic': 1, 'large': 1, 'statistical': 1}, ('on', 'prediction'): {'errors': 104}, ('text', 'accurately'): {'the': 5, 'perplexity': 1, 'a': 4, 'furthermore': 1, 'represents': 1, 'evaluates': 2, 'predicts': 1, 'moreover': 1, 'adjusts': 1}, ('sequences', 'of'): {'words': 93}, ('words', 'however'): {'the': 1}, ('patterns', 'for'): {'example': 5}, ('model', 'memorizes'): {'training': 104}, ('represents', 'linguistic'): {'features': 16}, ('loss', 'backpropagation'): {'predicts': 1, 'samples': 1, 'adjusts': 1, 'updates': 1}, ('calculates', 'word'): {'embeddings': 16, 'frequencies': 10}, ('pre-trained', 'the'): {'embedding': 4, 'context': 9, 'training': 8, 'tokenizer': 2, 'weight': 4, 'vocabulary': 3, 'system': 4, 'trigram': 5, 'dataset': 3, 'researcher': 6, 'prediction': 3, 'corpus': 1, 'probability': 9, 'language': 3, 'evaluation': 5, 'n-gram': 5, 'gradient': 4, 'neural': 8, 'attention': 3, 'perplexity': 4, 'bigram': 4, 'optimizer': 6, 'input': 5, 'loss': 3, 'sequence': 1, 'algorithm': 3, 'output': 5, 'architecture': 2}, ('rapidly', 'processes'): {'sentence': 2, 'the': 3, 'syntactic': 1, 'word': 1}, ('distribution', 'nevertheless'): {'the': 8}, ('dataset', 'improves'): {'the': 6, 'large': 1}, ('dataset', 'overfits'): {'the': 6, 'co-occurrence': 2, 'token': 1, 'semantic': 1}, ('gradually', 'backpropagation'): {'maximizes': 1}, ('function', 'effectively'): {'the': 5, 'perplexity': 1, 'optimizes': 1, 'cross': 1, 'calculates': 2, 'outputs': 1, 'tokenization': 1, 'encodes': 1, 'cleaning': 1, 'subsequently': 1}, ('information', 'however'): {'the': 3}, ('nevertheless', 'the'): {'gradient': 5, 'output': 7, 'text': 6, 'sequence': 7, 'evaluation': 10, 'weight': 6, 'algorithm': 8, 'optimizer': 6, 'input': 4, 'embedding': 7, 'context': 5, 'n-gram': 7, 'probability': 10, 'perplexity': 6, 'model': 4, 'vocabulary': 6, 'language': 10, 'loss': 10, 'tokenizer': 4, 'bigram': 5, 'training': 4, 'neural': 5, 'dataset': 8, 'researcher': 6, 'prediction': 2, 'system': 5, 'trigram': 3, 'corpus': 6, 'attention': 3, 'architecture': 5}, ('corpus', 'cleaning'): {'and': 1}, ('successfully', 'consequently'): {'the': 6}, ('errors', 'backpropagation'): {'generates': 1, 'sequentially': 1}, ('entropy', 'loss'): {'rapidly': 16, 'probabilistically': 15, 'penalizes': 111, 'iteratively': 15, 'the': 108, 'recursively': 11, 'a': 49, 'gradually': 17, 'additionally': 1, 'efficiently': 18, 'successfully': 16, 'significantly': 17, 'correctly': 9, 'smoothing': 2, 'automatically': 20, 'continuously': 15, 'subsequently': 1, 'furthermore': 3, 'data': 1, 'statistically': 10, 'effectively': 13, 'accurately': 10, 'consequently': 3, 'sequentially': 10, 'specifically': 5, 'as': 2, 'training': 2, 'regularization': 4, 'meanwhile': 5, 'in': 3, 'moreover': 4, 'cleaning': 1, 'cross': 4, 'however': 2, 'nevertheless': 2, 'backpropagation': 2, 'word': 2, 'feeding': 3, 'similarly': 2, 'bigram': 4, 'overfitting': 2, 'gradient': 2, 'for': 3, 'transfer': 1}, ('bigram', 'represents'): {'the': 5, 'token': 1, 'linguistic': 1, 'language': 1, 'co-occurrence': 2, 'statistical': 1}, ('probabilistically', 'word'): {'embeddings': 4}, ('improves', 'the'): {'hidden': 21, 'vocabulary': 14, 'corpus': 17, 'gradient': 19, 'weight': 19, 'loss': 10, 'bias': 16, 'activation': 8, 'training': 13, 'softmax': 9, 'cross': 15, 'batch': 15, 'probability': 8, 'learning': 15, 'next': 10}, ('information', 'nevertheless'): {'the': 3}, ('layer', 'learns'): {'from': 4}, ('layer', 'generates'): {'the': 1, 'linguistic': 2, 'word': 1, 'large': 1, 'syntactic': 1}, ('word', 'a'): {'powerful': 1, 'robust': 4, 'accurate': 3, 'bidirectional': 3, 'lightweight': 3, 'generative': 5, 'shallow': 4, 'pre-trained': 4, 'statistical': 4, 'language': 3, 'autoregressive': 4, 'deep': 1, 'fine-tuned': 2, 'scalable': 2, 'neural': 1, 'large': 1}, ('distribution', 'significantly'): {'the': 3, 'subsequently': 1, 'a': 4, 'furthermore': 1, 'for': 1}, ('researcher', 'predicts'): {'the': 5, 'contextual': 2, 'language': 1, 'statistical': 1, 'linguistic': 1, 'large': 2, 'token': 1, 'sentence': 1, 'word': 4, 'co-occurrence': 1}, ('iteratively', 'evaluates'): {'large': 1, 'the': 2}, ('information', 'statistically'): {'the': 7, 'a': 3, 'moreover': 1, 'subsequently': 1, 'as': 1}, ('states', 'efficiently'): {'the': 11, 'a': 2}, ('patterns', 'tokenization'): {'is': 2}, ('significantly', 'a'): {'shallow': 3, 'generative': 3, 'lightweight': 4, 'bidirectional': 7, 'accurate': 4, 'recurrent': 3, 'large': 2, 'robust': 2, 'autoregressive': 3, 'language': 2, 'scalable': 3, 'fine-tuned': 1, 'neural': 3, 'powerful': 5, 'statistical': 2, 'small': 5, 'discriminative': 3, 'transformer-based': 3, 'efficient': 3, 'pre-trained': 2, 'deep': 3}, ('memorizes', 'training'): {'data': 104}, ('perplexity', 'computes'): {'the': 4, 'word': 4, 'token': 1, 'sentence': 1, 'co-occurrence': 1, 'semantic': 1, 'large': 1}, ('maximizes', 'the'): {'corpus': 19, 'next': 9, 'softmax': 13, 'hidden': 16, 'vocabulary': 13, 'learning': 11, 'gradient': 20, 'activation': 11, 'training': 14, 'batch': 14, 'cross': 15, 'bias': 10, 'loss': 17, 'probability': 15, 'weight': 7}, ('efficiently', 'encodes'): {'the': 4, 'linguistic': 1, 'sentence': 1}, ('mechanism', 'rapidly'): {'diverges': 1, 'calculates': 1, 'updates': 1, 'improves': 1}, ('recursively', 'meanwhile'): {'the': 4}, ('effectively', 'moreover'): {'the': 3}, ('window', 'evaluates'): {'the': 4, 'large': 1, 'millions': 1}, ('vocabulary', 'significantly'): {'fine-tunes': 1, 'updates': 1, 'represents': 1, 'increases': 2, 'outputs': 1, 'processes': 1}, ('accurately', 'outputs'): {'co-occurrence': 1, 'sentence': 2, 'the': 5, 'contextual': 2, 'syntactic': 1}, ('meaning', 'recursively'): {'the': 5, 'for': 1, 'a': 4, 'cleaning': 1, 'additionally': 1, 'moreover': 1, 'therefore': 1}, ('the', 'dataset'): {'iteratively': 5, 'computes': 4, 'encodes': 7, 'reduces': 10, 'successfully': 6, 'predicts': 22, 'optimizes': 5, 'continuously': 4, 'gradually': 5, 'overfits': 10, 'captures': 13, 'effectively': 4, 'maximizes': 8, 'models': 7, 'samples': 9, 'represents': 8, 'fine-tunes': 6, 'learns': 13, 'outputs': 5, 'diverges': 15, 'sequentially': 7, 'increases': 7, 'tokenizes': 5, 'automatically': 5, 'converges': 9, 'minimizes': 8, 'accurately': 8, 'processes': 7, 'statistically': 4, 'significantly': 3, 'adjusts': 12, 'improves': 7, 'generalizes': 8, 'rapidly': 4, 'decodes': 10, 'calculates': 5, 'trains': 6, 'updates': 4, 'recursively': 6, 'correctly': 2, 'evaluates': 9, 'generates': 8, 'efficiently': 5}, ('efficiently', 'minimizes'): {'the': 2, 'millions': 1, 'linguistic': 2, 'co-occurrence': 1}, ('encodes', 'contextual'): {'information': 18}, ('converges', 'syntactic'): {'rules': 13}, ('metric', 'converges'): {'the': 4, 'large': 1, 'co-occurrence': 1, 'word': 1}, ('iteratively', 'meanwhile'): {'the': 10, 'backpropagation': 1}, ('corpus', 'additionally'): {'the': 4}, ('calculates', 'linguistic'): {'features': 13}, ('increases', 'co-occurrence'): {'matrices': 12}, ('word', 'gradually'): {'the': 9, 'in': 1, 'feeding': 2, 'specifically': 1, 'a': 3}, ('states', 'for'): {'example': 1}, ('diverges', 'syntactic'): {'rules': 9}, ('parameters', 'meanwhile'): {'the': 1}, ('encodes', 'the'): {'cross': 13, 'activation': 9, 'weight': 14, 'softmax': 13, 'vocabulary': 9, 'bias': 11, 'probability': 13, 'loss': 12, 'next': 8, 'batch': 13, 'gradient': 15, 'hidden': 14, 'corpus': 10, 'learning': 12, 'training': 11}, ('layer', 'accurately'): {'predicts': 1, 'optimizes': 1, 'processes': 1, 'samples': 1}, ('adjusts', 'large'): {'amounts': 13}, ('raw', 'scores'): {'into': 97}, ('trigram', 'evaluates'): {'contextual': 1, 'semantic': 1, 'token': 1, 'the': 3, 'statistical': 2, 'linguistic': 1, 'sentence': 1}, ('data', 'backpropagation'): {'correctly': 1, 'optimizes': 1}, ('backpropagation', 'evaluates'): {'the': 2, 'co-occurrence': 1, 'semantic': 1, 'word': 1}, ('input', 'continuously'): {'increases': 1, 'outputs': 1, 'learns': 1, 'maximizes': 1}, ('autoregressive', 'the'): {'input': 7, 'corpus': 3, 'tokenizer': 5, 'algorithm': 4, 'system': 13, 'output': 3, 'perplexity': 5, 'bigram': 10, 'trigram': 7, 'training': 7, 'language': 6, 'neural': 6, 'context': 6, 'text': 6, 'dataset': 6, 'gradient': 8, 'weight': 2, 'researcher': 6, 'prediction': 6, 'optimizer': 5, 'evaluation': 4, 'n-gram': 2, 'loss': 2, 'attention': 1, 'architecture': 1, 'vocabulary': 1, 'probability': 1, 'embedding': 1}, ('loss', 'feeding'): {'diverse': 3}, ('corpus', 'cross'): {'entropy': 2}, ('process', 'recursively'): {'encodes': 1, 'adjusts': 3, 'diverges': 1, 'trains': 1, 'calculates': 2, 'predicts': 1}, ('probability', 'significantly'): {'computes': 1, 'represents': 1, 'optimizes': 1, 'processes': 1, 'fine-tunes': 1}, ('successfully', 'specifically'): {'the': 4}, ('frequencies', 'subsequently'): {'the': 4}, ('minimizes', 'large'): {'amounts': 16}, ('features', 'training'): {'a': 1}, ('words', 'moreover'): {'the': 2, 'backpropagation': 1}, ('features', 'therefore'): {'the': 4}, ('efficiently', 'overfitting'): {'occurs': 4}, ('network', 'recursively'): {'evaluates': 2, 'trains': 1, 'represents': 2, 'processes': 1, 'samples': 1}, ('loss', 'recursively'): {'the': 5, 'a': 4, 'consequently': 1, 'however': 1}, ('gradually', 'feeding'): {'diverse': 4}, ('gradient', 'reduces'): {'the': 6, 'sentence': 3, 'statistical': 2, 'word': 3, 'token': 1, 'co-occurrence': 1}, ('word', 'similarly'): {'the': 4}, ('output', 'adjusts'): {'the': 6, 'word': 3, 'co-occurrence': 1, 'semantic': 1, 'millions': 1, 'language': 1, 'sentence': 1}, ('statistically', 'generalizes'): {'the': 5, 'sentence': 1, 'linguistic': 1}, ('gradient', 'tokenizes'): {'word': 2, 'the': 4, 'linguistic': 2, 'semantic': 1, 'large': 1, 'statistical': 1}, ('input', 'captures'): {'the': 3, 'linguistic': 1, 'large': 1, 'millions': 1}, ('model', 'reduces'): {'the': 12, 'semantic': 1, 'word': 2, 'sentence': 1}, ('iteratively', 'increases'): {'the': 4, 'semantic': 1}, ('bigram', 'gradually'): {'reduces': 1, 'models': 1, 'improves': 1, 'calculates': 1}, ('states', 'tokenization'): {'is': 1}, ('significantly', 'similarly'): {'the': 4}, ('prediction', 'recursively'): {'optimizes': 1, 'processes': 1}, ('prediction', 'errors'): {'the': 48, 'as': 1, 'specifically': 4, 'a': 29, 'additionally': 4, 'however': 1, 'therefore': 2, 'consequently': 1, 'in': 4, 'backpropagation': 2, 'moreover': 1, 'similarly': 1, 'furthermore': 2, 'nevertheless': 1, 'for': 3}, ('fine-tunes', 'large'): {'amounts': 17}, ('model', 'tokenizes'): {'linguistic': 2, 'millions': 1, 'the': 11, 'sentence': 1, 'statistical': 2, 'word': 1, 'semantic': 1}, ('embeddings', 'consequently'): {'the': 4}, ('efficiently', 'smoothing'): {'techniques': 6}, ('captures', 'large'): {'amounts': 10}, ('model', 'therefore'): {'the': 8, 'backpropagation': 1}, ('efficiently', 'maximizes'): {'token': 2, 'the': 2, 'co-occurrence': 1, 'word': 1, 'semantic': 1}, ('structure', 'backpropagation'): {'efficiently': 1, 'fine-tunes': 1, 'effectively': 1, 'significantly': 1}, ('recursively', 'transfer'): {'learning': 3}, ('output', 'subsequently'): {'the': 2}, ('iteratively', 'optimizes'): {'the': 4, 'semantic': 1, 'linguistic': 1}, ('states', 'gradient'): {'descent': 3}, ('correctly', 'represents'): {'the': 5, 'word': 2, 'token': 1, 'language': 1, 'syntactic': 1}, ('window', 'increases'): {'the': 4, 'large': 1, 'word': 1, 'millions': 1}, ('statistically', 'converges'): {'co-occurrence': 1, 'large': 1, 'word': 1, 'the': 1}, ('value', 'consequently'): {'the': 3, 'backpropagation': 1}, ('frequencies', 'efficiently'): {'therefore': 2, 'the': 5, 'overfitting': 1, 'feeding': 1, 'as': 1, 'backpropagation': 1, 'a': 1, 'moreover': 1}, ('parameters', 'iteratively'): {'feeding': 1, 'a': 3, 'regularization': 1, 'the': 5, 'subsequently': 1, 'specifically': 2}, ('matrix', 'backpropagation'): {'represents': 1}, ('distribution', 'word'): {'embeddings': 1}, ('sequences', 'sequentially'): {'the': 4, 'a': 1, 'transfer': 1}, ('function', 'evaluates'): {'semantic': 1, 'the': 4, 'linguistic': 1, 'large': 1, 'language': 1, 'millions': 1, 'token': 1, 'sentence': 1}, ('output', 'fine-tunes'): {'the': 5, 'sentence': 1}, ('rapidly', 'trains'): {'on': 8}, ('window', 'iteratively'): {'generates': 1, 'calculates': 1, 'learns': 2, 'reduces': 1, 'adjusts': 1, 'samples': 1}, ('efficiently', 'regularization'): {'techniques': 4}, ('continuously', 'specifically'): {'the': 7, 'backpropagation': 1}, ('trigram', 'increases'): {'the': 5, 'linguistic': 1}, ('generalizes', 'word'): {'embeddings': 11, 'frequencies': 8}, ('frequencies', 'as'): {'a': 3}, ('dataset', 'automatically'): {'outputs': 1, 'captures': 1, 'predicts': 1, 'samples': 1, 'models': 1}, ('data', 'feeding'): {'diverse': 1}, ('architecture', 'adjusts'): {'the': 6, 'linguistic': 2}, ('accurately', 'adjusts'): {'the': 4, 'word': 1, 'semantic': 1, 'large': 1}, ('rapidly', 'models'): {'contextual': 1, 'the': 4, 'word': 1}, ('frequencies', 'for'): {'example': 2}, ('embeddings', 'subsequently'): {'the': 7}, ('recursively', 'in'): {'contrast': 5, 'addition': 6}, ('deep', 'the'): {'perplexity': 4, 'output': 8, 'tokenizer': 4, 'probability': 4, 'training': 6, 'input': 2, 'context': 7, 'language': 1, 'evaluation': 5, 'vocabulary': 7, 'researcher': 5, 'attention': 3, 'embedding': 6, 'bigram': 2, 'corpus': 3, 'trigram': 8, 'sequence': 7, 'neural': 6, 'gradient': 5, 'algorithm': 4, 'loss': 5, 'text': 5, 'optimizer': 4, 'weight': 3, 'dataset': 3, 'architecture': 3, 'n-gram': 3, 'prediction': 2}, ('trigram', 'optimizes'): {'the': 4}, ('researcher', 'processes'): {'the': 4, 'language': 1, 'word': 2, 'semantic': 1, 'sentence': 1, 'linguistic': 1}, ('correctly', 'a'): {'discriminative': 5, 'shallow': 9, 'small': 1, 'powerful': 8, 'accurate': 4, 'fine-tuned': 3, 'generative': 2, 'autoregressive': 3, 'pre-trained': 7, 'bidirectional': 2, 'robust': 3, 'language': 4, 'lightweight': 2, 'recurrent': 2, 'large': 3, 'neural': 1, 'efficient': 4, 'scalable': 2, 'statistical': 1, 'deep': 2}, ('metric', 'predicts'): {'syntactic': 1, 'millions': 2, 'the': 9, 'large': 3, 'word': 2, 'co-occurrence': 1, 'semantic': 1}, ('trigram', 'iteratively'): {'outputs': 1, 'predicts': 1, 'processes': 1, 'captures': 1, 'increases': 1, 'diverges': 1, 'reduces': 1}, ('backpropagation', 'optimizes'): {'the': 6, 'large': 1, 'co-occurrence': 1, 'semantic': 1, 'word': 1, 'statistical': 1}, ('sequentially', 'decodes'): {'the': 3, 'statistical': 2, 'word': 2}, ('robust', 'the'): {'corpus': 4, 'trigram': 7, 'researcher': 9, 'language': 6, 'perplexity': 7, 'probability': 11, 'weight': 9, 'dataset': 7, 'vocabulary': 10, 'output': 4, 'embedding': 3, 'system': 4, 'optimizer': 7, 'attention': 3, 'tokenizer': 4, 'evaluation': 8, 'text': 3, 'neural': 8, 'architecture': 8, 'gradient': 3, 'context': 5, 'sequence': 5, 'input': 6, 'n-gram': 10, 'algorithm': 7, 'bigram': 1, 'training': 6, 'loss': 2}, ('represents', 'semantic'): {'meaning': 15}, ('rules', 'overfitting'): {'occurs': 6}, ('curated', 'datasets'): {'and': 109}, ('function', 'meanwhile'): {'the': 2}, ('layer', 'probabilistically'): {'evaluates': 1, 'minimizes': 1, 'optimizes': 1, 'predicts': 1, 'computes': 1, 'encodes': 1}, ('embeddings', 'specifically'): {'the': 2, 'backpropagation': 1}, ('calculates', 'co-occurrence'): {'matrices': 16}, ('probability', 'to'): {'correct': 111}, ('predicts', 'a'): {'sample': 104}, ('text', 'represents'): {'the': 4, 'linguistic': 1, 'semantic': 1, 'token': 1}, ('bigram', 'calculates'): {'statistical': 1, 'syntactic': 1, 'the': 5, 'millions': 2, 'co-occurrence': 1, 'sentence': 1}, ('output', 'as'): {'a': 5}, ('process', 'of'): {'splitting': 82}, ('iteratively', 'cleaning'): {'and': 2}, ('probabilistically', 'captures'): {'linguistic': 2}, ('sequentially', 'trains'): {'on': 7}, ('descent', 'gradient'): {'descent': 1}, ('states', 'accurately'): {'the': 5, 'additionally': 2, 'as': 1, 'specifically': 2, 'consequently': 1, 'data': 1, 'bigram': 1, 'a': 2, 'backpropagation': 1}, ('output', 'for'): {'example': 1}, ('scores', 'into'): {'a': 97}, ('structure', 'feeding'): {'diverse': 2}, ('value', 'specifically'): {'the': 6}, ('parameters', 'cleaning'): {'and': 3}, ('frequencies', 'tokenization'): {'is': 2}, ('automatically', 'samples'): {'millions': 1, 'statistical': 1, 'the': 1, 'linguistic': 1}, ('optimizer', 'represents'): {'the': 4, 'sentence': 1, 'millions': 1}, ('rules', 'continuously'): {'regularization': 1, 'meanwhile': 1, 'the': 1, 'a': 1, 'backpropagation': 1}, ('successfully', 'encodes'): {'contextual': 1, 'co-occurrence': 1, 'the': 1, 'word': 1}, ('accurately', 'fine-tunes'): {'the': 3, 'word': 2, 'contextual': 2, 'statistical': 1, 'millions': 1}, ('samples', 'sentence'): {'structure': 14}, ('sequence', 'decodes'): {'token': 1, 'contextual': 2, 'the': 3, 'sentence': 1}, ('from', 'large'): {'amounts': 15}, ('large', 'amounts'): {'of': 391}, ('window', 'rapidly'): {'adjusts': 1, 'represents': 1, 'samples': 1, 'reduces': 1, 'converges': 1, 'trains': 1, 'evaluates': 1}, ('rapidly', 'word'): {'embeddings': 1}, ('additionally', 'the'): {'n-gram': 11, 'corpus': 4, 'model': 8, 'probability': 7, 'perplexity': 7, 'evaluation': 9, 'output': 2, 'architecture': 9, 'text': 6, 'context': 8, 'dataset': 6, 'vocabulary': 9, 'weight': 4, 'neural': 5, 'trigram': 7, 'sequence': 9, 'embedding': 5, 'attention': 7, 'optimizer': 10, 'algorithm': 4, 'tokenizer': 8, 'loss': 6, 'training': 4, 'bigram': 9, 'system': 10, 'language': 2, 'input': 6, 'gradient': 5, 'prediction': 4, 'researcher': 1}, ('automatically', 'the'): {'corpus': 3, 'algorithm': 3, 'weight': 3, 'training': 9, 'neural': 6, 'softmax': 5, 'optimizer': 5, 'context': 9, 'attention': 5, 'vocabulary': 8, 'input': 4, 'frequency': 6, 'tokenizer': 6, 'system': 3, 'dataset': 5, 'embedding': 4, 'perplexity': 6, 'language': 4, 'trigram': 6, 'loss': 4, 'architecture': 4, 'prediction': 4, 'researcher': 6, 'probability': 2, 'sequence': 3, 'bigram': 5, 'gradient': 2, 'evaluation': 8, 'output': 4, 'n-gram': 1, 'text': 3, 'model': 1}, ('backpropagation', 'calculates'): {'statistical': 1, 'the': 7, 'contextual': 1, 'token': 1, 'word': 2}, ('input', 'generalizes'): {'statistical': 1, 'word': 2, 'the': 7, 'semantic': 1}, ('matrix', 'feeding'): {'diverse': 1}, ('n-gram', 'generalizes'): {'the': 6, 'syntactic': 1, 'word': 2, 'language': 1, 'statistical': 1}, ('sequentially', 'models'): {'language': 1, 'statistical': 1, 'token': 1, 'syntactic': 1, 'semantic': 1}, ('corpora', 'to'): {'a': 121}, ('weight', 'evaluates'): {'the': 9, 'language': 1, 'large': 1, 'semantic': 1, 'contextual': 1}, ('generalizes', 'linguistic'): {'features': 14}, ('function', 'increases'): {'contextual': 3, 'the': 5, 'syntactic': 1}, ('accurate', 'backpropagation'): {'calculates': 1, 'learns': 1, 'processes': 1, 'trains': 1, 'adjusts': 1, 'updates': 1}, ('efficiently', 'updates'): {'the': 6, 'large': 1, 'millions': 1}, ('the', 'architecture'): {'increases': 12, 'significantly': 6, 'encodes': 6, 'efficiently': 7, 'gradually': 9, 'evaluates': 7, 'represents': 11, 'samples': 13, 'decodes': 16, 'generates': 7, 'computes': 6, 'recursively': 5, 'models': 8, 'outputs': 9, 'predicts': 17, 'learns': 9, 'converges': 7, 'adjusts': 8, 'reduces': 11, 'trains': 14, 'calculates': 10, 'improves': 4, 'generalizes': 8, 'accurately': 3, 'captures': 15, 'rapidly': 6, 'overfits': 9, 'correctly': 11, 'automatically': 7, 'maximizes': 9, 'statistically': 6, 'diverges': 7, 'updates': 5, 'tokenizes': 7, 'fine-tunes': 7, 'probabilistically': 3, 'processes': 7, 'successfully': 7, 'optimizes': 16, 'sequentially': 7, 'continuously': 1, 'minimizes': 4, 'effectively': 8, 'iteratively': 1}, ('architecture', 'efficiently'): {'increases': 1, 'adjusts': 2, 'predicts': 1, 'overfits': 1, 'outputs': 1, 'computes': 1}, ('perplexity', 'correctly'): {'improves': 1, 'evaluates': 1, 'updates': 1, 'diverges': 1, 'models': 2, 'reduces': 1}, ('sequence', 'trains'): {'on': 10}, ('space', 'for'): {'example': 4}, ('text', 'a'): {'large': 4, 'generative': 6, 'shallow': 8, 'powerful': 5, 'small': 6, 'recurrent': 3, 'autoregressive': 4, 'efficient': 4, 'lightweight': 6, 'statistical': 3, 'discriminative': 4, 'pre-trained': 3, 'bidirectional': 3, 'transformer-based': 5, 'neural': 3, 'robust': 6, 'scalable': 4, 'deep': 2, 'fine-tuned': 2, 'language': 1, 'accurate': 3}, ('value', 'sequentially'): {'additionally': 1, 'perplexity': 2, 'the': 3, 'a': 3, 'for': 1, 'in': 1}, ('automatically', 'improves'): {'statistical': 1, 'the': 6, 'contextual': 1, 'word': 1}, ('automatically', 'overfits'): {'the': 3, 'large': 2}, ('features', 'furthermore'): {'the': 1}, ('function', 'optimizes'): {'the': 8, 'word': 1, 'co-occurrence': 2, 'millions': 1, 'syntactic': 2}, ('increases', 'the'): {'training': 13, 'vocabulary': 15, 'activation': 12, 'gradient': 9, 'next': 5, 'softmax': 15, 'hidden': 11, 'corpus': 15, 'batch': 20, 'bias': 16, 'weight': 9, 'probability': 20, 'loss': 13, 'cross': 7, 'learning': 14}, ('effectively', 'reduces'): {'the': 5, 'linguistic': 2, 'statistical': 1, 'word': 1}, ('function', 'iteratively'): {'transfer': 1, 'cleaning': 1, 'specifically': 1, 'captures': 1, 'the': 5, 'optimizes': 1, 'adjusts': 1, 'a': 1, 'evaluates': 1, 'as': 1, 'data': 1, 'decodes': 1, 'word': 1, 'minimizes': 1, 'predicts': 1, 'learns': 1}, ('to', 'minimize'): {'the': 94}, ('input', 'converges'): {'contextual': 2, 'the': 5, 'syntactic': 1, 'word': 1, 'millions': 1, 'large': 1}, ('updates', 'sentence'): {'structure': 13}, ('dataset', 'rapidly'): {'predicts': 1, 'adjusts': 1, 'represents': 1, 'maximizes': 1}, ('calculates', 'semantic'): {'meaning': 9}, ('effectively', 'training'): {'a': 4}, ('iteratively', 'additionally'): {'backpropagation': 1, 'the': 3}, ('effectively', 'therefore'): {'the': 4}, ('requirements', 'of'): {'the': 108}, ('rate', 'word'): {'embeddings': 3}, ('efficiently', 'diverges'): {'millions': 1, 'the': 5, 'co-occurrence': 1}, ('sequence', 'models'): {'contextual': 1, 'the': 6, 'statistical': 2, 'syntactic': 1}, ('system', 'reduces'): {'the': 6, 'word': 1, 'semantic': 1, 'co-occurrence': 1, 'large': 1}, ('parameters', 'additionally'): {'the': 1}, ('accurately', 'as'): {'a': 4}, ('bigram', 'outputs'): {'sentence': 1, 'word': 1, 'the': 6, 'millions': 1, 'contextual': 1, 'statistical': 1, 'language': 1, 'co-occurrence': 1}, ('model', 'furthermore'): {'the': 5}, ('researcher', 'significantly'): {'models': 1, 'outputs': 1, 'evaluates': 1, 'decodes': 1}, ('accurately', 'for'): {'example': 6}, ('iteratively', 'cross'): {'entropy': 4}, ('modeling', 'a'): {'lightweight': 3, 'pre-trained': 3, 'accurate': 3, 'generative': 4, 'small': 4, 'large': 2, 'discriminative': 5, 'scalable': 1, 'fine-tuned': 2, 'powerful': 1, 'deep': 2, 'bidirectional': 2, 'neural': 1, 'robust': 1, 'recurrent': 2, 'statistical': 2}, ('layer', 'represents'): {'word': 2, 'large': 1, 'syntactic': 1, 'the': 1, 'contextual': 1}, ('successfully', 'computes'): {'the': 4}, ('contrast', 'backpropagation'): {'calculates': 1, 'generalizes': 1, 'learns': 1, 'fine-tunes': 1, 'decodes': 1, 'increases': 1, 'predicts': 1}, ('parameters', 'cross'): {'entropy': 2}, ('continuously', 'encodes'): {'the': 5, 'co-occurrence': 1}, ('gradient', 'effectively'): {'learns': 1, 'computes': 1, 'overfits': 1, 'fine-tunes': 1, 'outputs': 1}, ('descent', 'accurately'): {'the': 6, 'specifically': 1, 'feeding': 1, 'a': 4, 'in': 1}, ('network', 'decodes'): {'the': 4, 'syntactic': 1}, ('represents', 'contextual'): {'information': 18}, ('n-gram', 'samples'): {'the': 6, 'millions': 1, 'semantic': 2, 'word': 1, 'linguistic': 1}, ('text', 'gradually'): {'similarly': 1, 'a': 4, 'the': 2, 'computes': 2, 'generalizes': 1, 'nevertheless': 1, 'smoothing': 1, 'generates': 1}, ('computes', 'large'): {'amounts': 4}, ('meaning', 'specifically'): {'the': 2}, ('backpropagation', 'outputs'): {'the': 6, 'millions': 1, 'word': 1}, ('sequences', 'overfitting'): {'occurs': 1}, ('model', 'effectively'): {'reduces': 1, 'overfits': 2, 'predicts': 1, 'improves': 1, 'encodes': 1}, ('dataset', 'statistically'): {'calculates': 1, 'maximizes': 1, 'predicts': 2}, ('the', 'frequency'): {'of': 110}, ('the', 'hidden'): {'states': 385}, ('represents', 'the'): {'training': 17, 'bias': 14, 'softmax': 14, 'next': 18, 'probability': 10, 'gradient': 12, 'hidden': 13, 'learning': 18, 'loss': 18, 'corpus': 10, 'activation': 14, 'cross': 21, 'vocabulary': 14, 'weight': 9, 'batch': 12}, ('continuously', 'minimizes'): {'the': 3, 'language': 1, 'word': 1, 'syntactic': 1}, ('on', 'statistical'): {'patterns': 19}, ('recursively', 'moreover'): {'the': 8, 'backpropagation': 1}, ('gradually', 'decodes'): {'linguistic': 1, 'the': 3, 'language': 1, 'statistical': 1}, ('prediction', 'decodes'): {'word': 2, 'large': 1, 'the': 6, 'syntactic': 1, 'sentence': 1}, ('matrices', 'overfitting'): {'occurs': 3}, ('word', 'consequently'): {'the': 3}, ('weight', 'increases'): {'word': 1, 'statistical': 1, 'large': 2, 'the': 6, 'co-occurrence': 1}, ('sequences', 'smoothing'): {'techniques': 1}, ('accurately', 'tokenization'): {'is': 1}, ('a', 'critical'): {'step': 99}, ('text', 'similarly'): {'the': 9}, ('probabilistically', 'generalizes'): {'the': 2, 'syntactic': 1}, ('descent', 'data'): {'preprocessing': 5}, ('n-gram', 'improves'): {'the': 6, 'co-occurrence': 1, 'statistical': 1, 'large': 1, 'linguistic': 1, 'word': 1}, ('n-gram', 'overfits'): {'word': 2, 'the': 5, 'co-occurrence': 1, 'large': 1, 'linguistic': 1, 'millions': 1}, ('significantly', 'consequently'): {'the': 8}, ('successfully', 'regularization'): {'techniques': 5}, ('sequences', 'continuously'): {'the': 5, 'specifically': 1, 'perplexity': 1, 'however': 1, 'consequently': 1, 'bigram': 1, 'a': 1}, ('meaning', 'sequentially'): {'in': 3, 'a': 2, 'the': 4, 'therefore': 1, 'subsequently': 2, 'nevertheless': 1, 'cross': 1, 'moreover': 1}, ('pipeline', 'the'): {'sequence': 1, 'weight': 1, 'language': 1, 'input': 2, 'text': 3, 'neural': 3, 'bigram': 2, 'researcher': 1, 'trigram': 1, 'loss': 3, 'vocabulary': 1, 'training': 2, 'output': 1, 'perplexity': 2, 'gradient': 2, 'context': 4, 'model': 1, 'tokenizer': 4, 'n-gram': 3, 'evaluation': 1, 'prediction': 2, 'architecture': 3, 'corpus': 1, 'system': 1, 'attention': 1, 'embedding': 1}, ('function', 'cleaning'): {'and': 3}, ('researcher', 'trains'): {'on': 6}, ('matrices', 'smoothing'): {'techniques': 1}, ('rather', 'than'): {'learning': 104}, ('weight', 'optimizes'): {'the': 7, 'millions': 1, 'word': 1, 'co-occurrence': 1}, ('corpus', 'gradient'): {'descent': 1}, ('metric', 'processes'): {'sentence': 1, 'the': 6}, ('samples', 'language'): {'patterns': 11}, ('weight', 'iteratively'): {'computes': 1, 'reduces': 1, 'converges': 2, 'generates': 2, 'optimizes': 1, 'updates': 1}, ('accurately', 'gradient'): {'descent': 3}, ('linguistic', 'features'): {'a': 43, 'successfully': 16, 'the': 90, 'rapidly': 21, 'statistically': 7, 'accurately': 11, 'feeding': 2, 'significantly': 10, 'correctly': 10, 'continuously': 17, 'efficiently': 15, 'effectively': 14, 'probabilistically': 15, 'transfer': 4, 'recursively': 12, 'automatically': 20, 'cross': 1, 'gradually': 13, 'therefore': 4, 'sequentially': 19, 'iteratively': 7, 'for': 5, 'subsequently': 6, 'regularization': 5, 'perplexity': 3, 'smoothing': 4, 'gradient': 3, 'tokenization': 2, 'however': 7, 'bigram': 3, 'meanwhile': 4, 'additionally': 2, 'as': 2, 'similarly': 1, 'in': 1, 'nevertheless': 2, 'training': 1, 'backpropagation': 2, 'word': 1, 'moreover': 3, 'furthermore': 1, 'consequently': 1}, ('corpus', 'tokenizes'): {'syntactic': 1, 'word': 2, 'linguistic': 1, 'co-occurrence': 2, 'the': 1}, ('loss', 'specifically'): {'the': 7}, ('matrices', 'continuously'): {'the': 5, 'a': 2, 'subsequently': 1, 'meanwhile': 1, 'as': 1}, ('tokenizer', 'decodes'): {'the': 6, 'statistical': 1}, ('corpus', 'therefore'): {'the': 2}, ('predicts', 'syntactic'): {'rules': 33}, ('overfits', 'large'): {'amounts': 19}, ('improves', 'statistical'): {'patterns': 16}, ('gradually', 'models'): {'co-occurrence': 1, 'semantic': 2, 'the': 3, 'statistical': 1, 'contextual': 1, 'large': 1}, ('researcher', 'models'): {'the': 6, 'large': 2, 'sentence': 1, 'contextual': 1}, ('continuously', 'computes'): {'language': 1, 'the': 1}, ('modeling', 'similarly'): {'the': 4}, ('prediction', 'specifically'): {'the': 2}, ('resources', 'backpropagation'): {'rapidly': 1, 'sequentially': 1}, ('generalizes', 'co-occurrence'): {'matrices': 7}, ('corpus', 'learns'): {'from': 12}, ('errors', 'specifically'): {'the': 4}, ('continuously', 'smoothing'): {'techniques': 2}, ('architecture', 'learns'): {'from': 9}, ('corpus', 'generates'): {'the': 4, 'token': 1}, ('automatically', 'meanwhile'): {'the': 5}, ('process', 'sequentially'): {'decodes': 1, 'reduces': 1, 'computes': 1, 'predicts': 1}, ('accurately', 'learns'): {'from': 7}, ('architecture', 'generates'): {'millions': 1, 'the': 5, 'token': 1}, ('calculates', 'contextual'): {'information': 18}, ('accurately', 'generates'): {'the': 7}, ('tokenizer', 'trains'): {'on': 8}, ('ability', 'a'): {'deep': 1, 'transformer-based': 1, 'accurate': 5, 'robust': 3, 'fine-tuned': 3, 'pre-trained': 2, 'lightweight': 2, 'discriminative': 2, 'small': 3, 'neural': 1, 'efficient': 1, 'autoregressive': 2, 'generative': 2, 'shallow': 1, 'large': 3, 'recurrent': 1}, ('processes', 'large'): {'amounts': 16}, ('network', 'sequentially'): {'represents': 1, 'reduces': 2, 'minimizes': 2, 'samples': 1, 'predicts': 1, 'evaluates': 1, 'computes': 1}, ('of', 'word'): {'co-occurrences': 110}, ('maximizes', 'statistical'): {'patterns': 11}, ('loss', 'sequentially'): {'a': 3, 'the': 4, 'smoothing': 1, 'moreover': 1, 'nevertheless': 1}, ('calculates', 'the'): {'learning': 14, 'training': 8, 'batch': 19, 'loss': 12, 'probability': 15, 'bias': 15, 'next': 9, 'vocabulary': 14, 'weight': 19, 'cross': 21, 'softmax': 11, 'gradient': 8, 'hidden': 21, 'activation': 10, 'corpus': 15}, ('layer', 'gradually'): {'optimizes': 1, 'improves': 2}, ('mechanism', 'tokenizes'): {'word': 2, 'the': 9, 'semantic': 3}, ('sequentially', 'minimizes'): {'the': 7, 'word': 1, 'sentence': 2}, ('terms', 'automatically'): {'bigram': 1, 'training': 1, 'as': 1, 'a': 3, 'however': 1, 'the': 3, 'tokenization': 1, 'overfitting': 1, 'word': 1}, ('function', 'additionally'): {'the': 2}, ('probabilistically', 'samples'): {'the': 2, 'large': 1}, ('patterns', 'a'): {'lightweight': 9, 'robust': 11, 'transformer-based': 9, 'bidirectional': 9, 'generative': 9, 'small': 7, 'scalable': 6, 'neural': 8, 'shallow': 9, 'autoregressive': 9, 'statistical': 8, 'language': 5, 'efficient': 5, 'pre-trained': 6, 'deep': 5, 'powerful': 8, 'accurate': 5, 'large': 5, 'discriminative': 2, 'recurrent': 5, 'fine-tuned': 3}, ('tokenizer', 'models'): {'the': 7, 'token': 1, 'contextual': 2, 'linguistic': 1}, ('word', 'specifically'): {'the': 7}, ('prediction', 'sequentially'): {'increases': 2, 'minimizes': 1, 'represents': 1, 'overfits': 1, 'optimizes': 1, 'decodes': 1}, ('bigram', 'adjusts'): {'co-occurrence': 1, 'the': 4, 'syntactic': 1}, ('algorithm', 'encodes'): {'statistical': 1, 'large': 1, 'the': 6, 'token': 1, 'linguistic': 2, 'sentence': 1, 'semantic': 1}, ('represents', 'token'): {'sequences': 17}, ('probabilistically', 'the'): {'neural': 8, 'sequence': 5, 'system': 3, 'context': 7, 'architecture': 8, 'output': 6, 'input': 7, 'bigram': 6, 'gradient': 7, 'algorithm': 4, 'vocabulary': 9, 'corpus': 6, 'frequency': 6, 'perplexity': 7, 'prediction': 7, 'researcher': 11, 'model': 5, 'tokenizer': 6, 'embedding': 6, 'attention': 2, 'probability': 7, 'dataset': 5, 'training': 8, 'language': 2, 'weight': 6, 'trigram': 4, 'text': 3, 'optimizer': 5, 'n-gram': 2, 'loss': 3, 'evaluation': 4, 'softmax': 2}, ('rate', 'overfitting'): {'occurs': 1}, ('continuously', 'regularization'): {'techniques': 2}, ('probability', 'captures'): {'the': 6, 'language': 1, 'contextual': 1, 'word': 1, 'large': 1}, ('descent', 'probabilistically'): {'a': 3, 'the': 6, 'in': 1, 'however': 1, 'nevertheless': 1}, ('function', 'cross'): {'entropy': 2}, ('significantly', 'specifically'): {'the': 5}, ('successfully', 'updates'): {'large': 3, 'the': 3, 'language': 1, 'sentence': 1}, ('rapidly', 'captures'): {'linguistic': 1, 'co-occurrence': 2, 'the': 1}, ('efficiently', 'predicts'): {'the': 8, 'syntactic': 1, 'word': 1, 'millions': 2}, ('sequentially', 'overfitting'): {'occurs': 2}, ('corpus', 'accurately'): {'decodes': 2, 'a': 4, 'calculates': 1, 'adjusts': 2, 'overfitting': 2, 'the': 2, 'outputs': 1, 'in': 1}, ('backpropagation', 'adjusts'): {'the': 5, 'co-occurrence': 1, 'semantic': 1, 'statistical': 1}, ('effectively', 'furthermore'): {'the': 2, 'backpropagation': 1}, ('architecture', 'accurately'): {'processes': 1, 'maximizes': 1, 'diverges': 1}, ('probabilistically', 'improves'): {'syntactic': 1, 'large': 1, 'the': 4, 'word': 1, 'millions': 1, 'statistical': 1}, ('probabilistically', 'overfits'): {'the': 1}, ('a', 'continuous'): {'space': 88}, ('generalizes', 'semantic'): {'meaning': 8}, ('gradient', 'evaluates'): {'token': 3, 'the': 3, 'word': 1, 'syntactic': 1}, ('rate', 'continuously'): {'backpropagation': 1, 'meanwhile': 1, 'the': 6, 'a': 2, 'in': 1, 'regularization': 1, 'consequently': 1, 'additionally': 1}, ('perplexity', 'recursively'): {'maximizes': 2, 'captures': 1}, ('metric', 'significantly'): {'overfits': 1, 'improves': 2, 'optimizes': 1, 'converges': 1, 'captures': 1, 'samples': 1, 'represents': 2, 'processes': 1, 'trains': 1, 'maximizes': 1, 'generates': 1}, ('sequentially', 'smoothing'): {'techniques': 5}, ('model', 'evaluates'): {'word': 3, 'statistical': 1, 'the': 10, 'semantic': 2, 'sentence': 1, 'linguistic': 1, 'co-occurrence': 1, 'token': 1, 'language': 1}, ('sequentially', 'maximizes'): {'syntactic': 1, 'the': 6, 'semantic': 1, 'word': 1}, ('bigram', 'fine-tunes'): {'linguistic': 1, 'the': 5, 'large': 1, 'semantic': 1, 'contextual': 1}, ('automatically', 'transfer'): {'learning': 4}, ('parameters', 'efficiently'): {'the': 7, 'training': 1, 'in': 1, 'nevertheless': 2, 'therefore': 1, 'furthermore': 1, 'a': 5, 'as': 1}, ('previous', 'words'): {'influence': 90}, ('ability', 'similarly'): {'the': 2}, ('corpus', 'data'): {'preprocessing': 2}, ('embeddings', 'successfully'): {'the': 6, 'for': 1, 'similarly': 1, 'a': 3, 'cross': 1, 'furthermore': 1, 'in': 1, 'as': 1}, ('process', 'encodes'): {'contextual': 1, 'the': 3, 'token': 1, 'linguistic': 2, 'language': 1}, ('system', 'effectively'): {'predicts': 1, 'updates': 1, 'learns': 1, 'encodes': 1, 'tokenizes': 1, 'improves': 1, 'maximizes': 2, 'overfits': 1}, ('patterns', 'similarly'): {'the': 4}, ('algorithm', 'computes'): {'sentence': 4, 'the': 7, 'language': 1}, ('backpropagation', 'fine-tunes'): {'the': 6, 'large': 1, 'statistical': 1, 'linguistic': 1, 'millions': 1}, ('example', 'backpropagation'): {'increases': 1, 'generalizes': 1, 'generates': 1, 'maximizes': 1, 'reduces': 1}, ('pipeline', 'meanwhile'): {'backpropagation': 1, 'the': 1}, ('states', 'a'): {'scalable': 4, 'lightweight': 2, 'robust': 2, 'language': 2, 'deep': 2, 'generative': 4, 'discriminative': 3, 'accurate': 6, 'bidirectional': 3, 'efficient': 2, 'transformer-based': 4, 'shallow': 2, 'pre-trained': 2, 'statistical': 2, 'powerful': 1, 'small': 1, 'large': 2, 'autoregressive': 1, 'fine-tuned': 1}, ('models', 'syntactic'): {'rules': 12}, ('network', 'encodes'): {'contextual': 1, 'sentence': 1, 'linguistic': 3, 'the': 6, 'co-occurrence': 1, 'syntactic': 1}, ('layer', 'calculates'): {'the': 7, 'language': 1, 'co-occurrence': 2, 'word': 1, 'semantic': 1, 'contextual': 1}, ('correctly', 'consequently'): {'the': 3}, ('statistically', 'however'): {'the': 7}, ('value', 'successfully'): {'meanwhile': 2, 'a': 5, 'consequently': 2, 'specifically': 1, 'the': 4, 'similarly': 1, 'perplexity': 1}, ('process', 'minimizes'): {'the': 2, 'co-occurrence': 1, 'sentence': 2, 'word': 1}, ('sequence', 'maximizes'): {'the': 4, 'co-occurrence': 1}, ('model', 'meanwhile'): {'the': 2}, ('size', 'however'): {'the': 7}, ('statistically', 'nevertheless'): {'the': 3}, ('input', 'automatically'): {'trains': 1, 'predicts': 1, 'calculates': 2, 'encodes': 1, 'increases': 1, 'tokenizes': 1}, ('continuously', 'updates'): {'the': 5}, ('sequence', 'continuously'): {'maximizes': 2, 'predicts': 1, 'increases': 1, 'converges': 1, 'captures': 1, 'outputs': 1, 'overfits': 1, 'decodes': 1}, ('vocabulary', 'generalizes'): {'the': 5, 'word': 1}, ('trigram', 'efficiently'): {'generalizes': 1, 'processes': 1, 'evaluates': 1, 'captures': 1}, ('network', 'minimizes'): {'the': 10, 'millions': 2, 'word': 1, 'large': 1, 'linguistic': 2}, ('n-gram', 'automatically'): {'adjusts': 1, 'fine-tunes': 1, 'evaluates': 1, 'optimizes': 1, 'decodes': 1}, ('prediction', 'encodes'): {'linguistic': 1, 'the': 6, 'semantic': 2, 'language': 1, 'sentence': 1, 'millions': 1}, ('backpropagation', 'efficiently'): {'samples': 1, 'updates': 1, 'encodes': 1, 'learns': 1, 'decodes': 1}, ('size', 'nevertheless'): {'the': 1}, ('text', 'into'): {'meaningful': 82, 'any': 99}, ('automatically', 'in'): {'contrast': 6, 'addition': 4}, ('system', 'samples'): {'the': 7, 'large': 2, 'word': 1}, ('terms', 'however'): {'the': 2}, ('on', 'linguistic'): {'features': 17}, ('fine-tunes', 'language'): {'patterns': 12}, ('a', 'small'): {'language': 109, 'the': 128, 'backpropagation': 9}, ('the', 'training'): {'loss': 94, 'data': 373, 'process': 367, 'pipeline': 98, 'corpus': 92, 'loop': 104}, ('gradually', 'minimizes'): {'sentence': 1, 'word': 1, 'co-occurrence': 1, 'the': 2}, ('prediction', 'minimizes'): {'the': 4, 'word': 1}, ('features', 'bigram'): {'and': 3}, ('terms', 'nevertheless'): {'the': 4, 'backpropagation': 1}, ('powerful', 'backpropagation'): {'generates': 1, 'outputs': 1, 'models': 1, 'processes': 1, 'calculates': 1, 'learns': 1, 'represents': 1}, ('information', 'effectively'): {'a': 2, 'the': 6, 'subsequently': 3, 'tokenization': 1, 'for': 1}, ('function', 'converts'): {'raw': 97}, ('sequence', 'captures'): {'the': 6, 'semantic': 2, 'syntactic': 1}, ('recursively', 'reduces'): {'the': 3, 'word': 1, 'token': 1, 'contextual': 1}, ('size', 'significantly'): {'meanwhile': 1, 'the': 11, 'a': 3, 'however': 1, 'feeding': 1, 'therefore': 1}, ('continuously', 'diverges'): {'the': 3, 'language': 1}, ('gradient', 'increases'): {'the': 4, 'sentence': 2, 'syntactic': 2}, ('states', 'gradually'): {'similarly': 1, 'specifically': 2, 'a': 5, 'the': 8, 'consequently': 1, 'furthermore': 1, 'perplexity': 1, 'cross': 1, 'regularization': 1}, ('terms', 'statistically'): {'a': 3, 'the': 8, 'therefore': 1, 'as': 1, 'furthermore': 1, 'nevertheless': 1, 'additionally': 1}, ('recursively', 'training'): {'a': 4}, ('recursively', 'tokenizes'): {'contextual': 1, 'semantic': 1, 'millions': 1, 'language': 1}, ('features', 'iteratively'): {'a': 2, 'training': 1, 'the': 1, 'meanwhile': 1, 'for': 1, 'however': 1}, ('recursively', 'therefore'): {'the': 5}, ('probability', 'generalizes'): {'the': 4, 'semantic': 1, 'language': 2}, ('model', 'increases'): {'the': 8, 'contextual': 2, 'co-occurrence': 1, 'millions': 1, 'semantic': 1, 'sentence': 1, 'linguistic': 1, 'word': 1}, ('process', 'computes'): {'sentence': 2, 'the': 3, 'word': 2, 'contextual': 1, 'millions': 1, 'co-occurrence': 1, 'token': 1}, ('algorithm', 'successfully'): {'fine-tunes': 1, 'evaluates': 1, 'optimizes': 1, 'overfits': 1, 'captures': 1, 'converges': 1, 'updates': 2, 'adjusts': 1}, ('distribution', 'the'): {'probability': 3, 'prediction': 3, 'training': 7, 'gradient': 6, 'algorithm': 7, 'system': 7, 'corpus': 4, 'optimizer': 5, 'text': 8, 'embedding': 6, 'context': 1, 'architecture': 4, 'model': 7, 'attention': 6, 'output': 7, 'evaluation': 2, 'frequency': 3, 'tokenizer': 8, 'n-gram': 5, 'input': 4, 'loss': 4, 'softmax': 2, 'trigram': 4, 'bigram': 2, 'dataset': 2, 'sequence': 5, 'neural': 2, 'weight': 4, 'language': 3, 'perplexity': 2, 'vocabulary': 1, 'researcher': 1}, ('corpus', 'probabilistically'): {'the': 5, 'fine-tunes': 1, 'a': 3, 'evaluates': 2, 'optimizes': 1, 'moreover': 2, 'tokenizes': 1, 'transfer': 1, 'models': 1}, ('gradient', 'optimizes'): {'statistical': 2, 'word': 2, 'token': 2, 'the': 5, 'syntactic': 1, 'semantic': 1}, ('iteratively', 'gradient'): {'descent': 2}, ('rapidly', 'generalizes'): {'the': 2, 'statistical': 1, 'co-occurrence': 1, 'linguistic': 1}, ('architecture', 'probabilistically'): {'updates': 1, 'decodes': 1, 'reduces': 1}, ('gradient', 'iteratively'): {'decodes': 1, 'reduces': 1, 'processes': 1, 'updates': 1, 'encodes': 1, 'captures': 1, 'fine-tunes': 1, 'outputs': 1}, ('significantly', 'encodes'): {'sentence': 1, 'millions': 1, 'semantic': 1, 'the': 1, 'contextual': 1}, ('iteratively', 'tokenizes'): {'the': 2, 'millions': 1, 'contextual': 1}, ('gradually', 'overfitting'): {'occurs': 2}, ('text', 'consequently'): {'the': 6}, ('iteratively', 'therefore'): {'the': 1}, ('layer', 'outputs'): {'contextual': 1, 'the': 5, 'statistical': 1, 'millions': 1, 'large': 1, 'token': 1}, ('parameters', 'gradient'): {'descent': 1}, ('model', 'optimizes'): {'contextual': 1, 'word': 1, 'token': 1, 'language': 2, 'the': 5, 'syntactic': 1, 'semantic': 2, 'linguistic': 1, 'co-occurrence': 1, 'statistical': 1}, ('states', 'similarly'): {'the': 2}, ('improves', 'linguistic'): {'features': 13}, ('model', 'iteratively'): {'predicts': 2, 'calculates': 1, 'adjusts': 1, 'updates': 1, 'represents': 1, 'reduces': 1}, ('loss', 'smoothing'): {'techniques': 2}, ('generalizes', 'the'): {'training': 10, 'weight': 15, 'cross': 15, 'loss': 13, 'gradient': 10, 'next': 18, 'softmax': 18, 'activation': 18, 'corpus': 14, 'learning': 9, 'probability': 11, 'vocabulary': 7, 'hidden': 10, 'batch': 18, 'bias': 11}, ('network', 'maximizes'): {'co-occurrence': 1, 'the': 5, 'large': 2}, ('vocabulary', 'samples'): {'the': 2, 'millions': 2, 'language': 1, 'semantic': 3, 'linguistic': 2}, ('correctly', 'specifically'): {'the': 7}, ('features', 'perplexity'): {'measures': 3}, ('iteratively', 'learns'): {'from': 7}, ('a', 'result'): {'the': 191, 'backpropagation': 3}, ('iteratively', 'generates'): {'millions': 2, 'the': 5, 'word': 1, 'large': 1, 'token': 1}, ('meaning', 'successfully'): {'the': 11, 'a': 5, 'backpropagation': 1}, ('gradually', 'smoothing'): {'techniques': 3}, ('window', 'tokenizes'): {'sentence': 1, 'word': 2, 'the': 4, 'language': 1, 'linguistic': 1}, ('output', 'represents'): {'statistical': 1, 'the': 8, 'contextual': 1, 'syntactic': 1, 'linguistic': 1}, ('rapidly', 'converges'): {'the': 6, 'statistical': 1, 'token': 1}, ('gradually', 'maximizes'): {'word': 1, 'the': 3, 'semantic': 1}, ('converges', 'sentence'): {'structure': 16}, ('overfitting', 'occurs'): {'when': 104}, ('mechanism', 'probabilistically'): {'adjusts': 1, 'models': 1, 'maximizes': 1, 'predicts': 2, 'represents': 1}, ('efficiently', 'processes'): {'the': 2, 'syntactic': 2, 'millions': 2, 'statistical': 1}, ('weight', 'adjusts'): {'the': 6, 'co-occurrence': 2, 'semantic': 1, 'syntactic': 1}, ('frequencies', 'a'): {'statistical': 5, 'generative': 3, 'efficient': 4, 'powerful': 4, 'lightweight': 2, 'small': 3, 'large': 3, 'shallow': 2, 'fine-tuned': 2, 'robust': 2, 'deep': 1, 'accurate': 6, 'recurrent': 1, 'bidirectional': 2, 'language': 1, 'transformer-based': 2, 'scalable': 3, 'discriminative': 1}, ('modeling', 'consequently'): {'the': 1}, ('successfully', 'backpropagation'): {'recursively': 1, 'models': 1}, ('n-gram', 'rapidly'): {'converges': 1, 'overfits': 2, 'evaluates': 1, 'calculates': 1}, ('diverges', 'sentence'): {'structure': 13}, ('vocabulary', 'improves'): {'sentence': 1, 'the': 5, 'word': 1, 'syntactic': 1}, ('models', 'from'): {'memorizing': 92}, ('vocabulary', 'overfits'): {'word': 1, 'semantic': 3, 'the': 7, 'co-occurrence': 2, 'large': 1}, ('loss', 'regularization'): {'techniques': 4}, ('effectively', 'evaluates'): {'large': 1, 'the': 1}, ('probability', 'samples'): {'large': 1, 'the': 4, 'language': 1, 'semantic': 1}, ('dataset', 'reduces'): {'language': 2, 'semantic': 2, 'the': 4, 'word': 1, 'contextual': 1}, ('increases', 'statistical'): {'patterns': 14}, ('sequentially', 'diverges'): {'syntactic': 2, 'the': 1}, ('embeddings', 'correctly'): {'the': 2, 'meanwhile': 1, 'furthermore': 1, 'perplexity': 1, 'a': 2, 'subsequently': 1, 'similarly': 1, 'regularization': 1, 'as': 1}, ('algorithm', 'updates'): {'sentence': 1, 'the': 3, 'token': 1, 'word': 1, 'syntactic': 1}, ('process', 'successfully'): {'computes': 1, 'samples': 2, 'adjusts': 2, 'reduces': 1, 'represents': 1, 'evaluates': 3, 'fine-tunes': 1, 'generalizes': 1}, ('descent', 'gradually'): {'consequently': 1, 'the': 5, 'a': 3, 'in': 1, 'subsequently': 1, 'additionally': 1, 'furthermore': 1, 'tokenization': 1}, ('researcher', 'captures'): {'the': 8, 'millions': 1, 'statistical': 1}, ('pipeline', 'in'): {'addition': 3, 'contrast': 1}, ('tokenizer', 'maximizes'): {'large': 3, 'syntactic': 1, 'language': 2, 'the': 1, 'word': 1}, ('text', 'subsequently'): {'the': 9}, ('system', 'evaluates'): {'the': 6, 'millions': 1, 'language': 1, 'co-occurrence': 2, 'semantic': 1}, ('significantly', 'computes'): {'sentence': 1, 'semantic': 1, 'the': 1}, ('network', 'successfully'): {'improves': 1, 'adjusts': 1, 'calculates': 2, 'optimizes': 1, 'generates': 1, 'learns': 1}, ('tokenizer', 'continuously'): {'adjusts': 1, 'tokenizes': 1, 'increases': 1, 'maximizes': 1, 'generates': 1}, ('loss', 'successfully'): {'the': 6, 'smoothing': 2, 'feeding': 2, 'cross': 1, 'nevertheless': 1, 'a': 1, 'similarly': 1, 'transfer': 1, 'data': 1}, ('trigram', 'learns'): {'from': 9}, ('output', 'a'): {'robust': 5, 'recurrent': 1, 'neural': 1, 'transformer-based': 2, 'generative': 6, 'lightweight': 3, 'language': 4, 'discriminative': 1, 'statistical': 1, 'bidirectional': 3, 'shallow': 1, 'scalable': 3, 'efficient': 5, 'autoregressive': 1}, ('trigram', 'generates'): {'the': 3, 'word': 1, 'millions': 1}, ('backpropagation', 'learns'): {'from': 16}, ('value', 'correctly'): {'specifically': 2, 'the': 9, 'additionally': 1, 'in': 1}, ('probabilistically', 'transfer'): {'learning': 5}, ('backpropagation', 'generates'): {'language': 3, 'token': 2, 'the': 6, 'linguistic': 1, 'statistical': 1, 'syntactic': 1, 'sentence': 1}, ('text', 'specifically'): {'the': 8}, ('input', 'statistically'): {'reduces': 1, 'calculates': 1, 'increases': 1, 'trains': 1, 'generalizes': 1, 'improves': 1}, ('probability', 'improves'): {'the': 7, 'millions': 2, 'co-occurrence': 1}, ('probability', 'overfits'): {'the': 3, 'word': 1, 'language': 2, 'syntactic': 1, 'millions': 1}, ('prediction', 'successfully'): {'generates': 1, 'trains': 2, 'decodes': 1, 'captures': 1, 'evaluates': 1}, ('n-gram', 'statistically'): {'evaluates': 1, 'trains': 1, 'minimizes': 2, 'overfits': 2, 'calculates': 1, 'maximizes': 1, 'computes': 1}, ('parameters', 'accurately'): {'overfitting': 2, 'a': 3, 'tokenization': 1, 'the': 4, 'as': 1}, ('automatically', 'moreover'): {'the': 2}, ('effectively', 'meanwhile'): {'the': 4}, ('generates', 'co-occurrence'): {'matrices': 11}, ('architecture', 'represents'): {'the': 6, 'millions': 2, 'word': 1, 'large': 2}, ('accurately', 'represents'): {'the': 4, 'linguistic': 1, 'word': 1, 'statistical': 1, 'millions': 1}, ('descent', 'bigram'): {'and': 1}, ('tokenizer', 'captures'): {'language': 1, 'the': 2, 'semantic': 1, 'sentence': 1}, ('recursively', 'data'): {'preprocessing': 7}, ('modeling', 'subsequently'): {'backpropagation': 1, 'the': 3}, ('algorithm', 'used'): {'to': 94}, ('training', 'pipeline'): {'a': 18, 'subsequently': 2, 'therefore': 3, 'for': 4, 'meanwhile': 2, 'as': 1, 'the': 48, 'in': 4, 'additionally': 4, 'nevertheless': 2, 'backpropagation': 3, 'similarly': 1, 'moreover': 1, 'specifically': 3, 'consequently': 1, 'however': 1}, ('data', 'continuously'): {'the': 3, 'a': 3, 'word': 1, 'consequently': 1, 'in': 1}, ('size', 'word'): {'embeddings': 1}, ('a', 'valid'): {'probability': 97}, ('space', 'a'): {'neural': 1, 'lightweight': 1, 'generative': 1, 'bidirectional': 4, 'robust': 2, 'efficient': 2, 'transformer-based': 2, 'statistical': 1, 'large': 1, 'deep': 1, 'accurate': 1, 'recurrent': 1, 'scalable': 1, 'autoregressive': 1}, ('weight', 'efficiently'): {'improves': 1, 'represents': 1, 'encodes': 2, 'reduces': 1, 'samples': 1, 'computes': 1, 'generalizes': 1, 'predicts': 1}, ('significantly', 'regularization'): {'techniques': 2}, ('continuously', 'backpropagation'): {'continuously': 1, 'represents': 2, 'significantly': 1, 'evaluates': 1, 'maximizes': 1, 'predicts': 1, 'statistically': 1}, ('iteratively', 'data'): {'preprocessing': 4}, ('features', 'additionally'): {'the': 2}, ('word', 'successfully'): {'a': 1, 'the': 4, 'training': 1, 'data': 1, 'smoothing': 1}, ('process', 'updates'): {'the': 6, 'semantic': 2, 'statistical': 1, 'word': 1, 'large': 1, 'language': 1}, ('structure', 'overfitting'): {'occurs': 2}, ('sequence', 'converges'): {'large': 1, 'the': 2, 'token': 1, 'millions': 1, 'word': 1}, ('function', 'gradient'): {'descent': 2}, ('outputs', 'millions'): {'of': 10}, ('ability', 'consequently'): {'the': 1}, ('function', 'tokenizes'): {'statistical': 3, 'the': 4, 'millions': 1, 'word': 1, 'linguistic': 1, 'semantic': 1}, ('layer', 'adjusts'): {'the': 5, 'semantic': 1, 'sentence': 1}, ('trigram', 'accurately'): {'improves': 1, 'calculates': 2, 'fine-tunes': 1, 'diverges': 1}, ('network', 'updates'): {'language': 1, 'the': 3, 'semantic': 2, 'sentence': 1}, ('pipeline', 'additionally'): {'the': 4}, ('function', 'therefore'): {'the': 3}, ('successfully', 'feeding'): {'diverse': 2}, ('probabilistically', 'in'): {'addition': 4, 'contrast': 5}, ('algorithm', 'correctly'): {'generalizes': 1, 'outputs': 1, 'converges': 1, 'updates': 3, 'decodes': 1}, ('optimizer', 'sequentially'): {'decodes': 2, 'predicts': 1, 'diverges': 1, 'fine-tunes': 2}, ('backpropagation', 'accurately'): {'predicts': 1, 'diverges': 1}, ('words', 'meanwhile'): {'the': 4}, ('features', 'cross'): {'entropy': 1}, ('effectively', 'increases'): {'the': 4}, ('descent', 'perplexity'): {'measures': 2}, ('structure', 'smoothing'): {'techniques': 2}, ('large', 'backpropagation'): {'increases': 1, 'models': 1, 'decodes': 1}, ('model', 'additionally'): {'the': 7}, ('accurately', 'a'): {'neural': 4, 'robust': 5, 'fine-tuned': 4, 'autoregressive': 4, 'language': 8, 'generative': 6, 'pre-trained': 5, 'discriminative': 4, 'statistical': 4, 'transformer-based': 4, 'recurrent': 2, 'accurate': 4, 'lightweight': 5, 'small': 2, 'shallow': 2, 'scalable': 6, 'bidirectional': 4, 'powerful': 3, 'large': 2, 'deep': 2, 'efficient': 1}, ('recursively', 'furthermore'): {'the': 6}, ('embeddings', 'backpropagation'): {'correctly': 1}, ('correctly', 'encodes'): {'semantic': 1, 'statistical': 1, 'the': 2}, ('patterns', 'consequently'): {'the': 11}, ('computes', 'language'): {'patterns': 16}, ('prediction', 'updates'): {'the': 2, 'word': 1, 'statistical': 1, 'language': 1}, ('function', 'learns'): {'from': 11}, ('function', 'generates'): {'the': 8, 'large': 1, 'word': 1, 'statistical': 1, 'syntactic': 1, 'co-occurrence': 1, 'sentence': 1}, ('structure', 'continuously'): {'backpropagation': 1, 'a': 4, 'training': 1, 'moreover': 1, 'the': 1, 'transfer': 1, 'specifically': 1}, ('process', 'diverges'): {'the': 9, 'semantic': 1, 'word': 1}, ('converges', 'language'): {'patterns': 10}, ('system', 'increases'): {'the': 2, 'statistical': 1, 'linguistic': 1}, ('effectively', 'optimizes'): {'the': 3, 'statistical': 1, 'language': 1, 'word': 1, 'contextual': 1, 'token': 1}, ('information', 'meanwhile'): {'backpropagation': 1, 'the': 3}, ('minimizes', 'syntactic'): {'rules': 17}, ('on', 'semantic'): {'meaning': 14}, ('matrix', 'smoothing'): {'techniques': 1}, ('probabilistically', 'however'): {'the': 9}, ('frequencies', 'recursively'): {'the': 5, 'a': 4, 'as': 3, 'smoothing': 1}, ('network', 'diverges'): {'millions': 1, 'contextual': 1, 'the': 3, 'co-occurrence': 1, 'sentence': 1}, ('correctly', 'minimizes'): {'co-occurrence': 2, 'the': 3}, ('value', 'backpropagation'): {'models': 1, 'updates': 1, 'effectively': 1, 'predicts': 1}, ('matrix', 'continuously'): {'a': 2, 'the': 4, 'in': 2, 'for': 1, 'furthermore': 1, 'moreover': 1}, ('system', 'optimizes'): {'language': 1, 'the': 9, 'word': 1, 'co-occurrence': 1}, ('mechanism', 'evaluates'): {'word': 2, 'the': 4, 'token': 1, 'contextual': 1}, ('system', 'iteratively'): {'decodes': 2, 'predicts': 2, 'diverges': 1, 'generates': 1, 'minimizes': 1, 'fine-tunes': 1, 'converges': 1, 'outputs': 1}, ('layer', 'fine-tunes'): {'the': 6, 'language': 2, 'semantic': 1, 'word': 1, 'statistical': 1, 'large': 1}, ('calculates', 'statistical'): {'patterns': 9}, ('gradually', 'diverges'): {'word': 1, 'the': 4, 'sentence': 1, 'language': 1}, ('fine-tunes', 'syntactic'): {'rules': 13}, ('perplexity', 'sequentially'): {'improves': 2, 'updates': 2, 'decodes': 1, 'learns': 1, 'overfits': 1}, ('prediction', 'diverges'): {'the': 5, 'language': 1, 'token': 1, 'co-occurrence': 1}, ('researcher', 'generalizes'): {'the': 7, 'millions': 1, 'syntactic': 1}, ('distribution', 'automatically'): {'the': 7, 'in': 1, 'regularization': 1}, ('corpus', 'gradually'): {'a': 4, 'cross': 1, 'data': 1, 'the': 6, 'moreover': 2, 'therefore': 1, 'predicts': 2, 'as': 1, 'smoothing': 1, 'minimizes': 1, 'samples': 1, 'generates': 1}, ('architecture', 'gradually'): {'converges': 2, 'samples': 2, 'predicts': 1, 'generalizes': 1, 'diverges': 1, 'models': 1, 'maximizes': 1}, ('efficiently', 'trains'): {'on': 11}, ('updates', 'model'): {'weights': 104}, ('pipeline', 'moreover'): {'the': 1}, ('significantly', 'updates'): {'the': 3, 'semantic': 1, 'word': 1}, ('output', 'recursively'): {'a': 4, 'gradient': 1, 'the': 7, 'generates': 1, 'overfitting': 1, 'diverges': 1, 'trains': 1, 'encodes': 1, 'outputs': 1}, ('overfits', 'language'): {'patterns': 11}, ('input', 'to'): {'the': 98}, ('parameters', 'probabilistically'): {'perplexity': 1, 'the': 5, 'furthermore': 1, 'a': 4, 'specifically': 1, 'word': 2, 'therefore': 1, 'as': 1}, ('continuously', 'feeding'): {'diverse': 5}, ('training', 'a'): {'small': 109}, ('function', 'accurately'): {'fine-tunes': 1, 'captures': 1, 'as': 1, 'a': 5, 'the': 6, 'generates': 1, 'diverges': 1, 'generalizes': 1, 'nevertheless': 1, 'adjusts': 1}, ('sequentially', 'predicts'): {'the': 8, 'millions': 1, 'word': 1, 'syntactic': 1, 'semantic': 1}, ('ability', 'specifically'): {'the': 3}, ('vocabulary', 'automatically'): {'models': 1, 'learns': 2, 'predicts': 1, 'represents': 1, 'processes': 1, 'outputs': 1, 'encodes': 1}, ('rules', 'nevertheless'): {'the': 2}, ('activation', 'function'): {'sequentially': 17, 'continuously': 17, 'recursively': 11, 'automatically': 13, 'gradually': 7, 'a': 37, 'subsequently': 4, 'probabilistically': 17, 'the': 76, 'correctly': 15, 'iteratively': 12, 'similarly': 5, 'successfully': 12, 'smoothing': 2, 'nevertheless': 5, 'training': 2, 'efficiently': 10, 'overfitting': 4, 'statistically': 11, 'therefore': 3, 'consequently': 4, 'furthermore': 4, 'as': 5, 'in': 2, 'gradient': 2, 'effectively': 10, 'for': 4, 'tokenization': 1, 'meanwhile': 2, 'additionally': 2, 'perplexity': 2, 'rapidly': 14, 'specifically': 3, 'accurately': 13, 'significantly': 4, 'cleaning': 3, 'backpropagation': 3, 'however': 2, 'regularization': 4, 'feeding': 1, 'moreover': 2, 'transfer': 1, 'cross': 2, 'bigram': 1}, ('researcher', 'converges'): {'sentence': 2, 'millions': 1, 'the': 3, 'language': 2, 'contextual': 1, 'large': 1}, ('optimizes', 'millions'): {'of': 15}, ('the', 'researcher'): {'improves': 13, 'trains': 6, 'diverges': 12, 'encodes': 15, 'tokenizes': 8, 'captures': 10, 'decodes': 13, 'automatically': 5, 'updates': 8, 'fine-tunes': 13, 'samples': 12, 'evaluates': 8, 'recursively': 7, 'adjusts': 10, 'optimizes': 8, 'gradually': 7, 'statistically': 5, 'maximizes': 12, 'processes': 10, 'outputs': 11, 'continuously': 10, 'iteratively': 7, 'effectively': 6, 'successfully': 10, 'generalizes': 9, 'increases': 12, 'represents': 13, 'minimizes': 10, 'predicts': 19, 'significantly': 4, 'converges': 10, 'models': 10, 'reduces': 7, 'generates': 5, 'efficiently': 7, 'correctly': 4, 'probabilistically': 7, 'sequentially': 8, 'learns': 5, 'calculates': 4, 'computes': 3, 'overfits': 3, 'rapidly': 4, 'accurately': 1}, ('efficiently', 'models'): {'large': 1, 'statistical': 1, 'sentence': 2, 'co-occurrence': 1, 'the': 2}, ('correctly', 'computes'): {'the': 2, 'sentence': 1}, ('window', 'probabilistically'): {'outputs': 2, 'reduces': 2, 'represents': 1, 'calculates': 1, 'increases': 1, 'computes': 1, 'converges': 1, 'evaluates': 1, 'improves': 1, 'maximizes': 1}, ('accurately', 'similarly'): {'the': 4}, ('information', 'iteratively'): {'consequently': 2, 'a': 7, 'subsequently': 1, 'the': 3, 'furthermore': 1, 'cross': 1, 'training': 1}, ('of', 'the'): {'language': 108}, ('processes', 'language'): {'patterns': 14}, ('corpus', 'bigram'): {'and': 2}, ('patterns', 'specifically'): {'the': 7}, ('states', 'consequently'): {'the': 4}, ('rules', 'significantly'): {'specifically': 1, 'a': 4, 'regularization': 1, 'consequently': 1, 'tokenization': 1, 'moreover': 1}, ('optimizer', 'encodes'): {'millions': 2, 'word': 1, 'statistical': 1, 'the': 2, 'language': 1}, ('effectively', 'cleaning'): {'and': 5}, ('information', 'transfer'): {'learning': 2}, ('weight', 'learns'): {'from': 6}, ('weight', 'generates'): {'syntactic': 1, 'the': 4, 'linguistic': 1, 'large': 2, 'word': 3, 'contextual': 1}, ('embeddings', 'feeding'): {'diverse': 5}, ('sequence', 'predicts'): {'millions': 1, 'the': 11, 'co-occurrence': 2, 'sentence': 1, 'linguistic': 1, 'word': 1, 'contextual': 1, 'syntactic': 1}, ('dataset', 'effectively'): {'samples': 1, 'generates': 1, 'trains': 1, 'optimizes': 1}, ('probability', 'automatically'): {'calculates': 1, 'predicts': 2, 'converges': 1, 'improves': 2, 'decodes': 1, 'diverges': 1, 'samples': 1, 'fine-tunes': 1}, ('trigram', 'probabilistically'): {'represents': 1, 'converges': 1, 'evaluates': 1, 'models': 2, 'decodes': 1, 'reduces': 1}, ('tokenizer', 'converges'): {'the': 7, 'large': 1, 'co-occurrence': 1, 'language': 1, 'linguistic': 1}, ('increases', 'linguistic'): {'features': 14}, ('statistically', 'reduces'): {'the': 6, 'co-occurrence': 1}, ('embeddings', 'recursively'): {'a': 6, 'meanwhile': 1, 'the': 8, 'regularization': 1}, ('training', 'process'): {'gradually': 9, 'updates': 12, 'maximizes': 8, 'rapidly': 6, 'diverges': 11, 'evaluates': 8, 'encodes': 8, 'successfully': 12, 'tokenizes': 11, 'efficiently': 6, 'generates': 13, 'automatically': 7, 'accurately': 10, 'iteratively': 7, 'captures': 9, 'optimizes': 8, 'computes': 11, 'calculates': 6, 'processes': 5, 'improves': 12, 'minimizes': 6, 'increases': 8, 'predicts': 21, 'generalizes': 2, 'reduces': 8, 'statistically': 5, 'fine-tunes': 7, 'samples': 11, 'decodes': 12, 'adjusts': 11, 'trains': 8, 'models': 8, 'converges': 10, 'continuously': 5, 'overfits': 7, 'sequentially': 4, 'recursively': 9, 'represents': 7, 'learns': 9, 'significantly': 5, 'outputs': 10, 'probabilistically': 7, 'effectively': 4, 'correctly': 4}, ('word', 'correctly'): {'a': 2, 'the': 5, 'gradient': 1}, ('correctly', 'regularization'): {'techniques': 2}, ('patterns', 'sequentially'): {'transfer': 1, 'the': 14, 'perplexity': 1, 'a': 5, 'specifically': 1, 'additionally': 1, 'smoothing': 1}, ('value', 'feeding'): {'diverse': 2}, ('neural', 'network'): {'rapidly': 2, 'processes': 7, 'accurately': 8, 'fine-tunes': 10, 'probabilistically': 5, 'minimizes': 16, 'correctly': 7, 'calculates': 11, 'samples': 12, 'significantly': 10, 'tokenizes': 10, 'improves': 14, 'generates': 13, 'encodes': 13, 'captures': 15, 'increases': 12, 'adjusts': 14, 'sequentially': 9, 'represents': 9, 'learns': 11, 'predicts': 16, 'efficiently': 7, 'gradually': 5, 'outputs': 10, 'reduces': 11, 'optimizes': 5, 'trains': 14, 'diverges': 7, 'decodes': 5, 'converges': 10, 'updates': 7, 'successfully': 7, 'maximizes': 8, 'computes': 7, 'overfits': 5, 'recursively': 7, 'models': 8, 'evaluates': 11, 'automatically': 4, 'generalizes': 11, 'continuously': 5, 'iteratively': 4, 'statistically': 4, 'effectively': 1}, ('descent', 'cross'): {'entropy': 5}, ('probabilistically', 'moreover'): {'the': 5}, ('on', 'contextual'): {'information': 12}, ('efficiently', 'word'): {'embeddings': 4}, ('words', 'in'): {'addition': 3, 'contrast': 7}, ('corpus', 'perplexity'): {'measures': 2}, ('distribution', 'rapidly'): {'a': 2, 'data': 2, 'the': 5, 'meanwhile': 1, 'regularization': 1}, ('mechanism', 'optimizes'): {'semantic': 1, 'statistical': 1}, ('on', 'the'): {'batch': 12, 'loss': 13, 'softmax': 9, 'training': 13, 'learning': 21, 'vocabulary': 15, 'bias': 17, 'next': 17, 'activation': 13, 'gradient': 9, 'weight': 12, 'corpus': 15, 'cross': 9, 'hidden': 8, 'probability': 7}, ('perplexity', 'encodes'): {'token': 1, 'syntactic': 1, 'semantic': 1, 'sentence': 1, 'word': 1}, ('researcher', 'overfits'): {'word': 1, 'large': 1, 'contextual': 1}, ('dataset', 'samples'): {'the': 6, 'co-occurrence': 1, 'sentence': 1, 'token': 1}, ('corpus', 'calculates'): {'the': 9, 'millions': 2, 'token': 1, 'syntactic': 1}, ('measures', 'how'): {'well': 104}, ('text', 'computes'): {'the': 7, 'word': 4, 'linguistic': 1, 'statistical': 1}, ('architecture', 'calculates'): {'word': 2, 'the': 4, 'co-occurrence': 1, 'semantic': 1, 'language': 1, 'token': 1}, ('information', 'in'): {'contrast': 3, 'addition': 2}, ('states', 'subsequently'): {'the': 4}, ('effectively', 'additionally'): {'the': 7}, ('weight', 'accurately'): {'outputs': 1, 'predicts': 1, 'decodes': 1, 'updates': 1, 'learns': 1, 'maximizes': 1, 'minimizes': 1, 'trains': 1, 'tokenizes': 1, 'captures': 1}, ('from', 'syntactic'): {'rules': 10}, ('information', 'rapidly'): {'a': 8, 'the': 11, 'consequently': 1, 'data': 1, 'feeding': 1, 'for': 1, 'furthermore': 1}, ('features', 'efficiently'): {'for': 2, 'word': 1, 'the': 7, 'as': 2, 'a': 2, 'consequently': 1}, ('perplexity', 'minimizes'): {'token': 1, 'the': 3, 'word': 1, 'large': 1, 'syntactic': 1}, ('distribution', 'however'): {'the': 4}, ('automatically', 'reduces'): {'large': 1, 'word': 1, 'co-occurrence': 1, 'the': 3}, ('vocabulary', 'rapidly'): {'increases': 2, 'converges': 2, 'improves': 1}, ('rate', 'automatically'): {'data': 1, 'specifically': 1, 'the': 6, 'cross': 1, 'in': 1}, ('optimizer', 'computes'): {'word': 1, 'linguistic': 1, 'the': 3, 'millions': 1}, ('bigram', 'correctly'): {'represents': 2}, ('how', 'many'): {'previous': 90}, ('automatically', 'training'): {'a': 4}, ('automatically', 'tokenizes'): {'the': 3, 'semantic': 1, 'co-occurrence': 2}, ('the', 'trigram'): {'encodes': 7, 'computes': 10, 'updates': 9, 'learns': 9, 'reduces': 10, 'recursively': 8, 'predicts': 14, 'converges': 13, 'improves': 10, 'trains': 10, 'increases': 6, 'calculates': 22, 'iteratively': 7, 'fine-tunes': 9, 'decodes': 12, 'statistically': 8, 'models': 5, 'continuously': 7, 'generates': 5, 'represents': 7, 'generalizes': 5, 'diverges': 10, 'tokenizes': 14, 'processes': 6, 'probabilistically': 7, 'minimizes': 5, 'evaluates': 10, 'maximizes': 11, 'captures': 5, 'automatically': 4, 'efficiently': 4, 'samples': 8, 'successfully': 5, 'adjusts': 17, 'accurately': 5, 'outputs': 10, 'significantly': 8, 'effectively': 5, 'rapidly': 9, 'gradually': 7, 'overfits': 6, 'sequentially': 6, 'correctly': 7, 'optimizes': 4}, ('states', 'specifically'): {'the': 2}, ('gradient', 'efficiently'): {'adjusts': 2, 'optimizes': 1, 'represents': 1, 'learns': 1, 'tokenizes': 1, 'converges': 1}, ('automatically', 'therefore'): {'the': 4}, ('effectively', 'cross'): {'entropy': 5}, ('probabilities', 'to'): {'sequences': 93}, ('improves', 'contextual'): {'information': 10}, ('network', 'predicts'): {'language': 1, 'the': 12, 'millions': 1, 'contextual': 1, 'sentence': 1}, ('recursively', 'evaluates'): {'token': 1, 'co-occurrence': 1, 'large': 1, 'the': 5}, ('dense', 'vector'): {'representations': 88}, ('distribution', 'statistically'): {'the': 5, 'a': 4, 'therefore': 1, 'tokenization': 1}, ('model', 'efficiently'): {'processes': 1, 'computes': 1, 'models': 2, 'evaluates': 1, 'generates': 1, 'reduces': 2, 'maximizes': 1, 'decodes': 1, 'represents': 1, 'updates': 1, 'generalizes': 1, 'minimizes': 1}, ('mechanism', 'calculates'): {'contextual': 2, 'the': 4, 'language': 1, 'semantic': 1, 'syntactic': 1}, ('sequences', 'nevertheless'): {'the': 3}, ('function', 'probabilistically'): {'the': 10, 'models': 2, 'evaluates': 1, 'word': 1, 'a': 4, 'processes': 1, 'predicts': 1, 'optimizes': 1, 'consequently': 1, 'additionally': 1, 'reduces': 1}, ('predicts', 'sentence'): {'structure': 32}, ('features', 'as'): {'a': 2}, ('text', 'regularization'): {'techniques': 1}, ('algorithm', 'recursively'): {'represents': 1, 'adjusts': 1, 'captures': 1, 'encodes': 1}, ('gradually', 'predicts'): {'linguistic': 2, 'the': 8, 'semantic': 3, 'syntactic': 2}, ('features', 'for'): {'example': 5}, ('maximizes', 'contextual'): {'information': 10}, ('words', 'additionally'): {'the': 1}, ('matrices', 'nevertheless'): {'the': 3, 'backpropagation': 1}, ('loss', 'function'): {'minimizes': 8, 'computes': 8, 'maximizes': 9, 'continuously': 3, 'increases': 9, 'generalizes': 5, 'statistically': 7, 'optimizes': 14, 'outputs': 8, 'trains': 12, 'evaluates': 11, 'captures': 8, 'accurately': 6, 'predicts': 25, 'represents': 12, 'successfully': 4, 'rapidly': 13, 'updates': 7, 'diverges': 8, 'models': 9, 'generates': 14, 'recursively': 9, 'processes': 2, 'gradually': 10, 'encodes': 8, 'probabilistically': 7, 'decodes': 9, 'improves': 8, 'automatically': 3, 'converges': 14, 'iteratively': 8, 'sequentially': 6, 'significantly': 11, 'reduces': 10, 'correctly': 5, 'tokenizes': 11, 'adjusts': 5, 'learns': 11, 'calculates': 9, 'samples': 9, 'fine-tunes': 7, 'overfits': 8, 'efficiently': 3, 'effectively': 5}, ('probability', 'rapidly'): {'improves': 1, 'predicts': 1, 'maximizes': 1, 'trains': 1, 'reduces': 1, 'increases': 1, 'adjusts': 1, 'learns': 2}, ('metric', 'generalizes'): {'sentence': 1, 'contextual': 1, 'word': 2, 'the': 4, 'language': 2}, ('trigram', 'represents'): {'language': 1, 'millions': 1, 'syntactic': 1, 'the': 2, 'word': 2}, ('correctly', 'updates'): {'language': 3, 'linguistic': 1, 'word': 2, 'the': 3, 'co-occurrence': 1, 'contextual': 1, 'token': 1}, ('meaning', 'feeding'): {'diverse': 1}, ('vocabulary', 'statistically'): {'tokenizes': 1, 'represents': 2, 'encodes': 1}, ('a', 'model'): {'memorizes': 104}, ('sequences', 'significantly'): {'bigram': 1, 'the': 3, 'feeding': 1, 'a': 2, 'as': 1}, ('converts', 'raw'): {'scores': 97}, ('generates', 'millions'): {'of': 17}, ('backpropagation', 'represents'): {'the': 5, 'contextual': 1, 'language': 1, 'millions': 2, 'token': 1}, ('successfully', 'decodes'): {'statistical': 1, 'the': 5, 'sentence': 1}, ('text', 'successfully'): {'samples': 1, 'a': 2, 'the': 7, 'models': 1, 'additionally': 1, 'for': 1, 'consequently': 1, 'updates': 1, 'specifically': 1, 'data': 1, 'adjusts': 1, 'reduces': 1, 'improves': 1, 'as': 1}, ('word', 'backpropagation'): {'generalizes': 1, 'captures': 1}, ('learning', 'patterns'): {'however': 4, 'the': 34, 'in': 4, 'moreover': 2, 'a': 39, 'therefore': 4, 'as': 1, 'consequently': 3, 'backpropagation': 4, 'similarly': 1, 'meanwhile': 3, 'nevertheless': 2, 'furthermore': 1, 'additionally': 1, 'subsequently': 1}, ('generalizes', 'statistical'): {'patterns': 19}, ('corpus', 'outputs'): {'the': 3, 'word': 1, 'contextual': 1, 'semantic': 1}, ('information', 'additionally'): {'the': 5}, ('architecture', 'outputs'): {'the': 5, 'token': 1, 'word': 1, 'language': 1, 'large': 1}, ('matrices', 'significantly'): {'additionally': 1, 'consequently': 1, 'the': 7, 'a': 3, 'specifically': 1, 'feeding': 1, 'furthermore': 1}, ('rules', 'word'): {'embeddings': 1}, ('sequentially', 'processes'): {'statistical': 1, 'the': 4, 'syntactic': 1}, ('computes', 'syntactic'): {'rules': 7}, ('into', 'a'): {'valid': 97}, ('tokenizer', 'predicts'): {'the': 10, 'large': 1, 'sentence': 2, 'co-occurrence': 1, 'syntactic': 1, 'semantic': 1, 'word': 1, 'contextual': 1, 'linguistic': 1}, ('optimizer', 'successfully'): {'generates': 1, 'encodes': 1, 'adjusts': 1, 'optimizes': 1, 'improves': 2, 'reduces': 2, 'decodes': 1}, ('evaluates', 'large'): {'amounts': 14}, ('successfully', 'trains'): {'on': 8}, ('descent', 'subsequently'): {'the': 4}, ('output', 'consequently'): {'the': 1}, ('the', 'tokenizer'): {'calculates': 9, 'overfits': 10, 'converges': 11, 'tokenizes': 11, 'significantly': 9, 'predicts': 19, 'encodes': 8, 'decodes': 7, 'iteratively': 5, 'learns': 12, 'evaluates': 5, 'reduces': 6, 'updates': 11, 'diverges': 10, 'statistically': 9, 'sequentially': 8, 'successfully': 5, 'gradually': 6, 'efficiently': 11, 'improves': 8, 'maximizes': 8, 'increases': 10, 'recursively': 8, 'computes': 8, 'represents': 9, 'accurately': 8, 'models': 11, 'fine-tunes': 8, 'samples': 13, 'trains': 8, 'processes': 14, 'generalizes': 4, 'probabilistically': 7, 'correctly': 5, 'captures': 5, 'rapidly': 9, 'optimizes': 8, 'outputs': 6, 'automatically': 8, 'continuously': 5, 'minimizes': 7, 'adjusts': 7, 'generates': 2, 'effectively': 3}, ('features', 'tokenization'): {'is': 2}, ('input', 'reduces'): {'the': 1, 'language': 1, 'word': 1}, ('rapidly', 'however'): {'the': 6}, ('from', 'memorizing'): {'the': 92}, ('into', 'any'): {'language': 99}, ('n-gram', 'reduces'): {'the': 6, 'contextual': 1, 'linguistic': 3}, ('frequency', 'of'): {'word': 110}, ('rapidly', 'nevertheless'): {'the': 7}, ('probability', 'statistically'): {'adjusts': 1, 'generates': 1, 'models': 1, 'fine-tunes': 1, 'increases': 1}, ('n-gram', 'tokenizes'): {'the': 6, 'co-occurrence': 1, 'language': 1, 'millions': 2}, ('dataset', 'evaluates'): {'contextual': 2, 'statistical': 1, 'the': 4, 'token': 1, 'semantic': 1}, ('mechanism', 'outputs'): {'the': 4, 'millions': 1, 'sentence': 1, 'contextual': 1, 'linguistic': 1}, ('successfully', 'models'): {'the': 6, 'co-occurrence': 1, 'semantic': 1}, ('features', 'gradient'): {'descent': 3}, ('parameters', 'gradually'): {'the': 6, 'cleaning': 1, 'a': 5}, ('distribution', 'moreover'): {'the': 2}, ('learned', 'patterns'): {'furthermore': 3, 'a': 18, 'in': 4, 'similarly': 2, 'the': 45, 'backpropagation': 4, 'for': 3, 'nevertheless': 1, 'meanwhile': 2, 'specifically': 1, 'however': 3, 'subsequently': 1, 'therefore': 1, 'consequently': 2, 'additionally': 2, 'moreover': 1}, ('sequence', 'processes'): {'word': 5, 'the': 4, 'large': 1, 'statistical': 1, 'language': 1, 'linguistic': 1, 'contextual': 1, 'millions': 1}, ('recursively', 'increases'): {'language': 1}, ('metric', 'samples'): {'the': 6, 'token': 1}, ('weight', 'probabilistically'): {'samples': 1, 'predicts': 1, 'evaluates': 2, 'computes': 1, 'adjusts': 1, 'reduces': 1}, ('frequencies', 'specifically'): {'the': 2}, ('perplexity', 'successfully'): {'tokenizes': 1, 'samples': 1, 'updates': 1, 'overfits': 1, 'models': 2}, ('pipeline', 'therefore'): {'the': 3}, ('rate', 'however'): {'the': 3}, ('recursively', 'optimizes'): {'word': 1, 'statistical': 1, 'the': 3, 'language': 1}, ('continuously', 'decodes'): {'the': 4, 'large': 1}, ('automatically', 'data'): {'preprocessing': 5}, ('improves', 'token'): {'sequences': 13}, ('descent', 'efficiently'): {'smoothing': 1, 'transfer': 1, 'a': 2, 'the': 7, 'backpropagation': 1, 'additionally': 1, 'data': 1, 'bigram': 1}, ('overfits', 'syntactic'): {'rules': 8}, ('information', 'moreover'): {'the': 1}, ('iteratively', 'bigram'): {'and': 3}, ('parameters', 'similarly'): {'the': 3}, ('rate', 'nevertheless'): {'the': 4}, ('shallow', 'the'): {'dataset': 3, 'perplexity': 4, 'attention': 4, 'sequence': 7, 'n-gram': 13, 'evaluation': 5, 'input': 9, 'output': 5, 'trigram': 4, 'gradient': 7, 'training': 4, 'neural': 10, 'language': 1, 'probability': 4, 'researcher': 11, 'vocabulary': 7, 'tokenizer': 5, 'weight': 7, 'prediction': 6, 'context': 7, 'embedding': 6, 'text': 3, 'loss': 4, 'algorithm': 3, 'corpus': 6, 'architecture': 6, 'optimizer': 5, 'bigram': 3, 'system': 3}, ('optimizer', 'updates'): {'language': 1, 'word': 2, 'the': 6, 'contextual': 1, 'millions': 2, 'large': 2, 'statistical': 1}, ('gradient', 'learns'): {'from': 10}, ('gradient', 'generates'): {'the': 12, 'semantic': 3, 'sentence': 1, 'linguistic': 1, 'co-occurrence': 1, 'language': 1}, ('metric', 'improves'): {'semantic': 1, 'statistical': 2, 'language': 1, 'the': 6, 'millions': 2}, ('metric', 'overfits'): {'the': 5, 'language': 2}, ('word', 'feeding'): {'diverse': 4}, ('trigram', 'gradually'): {'diverges': 1, 'learns': 2, 'converges': 1, 'encodes': 1, 'optimizes': 1, 'captures': 1}, ('sequentially', 'nevertheless'): {'the': 8, 'backpropagation': 1}, ('accurately', 'consequently'): {'the': 4}, ('maximizes', 'token'): {'sequences': 9}, ('processes', 'syntactic'): {'rules': 16}, ('researcher', 'automatically'): {'improves': 1, 'samples': 1, 'processes': 2, 'encodes': 1}, ('continuously', 'trains'): {'on': 5}, ('predicts', 'language'): {'patterns': 32}, ('increases', 'semantic'): {'meaning': 12}, ('model', 'learns'): {'from': 12}, ('backpropagation', 'gradually'): {'converges': 1, 'tokenizes': 1, 'updates': 1}, ('model', 'generates'): {'semantic': 2, 'the': 10, 'contextual': 2, 'token': 1, 'co-occurrence': 1, 'statistical': 1, 'word': 1, 'language': 1}, ('frequencies', 'sequentially'): {'the': 6, 'a': 4, 'in': 1, 'overfitting': 1, 'nevertheless': 2, 'however': 2, 'backpropagation': 1}, ('models', 'sentence'): {'structure': 17}, ('rate', 'significantly'): {'the': 3, 'as': 1, 'a': 5, 'feeding': 1, 'word': 1}, ('descent', 'as'): {'a': 2}, ('output', 'specifically'): {'the': 1}, ('word', 'recursively'): {'the': 7, 'moreover': 1, 'bigram': 1, 'a': 3, 'similarly': 1, 'however': 1, 'data': 1, 'feeding': 1}, ('significantly', 'feeding'): {'diverse': 6}, ('specifically', 'backpropagation'): {'predicts': 1, 'tokenizes': 1, 'computes': 1}, ('descent', 'for'): {'example': 4}, ('efficiently', 'captures'): {'the': 4, 'syntactic': 1, 'co-occurrence': 1}, ('window', 'optimizes'): {'the': 4, 'language': 1, 'large': 2, 'token': 1, 'statistical': 1}, ('continuously', 'models'): {'contextual': 2, 'the': 2, 'token': 1, 'word': 1, 'linguistic': 1, 'statistical': 1, 'co-occurrence': 1}, ('terms', 'effectively'): {'in': 1, 'the': 7, 'a': 1, 'cross': 1, 'nevertheless': 1}, ('automatically', 'furthermore'): {'the': 3}, ('space', 'subsequently'): {'the': 4}, ('iteratively', 'perplexity'): {'measures': 2}, ('network', 'processes'): {'the': 5, 'large': 1, 'token': 1}, ('probabilistically', 'reduces'): {'the': 6, 'language': 1, 'linguistic': 1, 'word': 2}, ('features', 'accurately'): {'the': 5, 'a': 1, 'perplexity': 1, 'furthermore': 1, 'cleaning': 1, 'backpropagation': 1, 'specifically': 1}, ('perplexity', 'updates'): {'the': 4, 'syntactic': 1, 'co-occurrence': 1, 'language': 1, 'large': 1, 'semantic': 1}, ('corpus', 'adjusts'): {'the': 3, 'co-occurrence': 1, 'large': 1, 'word': 1}, ('statistically', 'samples'): {'the': 2}, ('dataset', 'increases'): {'the': 6, 'token': 1}, ('encodes', 'token'): {'sequences': 10}, ('parameters', 'perplexity'): {'measures': 3}, ('probabilistically', 'training'): {'a': 3}, ('iteratively', 'calculates'): {'the': 5, 'statistical': 1}, ('output', 'sequentially'): {'the': 8, 'a': 1, 'converges': 1, 'consequently': 1, 'however': 1, 'reduces': 1, 'tokenizes': 1, 'word': 1, 'meanwhile': 1, 'updates': 1, 'generates': 1}, ('statistically', 'the'): {'input': 4, 'bigram': 2, 'frequency': 3, 'probability': 11, 'context': 5, 'attention': 6, 'model': 4, 'trigram': 9, 'optimizer': 4, 'corpus': 2, 'sequence': 4, 'text': 4, 'tokenizer': 11, 'training': 9, 'language': 4, 'gradient': 4, 'evaluation': 5, 'n-gram': 3, 'vocabulary': 11, 'prediction': 3, 'weight': 3, 'perplexity': 4, 'system': 7, 'neural': 7, 'softmax': 5, 'embedding': 2, 'loss': 5, 'researcher': 2, 'output': 3, 'algorithm': 5, 'architecture': 3, 'dataset': 2}, ('text', 'correctly'): {'for': 1, 'the': 7, 'reduces': 2, 'data': 1, 'a': 2, 'moreover': 1, 'outputs': 1, 'converges': 1, 'meanwhile': 1, 'in': 1, 'updates': 2, 'minimizes': 1, 'improves': 1, 'fine-tunes': 1, 'subsequently': 1}, ('gradually', 'processes'): {'the': 5, 'semantic': 1, 'word': 1, 'contextual': 1}, ('matrices', 'word'): {'embeddings': 3}, ('gradient', 'accurately'): {'trains': 1, 'predicts': 2, 'processes': 1}, ('patterns', 'successfully'): {'in': 1, 'a': 5, 'the': 8, 'regularization': 1, 'training': 1, 'for': 2, 'consequently': 1, 'word': 1}, ('size', 'the'): {'gradient': 9, 'trigram': 6, 'softmax': 3, 'text': 6, 'architecture': 7, 'dataset': 6, 'bigram': 10, 'algorithm': 3, 'researcher': 5, 'vocabulary': 10, 'perplexity': 4, 'evaluation': 5, 'prediction': 2, 'embedding': 4, 'corpus': 4, 'training': 5, 'model': 4, 'attention': 11, 'frequency': 2, 'sequence': 6, 'loss': 6, 'n-gram': 7, 'language': 4, 'tokenizer': 7, 'weight': 9, 'context': 6, 'input': 6, 'neural': 6, 'output': 7, 'probability': 3, 'optimizer': 5, 'system': 3}, ('dataset', 'optimizes'): {'linguistic': 1, 'the': 3, 'statistical': 1}, ('bigram', 'recursively'): {'diverges': 1, 'minimizes': 2, 'captures': 1, 'predicts': 1, 'samples': 1, 'models': 1, 'decodes': 1}, ('dataset', 'iteratively'): {'trains': 1, 'improves': 2, 'learns': 1, 'generates': 1}, ('recursively', 'cleaning'): {'and': 5}, ('descent', 'tokenization'): {'is': 2}, ('model', 'accurately'): {'trains': 1, 'encodes': 1, 'updates': 1, 'improves': 1, 'evaluates': 2, 'predicts': 3, 'increases': 1, 'adjusts': 1, 'captures': 1, 'processes': 1, 'represents': 1, 'learns': 1, 'outputs': 1, 'overfits': 1}, ('corpus', 'subsequently'): {'the': 9, 'backpropagation': 1}, ('sequence', 'significantly'): {'improves': 1, 'represents': 1, 'increases': 1}, ('weight', 'represents'): {'the': 6, 'millions': 1, 'co-occurrence': 1, 'word': 1}, ('window', 'calculates'): {'sentence': 2, 'large': 1, 'the': 1, 'millions': 1}, ('accurately', 'subsequently'): {'the': 4, 'backpropagation': 1}, ('optimizer', 'correctly'): {'captures': 1, 'improves': 1, 'processes': 1, 'updates': 1, 'diverges': 1}, ('perplexity', 'diverges'): {'the': 5, 'large': 1, 'contextual': 1, 'word': 1, 'statistical': 1}, ('statistically', 'improves'): {'the': 4, 'semantic': 1}, ('terms', 'the'): {'dataset': 4, 'optimizer': 3, 'algorithm': 3, 'output': 6, 'architecture': 3, 'corpus': 7, 'input': 3, 'probability': 3, 'sequence': 1, 'prediction': 5, 'softmax': 2, 'loss': 3, 'gradient': 1, 'researcher': 3, 'training': 6, 'weight': 3, 'context': 2, 'tokenizer': 3, 'n-gram': 3, 'frequency': 2, 'bigram': 1, 'evaluation': 3, 'text': 3, 'neural': 2, 'vocabulary': 7, 'attention': 3, 'embedding': 3, 'perplexity': 2, 'language': 3}, ('statistically', 'overfits'): {'large': 1, 'the': 4, 'semantic': 1, 'co-occurrence': 1}, ('correctly', 'backpropagation'): {'improves': 1, 'calculates': 1}, ('function', 'gradually'): {'the': 1, 'predicts': 4, 'models': 2, 'a': 4, 'trains': 2, 'optimizes': 1, 'bigram': 1, 'for': 1, 'learns': 1}, ('mechanism', 'adjusts'): {'the': 3, 'semantic': 1, 'contextual': 1}, ('lightweight', 'backpropagation'): {'updates': 1, 'models': 1, 'improves': 1, 'evaluates': 1, 'learns': 1, 'converges': 1, 'predicts': 1}, ('for', 'example'): {'the': 183, 'backpropagation': 5}, ('accurately', 'specifically'): {'the': 6}, ('outputs', 'word'): {'frequencies': 15, 'embeddings': 13}, ('corpus', 'fine-tunes'): {'the': 4, 'token': 1, 'large': 1, 'word': 1, 'co-occurrence': 1, 'statistical': 1, 'sentence': 1}, ('tokenizer', 'processes'): {'the': 4, 'language': 1, 'word': 2, 'co-occurrence': 1, 'semantic': 2, 'syntactic': 1, 'contextual': 2, 'sentence': 1}, ('architecture', 'fine-tunes'): {'token': 2, 'the': 2, 'syntactic': 1, 'word': 1, 'language': 1}, ('meaning', 'significantly'): {'a': 7, 'the': 1, 'however': 1, 'subsequently': 1, 'moreover': 1, 'in': 1, 'consequently': 1, 'bigram': 1}, ('algorithm', 'decodes'): {'the': 5, 'word': 1, 'linguistic': 1}, ('probability', 'distribution'): {'correctly': 17, 'the': 135, 'continuously': 15, 'cleaning': 2, 'additionally': 6, 'efficiently': 13, 'backpropagation': 5, 'a': 56, 'moreover': 2, 'iteratively': 17, 'in': 10, 'sequentially': 12, 'statistically': 11, 'gradually': 11, 'perplexity': 1, 'significantly': 10, 'recursively': 14, 'training': 3, 'accurately': 12, 'successfully': 5, 'effectively': 10, 'rapidly': 11, 'subsequently': 3, 'consequently': 7, 'meanwhile': 8, 'nevertheless': 8, 'furthermore': 6, 'however': 4, 'probabilistically': 12, 'similarly': 6, 'automatically': 9, 'word': 1, 'therefore': 3, 'overfitting': 2, 'bigram': 1, 'specifically': 2, 'cross': 2, 'gradient': 1, 'feeding': 2, 'for': 7, 'as': 3, 'data': 2, 'smoothing': 2, 'transfer': 2}, ('tokenization', 'is'): {'the': 82}, ('trigram', 'calculates'): {'syntactic': 4, 'linguistic': 2, 'the': 12, 'word': 1, 'sentence': 1, 'semantic': 1, 'co-occurrence': 1}, ('recursively', 'outputs'): {'the': 2, 'token': 1}, ('embeddings', 'sequentially'): {'the': 6, 'cleaning': 1, 'bigram': 1, 'a': 3, 'similarly': 1}, ('successfully', 'minimizes'): {'the': 4, 'semantic': 1, 'syntactic': 1, 'large': 1}, ('effectively', 'tokenization'): {'is': 5}, ('diverse', 'text'): {'corpora': 121}, ('corpus', 'efficiently'): {'represents': 1, 'increases': 1, 'a': 3, 'the': 7, 'for': 1, 'furthermore': 2, 'smoothing': 1, 'specifically': 1, 'meanwhile': 1}, ('function', 'bigram'): {'and': 1}, ('increases', 'contextual'): {'information': 13}, ('iteratively', 'outputs'): {'co-occurrence': 2, 'linguistic': 1, 'the': 1}, ('recursively', 'additionally'): {'the': 9}, ('reduces', 'large'): {'amounts': 8}, ('decodes', 'large'): {'amounts': 15}, ('mechanism', 'fine-tunes'): {'the': 8, 'sentence': 2, 'statistical': 1}, ('of', 'statistical'): {'language': 110}, ('effectively', 'gradient'): {'descent': 2}, ('gradually', 'nevertheless'): {'backpropagation': 1, 'the': 4}, ('models', 'language'): {'patterns': 16}, ('input', 'effectively'): {'optimizes': 1, 'overfits': 1, 'models': 1, 'encodes': 1, 'tokenizes': 1, 'increases': 1, 'decodes': 1, 'reduces': 1}, ('effectively', 'tokenizes'): {'contextual': 1, 'the': 6, 'millions': 1, 'word': 1}, ('n-gram', 'effectively'): {'decodes': 1, 'minimizes': 1, 'represents': 1, 'predicts': 1, 'computes': 1, 'reduces': 1, 'optimizes': 1}, ('network', 'significantly'): {'outputs': 1, 'adjusts': 1, 'overfits': 1, 'maximizes': 1, 'updates': 1, 'increases': 1, 'generates': 1, 'tokenizes': 1, 'learns': 1, 'encodes': 1}, ('recursively', 'cross'): {'entropy': 1}, ('states', 'successfully'): {'the': 4, 'a': 5, 'training': 1}, ('layer', 'correctly'): {'predicts': 1, 'calculates': 1, 'models': 1}, ('loss', 'significantly'): {'the': 8, 'training': 1, 'cleaning': 2, 'as': 1, 'in': 2, 'a': 2, 'subsequently': 1}, ('window', 'outputs'): {'the': 6, 'language': 1}, ('algorithm', 'models'): {'the': 9, 'linguistic': 1, 'word': 1, 'co-occurrence': 1, 'contextual': 2}, ('gracefully', 'however'): {'the': 1}, ('text', 'backpropagation'): {'samples': 1, 'diverges': 1, 'adjusts': 1, 'automatically': 1, 'accurately': 1}, ('researcher', 'statistically'): {'calculates': 1, 'converges': 1, 'improves': 1, 'processes': 1, 'predicts': 1}, ('corpus', 'as'): {'a': 9}, ('efficiently', 'generalizes'): {'syntactic': 1, 'the': 3, 'statistical': 1}, ('successfully', 'overfitting'): {'occurs': 3}, ('fine-tuned', 'backpropagation'): {'diverges': 1, 'samples': 1}, ('output', 'encodes'): {'semantic': 1, 'the': 5, 'word': 2, 'sentence': 1, 'statistical': 1}, ('gracefully', 'nevertheless'): {'the': 1}, ('system', 'tokenizes'): {'the': 5, 'linguistic': 1, 'word': 1, 'token': 1, 'semantic': 1, 'language': 1, 'co-occurrence': 1}, ('corpus', 'for'): {'example': 4}, ('mechanism', 'efficiently'): {'optimizes': 1, 'adjusts': 2, 'processes': 1, 'represents': 2, 'maximizes': 1, 'updates': 1, 'models': 1}, ('prediction', 'significantly'): {'calculates': 1, 'increases': 1, 'learns': 1, 'outputs': 1, 'maximizes': 1, 'captures': 1, 'predicts': 1, 'evaluates': 1, 'tokenizes': 1}, ('effectively', 'learns'): {'from': 7}, ('features', 'probabilistically'): {'the': 10, 'additionally': 1, 'however': 1, 'a': 1, 'similarly': 1, 'therefore': 1}, ('effectively', 'generates'): {'the': 5, 'language': 1, 'sentence': 2}, ('process', 'decodes'): {'the': 7, 'syntactic': 1, 'semantic': 2, 'sentence': 2}, ('sequentially', 'word'): {'embeddings': 3}, ('tokenizes', 'large'): {'amounts': 7}, ('function', 'perplexity'): {'measures': 2}, ('output', 'minimizes'): {'the': 3, 'language': 1, 'token': 1}, ('weight', 'gradually'): {'increases': 1, 'calculates': 1, 'learns': 1, 'computes': 1, 'generalizes': 1, 'decodes': 1}, ('input', 'samples'): {'the': 6, 'semantic': 1, 'millions': 1, 'token': 1, 'word': 1}, ('successfully', 'smoothing'): {'techniques': 3}, ('correctly', 'feeding'): {'diverse': 1}, ('metric', 'automatically'): {'increases': 1, 'trains': 1, 'generalizes': 2, 'adjusts': 1, 'predicts': 1, 'optimizes': 1, 'computes': 1}, ('trigram', 'outputs'): {'co-occurrence': 1, 'the': 7, 'sentence': 1, 'word': 1}, ('successfully', 'maximizes'): {'the': 3, 'semantic': 2, 'language': 1}, ('gradient', 'probabilistically'): {'calculates': 1, 'updates': 1, 'diverges': 1, 'optimizes': 1, 'generalizes': 1, 'converges': 1, 'generates': 1}, ('function', 'calculates'): {'language': 1, 'sentence': 1, 'the': 6, 'linguistic': 1}, ('optimizes', 'word'): {'frequencies': 14, 'embeddings': 19}, ('efficiently', 'converges'): {'the': 4}, ('algorithm', 'sequentially'): {'fine-tunes': 1, 'tokenizes': 1, 'computes': 1, 'generalizes': 1, 'improves': 1, 'learns': 1, 'processes': 1, 'evaluates': 1}, ('subsequently', 'the'): {'loss': 10, 'evaluation': 8, 'n-gram': 13, 'researcher': 3, 'context': 9, 'language': 8, 'bigram': 10, 'tokenizer': 6, 'neural': 11, 'output': 8, 'system': 7, 'text': 9, 'model': 7, 'vocabulary': 7, 'training': 7, 'sequence': 7, 'architecture': 6, 'weight': 7, 'dataset': 7, 'input': 8, 'attention': 10, 'gradient': 10, 'algorithm': 6, 'prediction': 7, 'perplexity': 5, 'trigram': 7, 'corpus': 2, 'optimizer': 8, 'embedding': 2, 'probability': 3}, ('distribution', 'training'): {'a': 3}, ('model', 'probabilistically'): {'encodes': 2, 'predicts': 1, 'diverges': 2, 'processes': 1, 'calculates': 1, 'increases': 2, 'decodes': 1, 'generates': 1, 'computes': 1, 'samples': 1, 'converges': 1}, ('process', 'trains'): {'on': 8}, ('is', 'a'): {'critical': 99}, ('tokenizer', 'significantly'): {'evaluates': 1, 'predicts': 2, 'represents': 1, 'generalizes': 1, 'increases': 1, 'adjusts': 1, 'diverges': 1, 'learns': 1}, ('statistically', 'meanwhile'): {'the': 7}, ('network', 'trains'): {'on': 14}, ('corpus', 'tokenization'): {'is': 1}, ('co-occurrence', 'matrices'): {'training': 5, 'the': 90, 'a': 41, 'accurately': 16, 'nevertheless': 4, 'smoothing': 1, 'automatically': 9, 'probabilistically': 18, 'for': 6, 'significantly': 15, 'gradually': 12, 'iteratively': 16, 'feeding': 6, 'recursively': 20, 'overfitting': 3, 'furthermore': 4, 'cleaning': 2, 'subsequently': 3, 'continuously': 10, 'bigram': 1, 'effectively': 11, 'statistically': 10, 'rapidly': 12, 'correctly': 11, 'sequentially': 14, 'gradient': 1, 'tokenization': 4, 'backpropagation': 3, 'additionally': 2, 'efficiently': 9, 'cross': 2, 'data': 2, 'regularization': 2, 'successfully': 7, 'similarly': 3, 'therefore': 1, 'word': 3, 'in': 4, 'specifically': 1, 'meanwhile': 3, 'perplexity': 2, 'moreover': 2, 'however': 1}, ('patterns', 'correctly'): {'a': 6, 'consequently': 1, 'the': 11, 'however': 1, 'meanwhile': 3, 'furthermore': 1, 'in': 1, 'perplexity': 1, 'cross': 1, 'as': 1, 'therefore': 1}, ('information', 'training'): {'a': 2}, ('input', 'improves'): {'co-occurrence': 1, 'the': 4, 'statistical': 1, 'syntactic': 1, 'sentence': 1}, ('size', 'meanwhile'): {'the': 2}, ('input', 'overfits'): {'co-occurrence': 1, 'the': 7, 'token': 1, 'millions': 1, 'word': 1}, ('vocabulary', 'reduces'): {'the': 5, 'word': 2, 'semantic': 1, 'millions': 1, 'syntactic': 1}, ('automatically', 'evaluates'): {'the': 3, 'statistical': 1}, ('data', 'nevertheless'): {'the': 5}, ('information', 'therefore'): {'the': 2, 'backpropagation': 1}, ('process', 'models'): {'language': 2, 'the': 4, 'word': 1, 'syntactic': 1}, ('data', 'preprocessing'): {'is': 99}, ('vocabulary', 'tokenizes'): {'sentence': 1, 'the': 4, 'token': 1, 'large': 1, 'word': 2}, ('probabilistically', 'furthermore'): {'the': 2}, ('gradually', 'trains'): {'on': 5}, ('prediction', 'trains'): {'on': 9}, ('terms', 'meanwhile'): {'the': 4}, ('network', 'models'): {'the': 7, 'sentence': 1}, ('output', 'computes'): {'millions': 1, 'the': 6, 'co-occurrence': 1, 'sentence': 1}, ('continuously', 'overfitting'): {'occurs': 3}, ('recursively', 'adjusts'): {'sentence': 1, 'the': 4, 'contextual': 1, 'language': 1, 'statistical': 1}, ('meaning', 'word'): {'embeddings': 2}, ('frequencies', 'regularization'): {'techniques': 2}, ('increases', 'token'): {'sequences': 6}, ('data', 'significantly'): {'subsequently': 1, 'the': 3, 'for': 1, 'furthermore': 1, 'in': 1, 'smoothing': 1, 'a': 1, 'meanwhile': 1}, ('prediction', 'models'): {'co-occurrence': 1, 'the': 10, 'sentence': 1, 'large': 1, 'linguistic': 1}, ('text', 'feeding'): {'diverse': 2}, ('significantly', 'decodes'): {'syntactic': 1, 'co-occurrence': 1, 'contextual': 1, 'the': 2, 'semantic': 1, 'linguistic': 1}, ('minimizes', 'sentence'): {'structure': 14}, ('statistically', 'increases'): {'large': 1, 'the': 4, 'token': 1, 'language': 1}, ('probability', 'reduces'): {'the': 5, 'semantic': 1, 'token': 1, 'word': 1, 'language': 1}, ('iteratively', 'adjusts'): {'syntactic': 1, 'the': 3, 'word': 1, 'co-occurrence': 1, 'language': 1}, ('continuously', 'maximizes'): {'the': 5, 'millions': 3, 'sentence': 1, 'statistical': 1}, ('function', 'outputs'): {'the': 4, 'word': 3, 'syntactic': 1}, ('in', 'natural'): {'language': 104}, ('frequencies', 'successfully'): {'specifically': 1, 'a': 3, 'moreover': 1, 'the': 7, 'tokenization': 1, 'in': 1}, ('size', 'automatically'): {'specifically': 1, 'the': 9, 'training': 1, 'cleaning': 1, 'backpropagation': 1, 'a': 3, 'data': 1}, ('text', 'recursively'): {'converges': 1, 'learns': 1, 'furthermore': 1, 'tokenizes': 1, 'a': 2, 'bigram': 1, 'the': 5, 'moreover': 1, 'processes': 1, 'reduces': 1, 'represents': 1, 'for': 1, 'transfer': 1}, ('structure', 'nevertheless'): {'the': 1}, ('effectively', 'data'): {'preprocessing': 6}, ('rapidly', 'reduces'): {'language': 1, 'linguistic': 1, 'the': 2, 'word': 1, 'semantic': 1, 'token': 1, 'statistical': 1}, ('embeddings', 'overfitting'): {'occurs': 1}, ('weight', 'calculates'): {'contextual': 1, 'the': 4, 'word': 1, 'sentence': 1}, ('metric', 'rapidly'): {'diverges': 2, 'increases': 1, 'converges': 1, 'optimizes': 1, 'learns': 2, 'updates': 1, 'trains': 1}, ('output', 'regularization'): {'techniques': 1}, ('fine-tunes', 'sentence'): {'structure': 11}, ('window', 'adjusts'): {'the': 9, 'sentence': 1, 'token': 1, 'contextual': 2, 'word': 1, 'large': 1}, ('iteratively', 'subsequently'): {'the': 8}, ('millions', 'of'): {'parameters': 421}, ('matrix', 'nevertheless'): {'the': 2, 'backpropagation': 1}, ('optimizer', 'recursively'): {'updates': 1, 'adjusts': 1, 'maximizes': 1, 'optimizes': 1, 'tokenizes': 1, 'decodes': 1}, ('gradient', 'represents'): {'the': 3, 'word': 1}, ('ability', 'backpropagation'): {'predicts': 1, 'sequentially': 1, 'overfits': 1, 'effectively': 1}, ('embedding', 'layer'): {'overfits': 8, 'generates': 6, 'fine-tunes': 12, 'minimizes': 10, 'outputs': 10, 'efficiently': 5, 'models': 11, 'encodes': 12, 'automatically': 4, 'iteratively': 5, 'computes': 8, 'learns': 4, 'samples': 4, 'improves': 13, 'reduces': 9, 'decodes': 6, 'captures': 6, 'increases': 9, 'rapidly': 5, 'represents': 6, 'tokenizes': 12, 'recursively': 8, 'gradually': 3, 'evaluates': 9, 'effectively': 3, 'predicts': 16, 'significantly': 9, 'updates': 11, 'calculates': 13, 'generalizes': 13, 'maximizes': 5, 'diverges': 8, 'trains': 5, 'processes': 8, 'adjusts': 7, 'optimizes': 9, 'statistically': 4, 'converges': 7, 'sequentially': 3, 'accurately': 4, 'correctly': 3, 'continuously': 2, 'probabilistically': 6, 'successfully': 5}, ('loss', 'word'): {'embeddings': 2}, ('statistically', 'transfer'): {'learning': 3}, ('structure', 'significantly'): {'training': 1, 'the': 8, 'a': 3, 'word': 1, 'nevertheless': 1}, ('embeddings', 'smoothing'): {'techniques': 2}, ('parameters', 'subsequently'): {'the': 3}, ('value', 'overfitting'): {'occurs': 1}, ('continuously', 'captures'): {'the': 2, 'language': 1, 'token': 2}, ('states', 'correctly'): {'a': 1, 'transfer': 1, 'the': 5, 'specifically': 2, 'bigram': 1, 'nevertheless': 1, 'therefore': 1}, ('mechanism', 'learns'): {'from': 5}, ('size', 'transfer'): {'learning': 5}, ('mechanism', 'generates'): {'word': 2, 'the': 12, 'syntactic': 2, 'millions': 1, 'sentence': 1}, ('n-gram', 'evaluates'): {'language': 1, 'co-occurrence': 1, 'the': 2, 'statistical': 2, 'syntactic': 1}, ('significantly', 'models'): {'the': 6, 'token': 1, 'syntactic': 1, 'language': 1}, ('embeddings', 'continuously'): {'the': 9, 'training': 1, 'word': 1, 'a': 1, 'meanwhile': 1, 'cross': 1, 'in': 2, 'specifically': 1, 'furthermore': 1, 'nevertheless': 1}, ('output', 'successfully'): {'a': 6, 'the': 4, 'moreover': 1, 'similarly': 1, 'calculates': 1, 'overfits': 1, 'however': 1, 'data': 1, 'minimizes': 1, 'reduces': 2, 'converges': 1, 'overfitting': 1, 'trains': 1, 'outputs': 1, 'furthermore': 1, 'as': 1, 'updates': 1}, ('gradually', 'word'): {'embeddings': 3}, ('accurately', 'computes'): {'language': 1, 'word': 1, 'the': 2}, ('outputs', 'co-occurrence'): {'matrices': 10}, ('automatically', 'increases'): {'the': 5, 'contextual': 1, 'sentence': 1, 'word': 1, 'language': 1}, ('patterns', 'backpropagation'): {'continuously': 1, 'updates': 1, 'successfully': 1, 'increases': 1, 'rapidly': 1, 'reduces': 1, 'maximizes': 1, 'models': 1, 'probabilistically': 1}, ('matrix', 'significantly'): {'feeding': 1, 'the': 12, 'furthermore': 1, 'for': 1, 'a': 1, 'subsequently': 1}, ('moreover', 'the'): {'model': 8, 'architecture': 8, 'gradient': 9, 'prediction': 9, 'loss': 5, 'sequence': 7, 'researcher': 5, 'context': 7, 'input': 4, 'neural': 7, 'training': 11, 'trigram': 3, 'embedding': 9, 'probability': 7, 'language': 9, 'weight': 1, 'corpus': 5, 'vocabulary': 5, 'n-gram': 8, 'bigram': 4, 'algorithm': 3, 'text': 6, 'system': 5, 'optimizer': 3, 'output': 5, 'attention': 4, 'dataset': 5, 'tokenizer': 2, 'evaluation': 2}, ('iteratively', 'fine-tunes'): {'the': 7, 'word': 1, 'millions': 1}, ('automatically', 'bigram'): {'and': 4}, ('algorithm', 'minimizes'): {'the': 3, 'contextual': 1, 'co-occurrence': 1, 'language': 1, 'large': 1}, ('trigram', 'adjusts'): {'contextual': 1, 'statistical': 1, 'the': 11, 'large': 1, 'word': 1, 'millions': 1, 'syntactic': 1}, ('value', 'smoothing'): {'techniques': 3}, ('features', 'a'): {'generative': 2, 'pre-trained': 2, 'statistical': 4, 'deep': 1, 'autoregressive': 2, 'transformer-based': 3, 'scalable': 2, 'neural': 5, 'large': 3, 'efficient': 2, 'small': 4, 'lightweight': 3, 'fine-tuned': 2, 'accurate': 2, 'language': 2, 'shallow': 1, 'robust': 2, 'discriminative': 1}, ('word', 'sequentially'): {'therefore': 1, 'the': 9, 'gradient': 1, 'cleaning': 1, 'specifically': 1, 'a': 2, 'backpropagation': 1}, ('metric', 'statistically'): {'reduces': 1, 'increases': 1, 'computes': 1, 'minimizes': 2}, ('value', 'continuously'): {'the': 7, 'tokenization': 1, 'a': 2, 'feeding': 1, 'smoothing': 1, 'cross': 1, 'backpropagation': 1, 'however': 1, 'consequently': 1}, ('automatically', 'optimizes'): {'co-occurrence': 1, 'contextual': 1, 'millions': 1, 'large': 1}, ('generates', 'word'): {'embeddings': 12, 'frequencies': 13}, ('consequently', 'backpropagation'): {'trains': 1, 'improves': 1, 'decodes': 1, 'represents': 1, 'adjusts': 1}, ('samples', 'millions'): {'of': 15}, ('embeddings', 'regularization'): {'techniques': 2}, ('window', 'fine-tunes'): {'large': 1, 'the': 7, 'word': 1, 'sentence': 2, 'language': 1, 'contextual': 1}, ('information', 'data'): {'preprocessing': 1}, ('rules', 'the'): {'vocabulary': 6, 'weight': 6, 'neural': 4, 'context': 8, 'probability': 2, 'prediction': 4, 'researcher': 3, 'loss': 5, 'corpus': 4, 'language': 4, 'evaluation': 6, 'n-gram': 3, 'attention': 2, 'frequency': 3, 'bigram': 3, 'algorithm': 3, 'tokenizer': 5, 'sequence': 2, 'system': 4, 'training': 5, 'dataset': 1, 'trigram': 5, 'optimizer': 2, 'embedding': 2, 'gradient': 2, 'architecture': 3, 'perplexity': 1, 'softmax': 2, 'input': 1, 'model': 1}, ('successfully', 'diverges'): {'millions': 1, 'language': 1, 'the': 3}, ('statistically', 'in'): {'addition': 4, 'contrast': 7}, ('recursively', 'as'): {'a': 3}, ('accurately', 'regularization'): {'techniques': 5}, ('weight', 'outputs'): {'contextual': 1, 'the': 4, 'statistical': 1, 'word': 1}, ('size', 'in'): {'contrast': 12, 'addition': 5}, ('recursively', 'for'): {'example': 4}, ('layer', 'recursively'): {'improves': 1, 'samples': 1, 'generalizes': 1, 'predicts': 1, 'learns': 1, 'models': 1, 'trains': 1, 'encodes': 1}, ('mechanism', 'accurately'): {'generalizes': 1, 'diverges': 1, 'samples': 1, 'models': 1, 'updates': 1, 'minimizes': 1, 'evaluates': 1, 'reduces': 1}, ('window', 'efficiently'): {'tokenizes': 1, 'learns': 1, 'encodes': 1, 'trains': 1, 'minimizes': 2, 'models': 2, 'predicts': 1, 'optimizes': 1}, ('size', 'rapidly'): {'regularization': 1, 'bigram': 1, 'backpropagation': 1, 'a': 2, 'the': 15, 'in': 1, 'however': 1, 'moreover': 1, 'subsequently': 1, 'therefore': 1, 'additionally': 1, 'overfitting': 1}, ('automatically', 'perplexity'): {'measures': 2}, ('adjusts', 'language'): {'patterns': 15}, ('trigram', 'fine-tunes'): {'syntactic': 2, 'the': 5, 'word': 1, 'semantic': 1}, ('distribution', 'furthermore'): {'the': 6}, ('meaningful', 'units'): {'for': 82}, ('iteratively', 'as'): {'a': 6}, ('output', 'updates'): {'the': 6, 'word': 1, 'co-occurrence': 1}, ('bigram', 'sequentially'): {'maximizes': 2, 'optimizes': 1, 'learns': 2, 'improves': 1, 'reduces': 1, 'predicts': 1, 'minimizes': 1, 'computes': 1, 'processes': 1}, ('system', 'probabilistically'): {'optimizes': 1, 'learns': 2, 'models': 1, 'minimizes': 1, 'represents': 2, 'increases': 2, 'maximizes': 1, 'adjusts': 2, 'captures': 1}, ('updates', 'millions'): {'of': 13}, ('terms', 'in'): {'contrast': 3, 'addition': 1}, ('features', 'gradually'): {'a': 4, 'the': 5, 'meanwhile': 1, 'as': 1, 'in': 2}, ('calculates', 'token'): {'sequences': 11}, ('sequentially', 'captures'): {'the': 3, 'language': 1, 'word': 1, 'syntactic': 1}, ('parameters', 'as'): {'a': 3}, ('to', 'a'): {'language': 121}, ('iteratively', 'for'): {'example': 8}, ('terms', 'rapidly'): {'the': 7, 'cleaning': 1, 'tokenization': 1, 'data': 1, 'a': 2, 'specifically': 1, 'additionally': 1}, ('algorithm', 'maximizes'): {'co-occurrence': 1, 'the': 4, 'language': 1}, ('ensures', 'consistent'): {'input': 98}, ('successfully', 'converges'): {'statistical': 1, 'word': 1, 'the': 4}, ('minimizes', 'language'): {'patterns': 14}, ('data', 'word'): {'embeddings': 3}, ('meaning', 'overfitting'): {'occurs': 2}, ('the', 'neural'): {'network': 387}, ('algorithm', 'continuously'): {'computes': 1, 'samples': 1, 'models': 1, 'predicts': 1, 'generates': 1}, ('parameters', 'for'): {'example': 1}, ('information', 'furthermore'): {'the': 2}, ('input', 'increases'): {'the': 3, 'syntactic': 1, 'millions': 1, 'sentence': 1, 'large': 1, 'word': 1}, ('gradient', 'gradually'): {'predicts': 1, 'generalizes': 1, 'captures': 2}, ('n-gram', 'increases'): {'the': 2, 'contextual': 1, 'semantic': 2, 'word': 1}, ('function', 'adjusts'): {'the': 3, 'language': 1, 'word': 1}, ('states', 'backpropagation'): {'converges': 1, 'gradually': 1, 'iteratively': 1}, ('distribution', 'effectively'): {'subsequently': 1, 'a': 1, 'the': 2, 'data': 1, 'consequently': 1, 'perplexity': 1, 'nevertheless': 1, 'cross': 1, 'similarly': 1}, ('optimizes', 'co-occurrence'): {'matrices': 19}, ('model', 'gradually'): {'calculates': 1, 'encodes': 1, 'generates': 2, 'diverges': 1, 'learns': 1, 'reduces': 1, 'optimizes': 1, 'predicts': 1}, ('recursively', 'tokenization'): {'is': 2}, ('output', 'diverges'): {'large': 1, 'word': 2, 'the': 3, 'syntactic': 1, 'semantic': 1, 'millions': 1}, ('probabilistically', 'evaluates'): {'the': 8, 'statistical': 1, 'word': 2}, ('features', 'similarly'): {'the': 1}, ('patterns', 'feeding'): {'diverse': 3}, ('generates', 'linguistic'): {'features': 10}, ('neural', 'the'): {'vocabulary': 5, 'output': 8, 'bigram': 4, 'tokenizer': 8, 'perplexity': 4, 'architecture': 5, 'loss': 3, 'gradient': 4, 'evaluation': 4, 'corpus': 4, 'optimizer': 3, 'trigram': 4, 'text': 7, 'attention': 3, 'input': 1, 'sequence': 3, 'neural': 3, 'algorithm': 2, 'researcher': 4, 'training': 4, 'weight': 4, 'n-gram': 3, 'embedding': 2, 'probability': 2, 'context': 5, 'prediction': 4, 'language': 4, 'dataset': 2, 'system': 2}, ('correctly', 'decodes'): {'co-occurrence': 1, 'the': 5}, ('size', 'statistically'): {'a': 9, 'the': 13, 'in': 2, 'however': 2, 'cleaning': 1, 'regularization': 1, 'therefore': 1, 'backpropagation': 1, 'additionally': 1, 'training': 1, 'overfitting': 1}, ('captures', 'language'): {'patterns': 20}, ('frequencies', 'correctly'): {'the': 6, 'cleaning': 1, 'a': 3, 'similarly': 1, 'however': 1, 'specifically': 1, 'moreover': 1}, ('automatically', 'cleaning'): {'and': 4}, ('n-gram', 'optimizes'): {'word': 1, 'the': 2, 'large': 1, 'syntactic': 1, 'token': 1}, ('n-gram', 'iteratively'): {'models': 1, 'captures': 1}, ('meaning', 'continuously'): {'a': 3, 'however': 1, 'for': 1, 'the': 10, 'similarly': 1, 'furthermore': 2, 'backpropagation': 1}, ('function', 'subsequently'): {'the': 4}, ('statistically', 'additionally'): {'the': 5}, ('patterns', 'recursively'): {'the': 8, 'a': 6, 'in': 2, 'meanwhile': 1, 'moreover': 1, 'consequently': 1, 'however': 1, 'training': 1}, ('information', 'probabilistically'): {'the': 7, 'moreover': 2, 'feeding': 1, 'a': 5, 'gradient': 1, 'similarly': 1}, ('iteratively', 'tokenization'): {'is': 2}, ('vocabulary', 'effectively'): {'generalizes': 2, 'tokenizes': 1, 'reduces': 1, 'captures': 1}, ('recursively', 'gradient'): {'descent': 5}, ('structure', 'word'): {'embeddings': 1}, ('model', 'similarly'): {'the': 3, 'backpropagation': 1}, ('loss', 'overfitting'): {'occurs': 2}, ('correctly', 'trains'): {'on': 8}, ('softmax', 'function'): {'converts': 97}, ('model', 'requires'): {'carefully': 109}, ('generalizes', 'contextual'): {'information': 9}, ('terms', 'additionally'): {'backpropagation': 1, 'the': 2}, ('function', 'fine-tunes'): {'language': 1, 'the': 5, 'large': 1}, ('diverges', 'co-occurrence'): {'matrices': 13}, ('process', 'maximizes'): {'the': 6, 'sentence': 1, 'linguistic': 1}, ('probabilistically', 'meanwhile'): {'the': 4}, ('matrix', 'word'): {'embeddings': 3}, ('recursively', 'learns'): {'from': 5}, ('automatically', 'outputs'): {'the': 2, 'statistical': 1, 'large': 1}, ('output', 'correctly'): {'maximizes': 1, 'for': 1, 'the': 3, 'fine-tunes': 2, 'a': 2}, ('recursively', 'generates'): {'sentence': 1, 'linguistic': 2, 'large': 1, 'the': 3, 'token': 1}, ('process', 'continuously'): {'updates': 1, 'optimizes': 1, 'predicts': 1, 'samples': 1, 'represents': 1}, ('continuously', 'converges'): {'the': 3, 'linguistic': 1, 'sentence': 1, 'contextual': 1}, ('sequences', 'the'): {'neural': 4, 'attention': 3, 'embedding': 3, 'system': 5, 'vocabulary': 3, 'output': 4, 'tokenizer': 3, 'probability': 5, 'dataset': 1, 'model': 3, 'trigram': 2, 'evaluation': 3, 'language': 4, 'bigram': 6, 'gradient': 1, 'prediction': 3, 'n-gram': 3, 'training': 3, 'perplexity': 1, 'optimizer': 3, 'researcher': 3, 'context': 3, 'weight': 2, 'text': 1, 'loss': 1, 'algorithm': 1, 'corpus': 2, 'architecture': 2}, ('descent', 'a'): {'lightweight': 3, 'deep': 4, 'generative': 1, 'transformer-based': 5, 'efficient': 3, 'recurrent': 2, 'small': 2, 'statistical': 3, 'language': 4, 'robust': 5, 'shallow': 2, 'autoregressive': 2, 'large': 3, 'bidirectional': 3, 'discriminative': 1, 'scalable': 2, 'accurate': 2}, ('correctly', 'models'): {'the': 4, 'sentence': 1, 'co-occurrence': 2, 'word': 1}, ('significantly', 'minimizes'): {'the': 1, 'sentence': 1, 'millions': 1}, ('probability', 'effectively'): {'represents': 1, 'learns': 1, 'trains': 1}, ('network', 'continuously'): {'minimizes': 1, 'represents': 1, 'processes': 1, 'adjusts': 1, 'maximizes': 1}, ('researcher', 'reduces'): {'the': 7}, ('loss', 'continuously'): {'the': 2, 'feeding': 1, 'overfitting': 1, 'a': 3, 'training': 1, 'similarly': 2, 'gradient': 1, 'consequently': 1, 'for': 1, 'furthermore': 1, 'meanwhile': 1}, ('function', 'efficiently'): {'similarly': 3, 'a': 2, 'as': 1, 'learns': 1, 'the': 4, 'generates': 1, 'tokenizes': 1}, ('optimizes', 'semantic'): {'meaning': 18}, ('automatically', 'additionally'): {'the': 1}, ('matrices', 'the'): {'prediction': 7, 'text': 3, 'context': 4, 'tokenizer': 2, 'trigram': 1, 'dataset': 3, 'n-gram': 4, 'weight': 4, 'evaluation': 4, 'output': 3, 'sequence': 3, 'neural': 3, 'softmax': 4, 'corpus': 5, 'gradient': 2, 'attention': 2, 'algorithm': 1, 'embedding': 1, 'bigram': 3, 'language': 4, 'system': 4, 'training': 4, 'model': 4, 'architecture': 2, 'loss': 3, 'input': 3, 'perplexity': 1, 'probability': 1, 'optimizer': 1, 'researcher': 3, 'vocabulary': 1}, ('hidden', 'states'): {'the': 78, 'perplexity': 2, 'iteratively': 14, 'correctly': 12, 'cross': 2, 'effectively': 14, 'a': 46, 'additionally': 2, 'probabilistically': 13, 'accurately': 16, 'successfully': 10, 'gradually': 21, 'bigram': 4, 'cleaning': 3, 'recursively': 12, 'rapidly': 10, 'subsequently': 4, 'efficiently': 13, 'nevertheless': 1, 'specifically': 2, 'in': 5, 'automatically': 10, 'sequentially': 9, 'statistically': 18, 'meanwhile': 2, 'gradient': 3, 'continuously': 8, 'overfitting': 2, 'furthermore': 3, 'however': 4, 'similarly': 2, 'significantly': 9, 'moreover': 2, 'consequently': 4, 'backpropagation': 3, 'data': 2, 'word': 2, 'smoothing': 3, 'for': 1, 'tokenization': 1, 'feeding': 1, 'regularization': 4, 'training': 4, 'transfer': 2, 'therefore': 2}, ('bigram', 'encodes'): {'sentence': 1, 'the': 6, 'token': 1, 'co-occurrence': 1, 'linguistic': 1, 'contextual': 2}, ('computes', 'sentence'): {'structure': 19}, ('in', 'addition'): {'the': 175, 'backpropagation': 4}, ('prediction', 'maximizes'): {'semantic': 1, 'the': 3, 'word': 2, 'language': 1}, ('encodes', 'large'): {'amounts': 12}, ('text', 'decodes'): {'syntactic': 1, 'the': 4, 'word': 1, 'co-occurrence': 1, 'sentence': 1, 'linguistic': 1}, ('prediction', 'continuously'): {'models': 1, 'adjusts': 2}, ('word', 'overfitting'): {'occurs': 3}, ('input', 'rapidly'): {'processes': 1, 'fine-tunes': 1, 'minimizes': 1, 'learns': 1, 'computes': 1}, ('statistically', 'moreover'): {'the': 7}, ('gradient', 'calculates'): {'millions': 1, 'the': 4}, ('states', 'feeding'): {'diverse': 1}, ('network', 'captures'): {'linguistic': 2, 'the': 9, 'co-occurrence': 1, 'syntactic': 2, 'statistical': 1}, ('automatically', 'cross'): {'entropy': 6}, ('bigram', 'minimizes'): {'the': 9, 'syntactic': 1}, ('window', 'learns'): {'from': 4}, ('probabilistically', 'increases'): {'the': 5, 'statistical': 3}, ('window', 'generates'): {'the': 3, 'millions': 1, 'token': 1, 'sentence': 1}, ('size', 'moreover'): {'the': 5}, ('model', 'calculates'): {'the': 8, 'linguistic': 2, 'word': 3, 'statistical': 1, 'semantic': 1, 'co-occurrence': 1}, ('optimizer', 'decodes'): {'word': 1, 'contextual': 1, 'the': 3, 'millions': 1, 'semantic': 1, 'token': 1, 'linguistic': 1}, ('gradient', 'descent'): {'a': 47, 'is': 94, 'rapidly': 16, 'significantly': 21, 'effectively': 8, 'sequentially': 14, 'efficiently': 15, 'furthermore': 1, 'the': 84, 'as': 2, 'successfully': 13, 'in': 6, 'iteratively': 14, 'for': 4, 'probabilistically': 12, 'gradually': 14, 'accurately': 13, 'correctly': 10, 'continuously': 15, 'data': 5, 'specifically': 2, 'recursively': 11, 'cross': 5, 'automatically': 9, 'similarly': 2, 'word': 1, 'meanwhile': 5, 'nevertheless': 2, 'however': 2, 'transfer': 1, 'subsequently': 4, 'backpropagation': 4, 'statistically': 18, 'perplexity': 2, 'additionally': 3, 'tokenization': 2, 'cleaning': 1, 'moreover': 2, 'training': 2, 'feeding': 1, 'gradient': 1, 'regularization': 1, 'bigram': 1}, ('significantly', 'overfitting'): {'occurs': 2}, ('function', 'as'): {'a': 5}, ('sequentially', 'generalizes'): {'sentence': 1, 'linguistic': 2, 'the': 2}, ('states', 'recursively'): {'a': 2, 'meanwhile': 1, 'cross': 1, 'the': 5, 'bigram': 2, 'regularization': 1}, ('successfully', 'predicts'): {'word': 1, 'the': 6, 'co-occurrence': 1}, ('frequencies', 'backpropagation'): {'automatically': 1, 'fine-tunes': 1, 'decodes': 1}, ('word', 'smoothing'): {'techniques': 2}, ('outputs', 'the'): {'vocabulary': 15, 'activation': 9, 'next': 8, 'corpus': 16, 'training': 11, 'loss': 8, 'cross': 15, 'learning': 16, 'batch': 17, 'bias': 15, 'weight': 19, 'softmax': 10, 'gradient': 20, 'hidden': 14, 'probability': 10}, ('dataset', 'tokenizes'): {'sentence': 1, 'token': 1, 'the': 3}, ('gradually', 'captures'): {'token': 1, 'the': 2, 'word': 1, 'language': 1}, ('prediction', 'captures'): {'the': 6, 'word': 1, 'co-occurrence': 1}, ('function', 'for'): {'example': 4}, ('rapidly', 'samples'): {'the': 4, 'co-occurrence': 1, 'contextual': 1}, ('terms', 'moreover'): {'the': 3}, ('probabilistically', 'optimizes'): {'the': 4, 'word': 1, 'semantic': 2, 'large': 1, 'linguistic': 1}, ('perplexity', 'significantly'): {'outputs': 1, 'updates': 1, 'tokenizes': 1}, ('generative', 'the'): {'perplexity': 9, 'bigram': 5, 'output': 4, 'evaluation': 3, 'n-gram': 7, 'loss': 6, 'neural': 11, 'prediction': 6, 'text': 5, 'vocabulary': 5, 'weight': 4, 'architecture': 8, 'trigram': 7, 'context': 10, 'probability': 7, 'language': 5, 'system': 5, 'input': 6, 'gradient': 3, 'attention': 6, 'dataset': 4, 'algorithm': 3, 'sequence': 4, 'optimizer': 5, 'tokenizer': 2, 'training': 5, 'corpus': 4, 'researcher': 1}, ('word', 'continuously'): {'a': 3, 'the': 5, 'additionally': 1, 'overfitting': 1, 'cleaning': 1}, ('rate', 'effectively'): {'the': 5, 'a': 3, 'in': 2, 'similarly': 1, 'additionally': 1}, ('rapidly', 'the'): {'text': 4, 'training': 14, 'vocabulary': 10, 'perplexity': 5, 'model': 9, 'sequence': 7, 'gradient': 10, 'language': 6, 'dataset': 6, 'prediction': 8, 'system': 5, 'researcher': 4, 'input': 5, 'embedding': 4, 'loss': 10, 'n-gram': 2, 'evaluation': 7, 'bigram': 2, 'frequency': 7, 'softmax': 4, 'trigram': 4, 'weight': 3, 'output': 1, 'context': 6, 'tokenizer': 5, 'neural': 6, 'architecture': 7, 'algorithm': 4, 'attention': 3, 'corpus': 5, 'optimizer': 2, 'probability': 1}, ('architecture', 'correctly'): {'converges': 1, 'calculates': 1, 'evaluates': 1, 'samples': 1, 'trains': 1, 'maximizes': 1, 'diverges': 1, 'overfits': 1, 'represents': 1, 'reduces': 1, 'updates': 1}, ('significantly', 'smoothing'): {'techniques': 3}, ('from', 'language'): {'patterns': 17}, ('optimizer', 'trains'): {'on': 8}, ('significantly', 'maximizes'): {'contextual': 1, 'semantic': 1, 'the': 3}, ('language', 'text'): {'the': 51, 'however': 3, 'furthermore': 2, 'as': 3, 'a': 22, 'specifically': 1, 'subsequently': 5, 'nevertheless': 3, 'similarly': 3, 'therefore': 4, 'meanwhile': 1, 'consequently': 2, 'moreover': 2, 'in': 1, 'backpropagation': 1}, ('the', 'n-gram'): {'predicts': 15, 'processes': 13, 'represents': 13, 'diverges': 9, 'accurately': 4, 'minimizes': 12, 'increases': 6, 'trains': 16, 'decodes': 7, 'encodes': 10, 'recursively': 6, 'tokenizes': 10, 'converges': 10, 'sequentially': 5, 'computes': 10, 'successfully': 3, 'evaluates': 7, 'reduces': 10, 'continuously': 8, 'fine-tunes': 11, 'outputs': 8, 'significantly': 3, 'captures': 12, 'generalizes': 11, 'correctly': 5, 'rapidly': 5, 'models': 9, 'overfits': 11, 'adjusts': 10, 'improves': 11, 'maximizes': 6, 'statistically': 9, 'automatically': 5, 'samples': 11, 'updates': 11, 'optimizes': 6, 'effectively': 7, 'calculates': 6, 'generates': 6, 'efficiently': 2, 'probabilistically': 2, 'iteratively': 2, 'learns': 6, 'gradually': 7}, ('overfits', 'sentence'): {'structure': 7}, ('rules', 'automatically'): {'the': 10, 'smoothing': 1, 'cross': 1, 'overfitting': 1, 'a': 4, 'in': 1, 'consequently': 1, 'transfer': 1}, ('weight', 'fine-tunes'): {'the': 6, 'large': 1, 'linguistic': 1, 'sentence': 2, 'co-occurrence': 1, 'contextual': 1, 'word': 1, 'semantic': 1}, ('sequentially', 'converges'): {'the': 2, 'contextual': 1, 'millions': 1, 'token': 1}, ('descent', 'similarly'): {'the': 2}, ('algorithm', 'diverges'): {'token': 1, 'word': 1, 'the': 6, 'language': 1, 'sentence': 1, 'syntactic': 1}, ('corpus', 'represents'): {'the': 8, 'contextual': 1, 'co-occurrence': 1, 'statistical': 1, 'language': 1, 'millions': 1}, ('sequence', 'generalizes'): {'token': 3, 'linguistic': 1, 'the': 5, 'sentence': 1, 'language': 1}, ('rapidly', 'improves'): {'token': 1, 'the': 5, 'syntactic': 1, 'statistical': 1}, ('rapidly', 'overfits'): {'the': 2, 'large': 1, 'millions': 1, 'word': 1, 'token': 1}, ('bigram', 'computes'): {'linguistic': 1, 'the': 5, 'word': 1, 'large': 1}, ('perplexity', 'decodes'): {'co-occurrence': 2, 'the': 5, 'token': 1, 'contextual': 2}, ('reduces', 'language'): {'patterns': 15}, ('optimizer', 'models'): {'token': 1, 'large': 1}, ('word', 'regularization'): {'techniques': 3}, ('window', 'accurately'): {'minimizes': 1, 'evaluates': 2, 'predicts': 2, 'encodes': 1, 'tokenizes': 1, 'captures': 1}, ('function', 'tokenization'): {'is': 1}, ('decodes', 'language'): {'patterns': 7}, ('generalizes', 'token'): {'sequences': 9}, ('processes', 'sentence'): {'structure': 15}, ('efficiently', 'however'): {'the': 4}, ('gradient', 'outputs'): {'language': 1, 'the': 7, 'token': 1, 'word': 1, 'statistical': 1}, ('efficiently', 'nevertheless'): {'the': 11}, ('rate', 'the'): {'n-gram': 2, 'training': 2, 'gradient': 3, 'frequency': 2, 'researcher': 2, 'loss': 4, 'text': 2, 'input': 5, 'weight': 8, 'bigram': 2, 'vocabulary': 4, 'neural': 4, 'softmax': 2, 'evaluation': 4, 'attention': 2, 'perplexity': 3, 'optimizer': 3, 'context': 2, 'algorithm': 2, 'sequence': 1, 'language': 2, 'corpus': 3, 'prediction': 3, 'tokenizer': 1, 'embedding': 3, 'dataset': 2, 'architecture': 1, 'output': 1, 'system': 2, 'probability': 1}, ('text', 'sequentially'): {'tokenization': 1, 'a': 4, 'in': 1, 'captures': 1, 'the': 6, 'word': 1, 'moreover': 1, 'feeding': 1, 'training': 1, 'maximizes': 1, 'data': 1, 'updates': 1, 'transfer': 1, 'optimizes': 1, 'however': 1, 'predicts': 1}, ('rules', 'transfer'): {'learning': 4}, ('the', 'corpus'): {'diverges': 7, 'rapidly': 19, 'decodes': 7, 'correctly': 15, 'the': 99, 'calculates': 13, 'adjusts': 6, 'a': 63, 'statistically': 16, 'predicts': 19, 'increases': 14, 'minimizes': 14, 'meanwhile': 2, 'computes': 7, 'recursively': 16, 'models': 9, 'smoothing': 3, 'successfully': 24, 'cross': 2, 'sequentially': 16, 'overfitting': 3, 'continuously': 25, 'efficiently': 18, 'encodes': 9, 'however': 6, 'represents': 13, 'optimizes': 9, 'effectively': 28, 'fine-tunes': 10, 'iteratively': 16, 'subsequently': 7, 'processes': 6, 'generates': 5, 'converges': 9, 'learns': 12, 'overfits': 6, 'significantly': 25, 'samples': 7, 'improves': 6, 'generalizes': 8, 'accurately': 15, 'probabilistically': 17, 'moreover': 3, 'tokenizes': 7, 'automatically': 13, 'gradually': 22, 'furthermore': 3, 'perplexity': 2, 'updates': 6, 'for': 3, 'gradient': 1, 'captures': 7, 'additionally': 2, 'maximizes': 10, 'trains': 2, 'regularization': 2, 'transfer': 2, 'reduces': 5, 'in': 3, 'data': 2, 'tokenization': 1, 'consequently': 2, 'bigram': 2, 'similarly': 2, 'outputs': 6, 'backpropagation': 1, 'as': 5, 'therefore': 1, 'word': 1, 'evaluates': 9, 'specifically': 1, 'nevertheless': 1, 'feeding': 1, 'cleaning': 1}, ('perplexity', 'trains'): {'on': 5}, ('backpropagation', 'computes'): {'the': 4, 'token': 1, 'semantic': 1, 'language': 1, 'co-occurrence': 1}, ('sequentially', 'samples'): {'the': 1, 'word': 1}, ('vocabulary', 'evaluates'): {'word': 2, 'syntactic': 1, 'the': 1}, ('model', 'outputs'): {'the': 8, 'co-occurrence': 1, 'word': 2, 'millions': 1}, ('evaluates', 'syntactic'): {'rules': 12}, ('automatically', 'adjusts'): {'the': 2, 'contextual': 2, 'language': 1}, ('continuously', 'predicts'): {'contextual': 2, 'the': 6, 'millions': 1, 'semantic': 3, 'language': 1, 'token': 1, 'word': 1}, ('space', 'backpropagation'): {'tokenizes': 1}, ('sequentially', 'the'): {'optimizer': 4, 'algorithm': 9, 'perplexity': 5, 'tokenizer': 6, 'attention': 6, 'training': 10, 'text': 7, 'neural': 3, 'trigram': 4, 'frequency': 6, 'researcher': 6, 'corpus': 4, 'gradient': 1, 'evaluation': 5, 'sequence': 7, 'context': 8, 'n-gram': 5, 'probability': 3, 'input': 6, 'weight': 7, 'vocabulary': 7, 'embedding': 5, 'prediction': 5, 'model': 4, 'softmax': 2, 'output': 4, 'language': 6, 'loss': 7, 'bigram': 4, 'system': 4, 'architecture': 4, 'dataset': 3}, ('mechanism', 'represents'): {'word': 1, 'the': 3, 'token': 1, 'contextual': 1, 'sentence': 1, 'large': 1, 'statistical': 1}, ('effectively', 'similarly'): {'the': 6}, ('distribution', 'meanwhile'): {'the': 8}, ('corpus', 'a'): {'discriminative': 6, 'scalable': 5, 'robust': 5, 'large': 6, 'shallow': 5, 'autoregressive': 4, 'efficient': 4, 'fine-tuned': 6, 'small': 4, 'powerful': 4, 'bidirectional': 7, 'recurrent': 4, 'statistical': 4, 'neural': 3, 'lightweight': 4, 'generative': 5, 'deep': 2, 'transformer-based': 4, 'pre-trained': 1, 'accurate': 2}, ('adjusts', 'syntactic'): {'rules': 11}, ('effectively', 'bigram'): {'and': 2}, ('probabilistically', 'cleaning'): {'and': 4}, ('perplexity', 'models'): {'the': 6, 'sentence': 1, 'language': 1, 'statistical': 1}, ('optimizes', 'the'): {'loss': 16, 'bias': 13, 'cross': 12, 'activation': 13, 'hidden': 14, 'weight': 13, 'corpus': 9, 'softmax': 11, 'gradient': 7, 'next': 9, 'learning': 15, 'probability': 8, 'training': 11, 'vocabulary': 10, 'batch': 13}, ('frequencies', 'feeding'): {'diverse': 2}, ('sequentially', 'improves'): {'the': 8, 'language': 1, 'token': 1, 'millions': 1}, ('sequentially', 'overfits'): {'word': 1, 'the': 3, 'token': 1}, ('memory', 'requirements'): {'of': 108}, ('sequence', 'samples'): {'contextual': 1, 'the': 6}, ('generates', 'semantic'): {'meaning': 13}, ('probability', 'evaluates'): {'the': 5, 'statistical': 1, 'word': 3, 'millions': 1, 'sentence': 1}, ('bigram', 'successfully'): {'calculates': 1}, ('network', 'generalizes'): {'co-occurrence': 1, 'the': 8, 'semantic': 2}, ('accurately', 'backpropagation'): {'gradually': 1, 'models': 1, 'significantly': 1, 'processes': 1, 'iteratively': 1, 'outputs': 1}, ('rules', 'in'): {'addition': 4, 'contrast': 1}, ('rules', 'rapidly'): {'in': 1, 'additionally': 1, 'the': 7, 'a': 1, 'as': 2, 'feeding': 1, 'however': 1}, ('metric', 'reduces'): {'large': 1, 'the': 3, 'contextual': 1}, ('gradually', 'generalizes'): {'the': 6}, ('prediction', 'generalizes'): {'large': 1, 'the': 5, 'language': 1, 'millions': 2, 'sentence': 1}, ('features', 'consequently'): {'the': 1}, ('captures', 'syntactic'): {'rules': 14}, ('process', 'converges'): {'the': 4, 'millions': 1, 'contextual': 1, 'syntactic': 1, 'token': 1, 'linguistic': 1, 'language': 1}, ('metric', 'tokenizes'): {'the': 5, 'sentence': 2, 'word': 1, 'co-occurrence': 1}, ('output', 'feeding'): {'diverse': 4}, ('backpropagation', 'successfully'): {'learns': 1, 'overfits': 1, 'increases': 1}, ('effectively', 'perplexity'): {'measures': 8}, ('sequence', 'improves'): {'semantic': 1, 'the': 6, 'linguistic': 1, 'co-occurrence': 2, 'syntactic': 2, 'token': 1}, ('sequence', 'overfits'): {'the': 9, 'word': 1, 'statistical': 1, 'token': 1, 'co-occurrence': 1}, ('network', 'converges'): {'token': 1, 'semantic': 2, 'the': 4, 'language': 1, 'statistical': 2}, ('sequences', 'automatically'): {'the': 7, 'tokenization': 1, 'a': 3}, ('effectively', 'calculates'): {'contextual': 1, 'the': 5, 'millions': 1, 'sentence': 1, 'word': 1, 'linguistic': 1}, ('rules', 'however'): {'the': 7}, ('correctly', 'overfitting'): {'occurs': 2}, ('probabilistically', 'additionally'): {'the': 6}, ('distribution', 'iteratively'): {'the': 4, 'bigram': 1, 'word': 2, 'a': 5, 'furthermore': 1, 'overfitting': 1, 'feeding': 1, 'subsequently': 1, 'backpropagation': 1}, ('layer', 'sequentially'): {'updates': 1, 'encodes': 1, 'predicts': 1}, ('information', 'bigram'): {'and': 5}, ('meanwhile', 'backpropagation'): {'updates': 1, 'overfits': 1, 'converges': 2, 'diverges': 1, 'generalizes': 2, 'increases': 1}, ('vocabulary', 'increases'): {'the': 9, 'semantic': 1, 'linguistic': 1, 'millions': 1, 'word': 2}, ('gradually', 'converges'): {'the': 8, 'word': 1, 'large': 1, 'linguistic': 1}, ('matrices', 'automatically'): {'the': 4, 'a': 4, 'as': 1}, ('researcher', 'effectively'): {'processes': 1, 'optimizes': 1, 'tokenizes': 1, 'generates': 2, 'represents': 1}, ('rapidly', 'meanwhile'): {'the': 6}, ('prediction', 'converges'): {'statistical': 1, 'semantic': 1, 'word': 2, 'the': 2}, ('text', 'encodes'): {'the': 7, 'syntactic': 1}, ('therefore', 'the'): {'evaluation': 7, 'prediction': 6, 'language': 11, 'corpus': 7, 'perplexity': 6, 'tokenizer': 11, 'optimizer': 6, 'bigram': 4, 'output': 6, 'dataset': 7, 'architecture': 8, 'algorithm': 3, 'input': 9, 'context': 3, 'vocabulary': 5, 'loss': 10, 'neural': 5, 'sequence': 4, 'training': 6, 'n-gram': 7, 'attention': 5, 'researcher': 5, 'probability': 7, 'trigram': 9, 'weight': 10, 'gradient': 6, 'embedding': 2, 'text': 2, 'system': 2, 'model': 1}, ('successfully', 'processes'): {'the': 2, 'sentence': 1, 'large': 1}, ('system', 'calculates'): {'contextual': 1, 'word': 2, 'the': 4, 'sentence': 1, 'syntactic': 2, 'statistical': 1, 'token': 1}, ('distribution', 'transfer'): {'learning': 2}, ('tokenizer', 'generalizes'): {'the': 2, 'syntactic': 1, 'millions': 1}, ('corpus', 'similarly'): {'the': 3}, ('probabilistically', 'cross'): {'entropy': 1}, ('rules', 'statistically'): {'the': 9, 'moreover': 1, 'a': 4, 'backpropagation': 1, 'consequently': 1}, ('bigram', 'updates'): {'token': 1, 'the': 4, 'language': 2, 'syntactic': 1, 'word': 4}, ('correctly', 'maximizes'): {'millions': 1, 'word': 1, 'co-occurrence': 1, 'the': 2}, ('vocabulary', 'optimizes'): {'contextual': 1, 'word': 2, 'token': 1, 'the': 5, 'semantic': 1}, ('mechanism', 'gradually'): {'processes': 1, 'adjusts': 1, 'increases': 1, 'tokenizes': 2, 'fine-tunes': 1}, ('vocabulary', 'iteratively'): {'reduces': 1}, ('significantly', 'diverges'): {'contextual': 2, 'the': 4, 'syntactic': 1, 'linguistic': 1}, ('automatically', 'as'): {'a': 8}, ('text', 'minimizes'): {'language': 1, 'the': 3, 'syntactic': 1, 'co-occurrence': 1, 'semantic': 1, 'word': 1}, ('combinations', 'gracefully'): {'the': 46, 'a': 21, 'additionally': 1, 'moreover': 5, 'in': 5, 'subsequently': 1, 'however': 1, 'nevertheless': 1, 'specifically': 2, 'therefore': 1, 'similarly': 1, 'for': 1, 'as': 1, 'consequently': 1}, ('gradient', 'adjusts'): {'statistical': 1, 'contextual': 1, 'large': 1, 'word': 2, 'the': 3, 'token': 1}, ('automatically', 'for'): {'example': 4}, ('algorithm', 'predicts'): {'millions': 1, 'the': 4, 'linguistic': 2, 'contextual': 2, 'co-occurrence': 2, 'word': 2, 'sentence': 2, 'large': 2}, ('computes', 'millions'): {'of': 9}, ('batch', 'size'): {'tokenization': 3, 'correctly': 11, 'statistically': 16, 'furthermore': 4, 'for': 3, 'accurately': 11, 'therefore': 11, 'data': 4, 'significantly': 13, 'iteratively': 18, 'transfer': 2, 'the': 104, 'probabilistically': 12, 'recursively': 11, 'rapidly': 9, 'a': 41, 'successfully': 14, 'automatically': 9, 'gradually': 16, 'in': 8, 'continuously': 14, 'sequentially': 10, 'similarly': 4, 'efficiently': 9, 'as': 7, 'effectively': 15, 'overfitting': 3, 'smoothing': 1, 'however': 3, 'moreover': 3, 'training': 1, 'subsequently': 2, 'consequently': 4, 'feeding': 1, 'bigram': 1, 'cleaning': 1, 'cross': 1, 'backpropagation': 1}, ('features', 'subsequently'): {'the': 6}, ('gradually', 'samples'): {'the': 3, 'language': 1, 'co-occurrence': 1, 'syntactic': 2}, ('the', 'softmax'): {'output': 390, 'function': 97}, ('converges', 'millions'): {'of': 18}, ('researcher', 'samples'): {'word': 1, 'the': 10, 'contextual': 1}, ('model', 'adjusts'): {'millions': 1, 'the': 10, 'statistical': 1, 'sentence': 1, 'token': 1, 'word': 1, 'syntactic': 1}, ('probability', 'increases'): {'the': 7, 'linguistic': 2, 'statistical': 2, 'large': 1, 'semantic': 1, 'contextual': 1, 'language': 1, 'sentence': 1, 'word': 2}, ('optimizer', 'minimizes'): {'the': 7, 'large': 1, 'language': 1, 'statistical': 1}, ('size', 'directly'): {'impacts': 108}, ('information', 'perplexity'): {'measures': 3}, ('discriminative', 'backpropagation'): {'learns': 1, 'processes': 1, 'calculates': 1, 'decodes': 1}, ('statistically', 'training'): {'a': 4}, ('accurately', 'feeding'): {'diverse': 4}, ('gradually', 'the'): {'perplexity': 2, 'context': 8, 'system': 8, 'architecture': 7, 'bigram': 3, 'softmax': 2, 'researcher': 7, 'training': 5, 'probability': 5, 'loss': 3, 'optimizer': 8, 'input': 3, 'vocabulary': 10, 'evaluation': 4, 'trigram': 7, 'language': 4, 'corpus': 5, 'weight': 7, 'gradient': 4, 'text': 2, 'embedding': 7, 'algorithm': 6, 'dataset': 7, 'frequency': 4, 'sequence': 3, 'neural': 6, 'model': 2, 'prediction': 3, 'n-gram': 1, 'attention': 3, 'output': 2, 'tokenizer': 2}, ('statistically', 'tokenizes'): {'token': 1, 'the': 4, 'linguistic': 1, 'language': 1}, ('bigram', 'diverges'): {'the': 4, 'large': 1, 'token': 1}, ('diverges', 'millions'): {'of': 17}, ('rapidly', 'increases'): {'syntactic': 2, 'the': 6, 'statistical': 1, 'word': 1}, ('statistically', 'therefore'): {'the': 8}, ('size', 'training'): {'a': 2}, ('probability', 'optimizes'): {'sentence': 2, 'the': 7, 'millions': 1, 'language': 1}, ('represents', 'large'): {'amounts': 12}, ('text', 'overfitting'): {'occurs': 3}, ('size', 'therefore'): {'the': 14}, ('generates', 'contextual'): {'information': 14}, ('distribution', 'in'): {'addition': 7, 'contrast': 3}, ('architecture', 'recursively'): {'adjusts': 1, 'fine-tunes': 1, 'updates': 1, 'captures': 1, 'predicts': 1}, ('probability', 'iteratively'): {'captures': 1, 'samples': 1, 'outputs': 1, 'calculates': 1, 'generates': 1}, ('model', 'subsequently'): {'the': 3}, ('effectively', 'outputs'): {'the': 4, 'sentence': 1, 'word': 1}, ('recursively', 'represents'): {'the': 6, 'word': 1, 'statistical': 1, 'semantic': 2}, ('gracefully', 'the'): {'evaluation': 3, 'architecture': 3, 'gradient': 2, 'neural': 3, 'dataset': 1, 'corpus': 1, 'training': 3, 'probability': 2, 'vocabulary': 1, 'trigram': 4, 'attention': 3, 'prediction': 1, 'loss': 3, 'language': 3, 'text': 1, 'weight': 1, 'system': 2, 'context': 2, 'input': 2, 'sequence': 1, 'embedding': 1, 'optimizer': 1, 'model': 1, 'algorithm': 1}, ('terms', 'training'): {'a': 1}, ('gradually', 'improves'): {'the': 1, 'language': 1, 'co-occurrence': 1, 'millions': 1, 'token': 1, 'syntactic': 1}, ('distribution', 'cleaning'): {'and': 2}, ('researcher', 'improves'): {'syntactic': 1, 'the': 8, 'co-occurrence': 1, 'token': 1, 'word': 1, 'linguistic': 1}, ('parameters', 'correctly'): {'bigram': 1, 'the': 7, 'a': 5, 'overfitting': 1, 'meanwhile': 1, 'similarly': 1, 'data': 1, 'backpropagation': 1}, ('gradually', 'overfits'): {'the': 2, 'contextual': 1}, ('generates', 'the'): {'probability': 14, 'training': 20, 'batch': 9, 'vocabulary': 12, 'cross': 18, 'gradient': 15, 'bias': 15, 'softmax': 19, 'weight': 16, 'next': 12, 'learning': 18, 'loss': 14, 'activation': 14, 'hidden': 13, 'corpus': 10}, ('n-gram', 'efficiently'): {'trains': 1, 'diverges': 1}, ('automatically', 'tokenization'): {'is': 2}, ('terms', 'therefore'): {'the': 6, 'backpropagation': 1}, ('tokenizer', 'samples'): {'the': 6, 'large': 3, 'linguistic': 1, 'sentence': 1, 'word': 1, 'syntactic': 1}, ('gradient', 'fine-tunes'): {'contextual': 2, 'the': 6, 'large': 1}, ('system', 'outputs'): {'linguistic': 1, 'language': 1, 'the': 4, 'word': 2}, ('continuously', 'processes'): {'the': 2, 'large': 1}, ('text', 'smoothing'): {'techniques': 1}, ('samples', 'word'): {'frequencies': 16, 'embeddings': 4}, ('sequences', 'rapidly'): {'the': 6, 'a': 1, 'for': 1}, ('iteratively', 'represents'): {'syntactic': 1, 'the': 3, 'word': 1}, ('rapidly', 'transfer'): {'learning': 2}, ('text', 'maximizes'): {'statistical': 2, 'the': 9, 'contextual': 1, 'syntactic': 1, 'co-occurrence': 1}, ('successfully', 'nevertheless'): {'the': 4}, ('model', 'fine-tunes'): {'syntactic': 1, 'the': 6, 'semantic': 2, 'contextual': 1, 'word': 1, 'statistical': 1}, ('information', 'cleaning'): {'and': 1}, ('text', 'continuously'): {'the': 3, 'predicts': 3, 'nevertheless': 1, 'backpropagation': 1, 'subsequently': 1, 'cross': 2, 'bigram': 1, 'a': 4, 'represents': 1, 'maximizes': 1, 'reduces': 1, 'calculates': 1, 'learns': 1}, ('matrices', 'in'): {'addition': 3, 'contrast': 1}, ('the', 'text'): {'reduces': 10, 'recursively': 6, 'outputs': 8, 'generates': 16, 'trains': 8, 'probabilistically': 8, 'samples': 11, 'successfully': 6, 'predicts': 21, 'learns': 6, 'encodes': 8, 'represents': 7, 'decodes': 9, 'fine-tunes': 16, 'continuously': 8, 'calculates': 17, 'rapidly': 2, 'processes': 8, 'computes': 13, 'minimizes': 8, 'models': 10, 'iteratively': 6, 'adjusts': 6, 'maximizes': 14, 'statistically': 2, 'increases': 7, 'converges': 7, 'updates': 9, 'tokenizes': 5, 'correctly': 9, 'automatically': 6, 'evaluates': 10, 'accurately': 5, 'diverges': 11, 'overfits': 9, 'sequentially': 5, 'generalizes': 3, 'improves': 8, 'efficiently': 6, 'captures': 5, 'optimizes': 7, 'gradually': 4, 'effectively': 4, 'significantly': 4}, ('layer', 'encodes'): {'the': 5, 'contextual': 1, 'statistical': 1, 'millions': 1, 'word': 1, 'sentence': 1, 'linguistic': 1, 'large': 1}, ('automatically', 'gradient'): {'descent': 3}, ('rules', 'moreover'): {'the': 3}, ('process', 'predicts'): {'the': 11, 'linguistic': 1, 'syntactic': 3, 'semantic': 1, 'millions': 2, 'token': 1, 'large': 1, 'word': 1}, ('matrices', 'rapidly'): {'a': 2, 'the': 4, 'consequently': 2, 'subsequently': 1, 'in': 1, 'regularization': 1, 'therefore': 1}, ('word', 'prediction'): {'a': 18, 'the': 46, 'specifically': 2, 'however': 2, 'as': 4, 'therefore': 1, 'furthermore': 1, 'nevertheless': 2, 'additionally': 2, 'similarly': 5, 'in': 2, 'meanwhile': 2, 'for': 2, 'consequently': 1}, ('optimizer', 'maximizes'): {'large': 1, 'semantic': 2, 'the': 5, 'statistical': 1}, ('sequences', 'however'): {'the': 4}, ('window', 'represents'): {'millions': 1, 'the': 4, 'word': 1, 'linguistic': 1, 'statistical': 1, 'semantic': 1}, ('tokenizer', 'improves'): {'the': 5, 'linguistic': 1, 'co-occurrence': 1, 'semantic': 1}, ('reduces', 'syntactic'): {'rules': 13}, ('tokenizer', 'overfits'): {'sentence': 1, 'the': 7, 'word': 1, 'language': 1}, ('optimizer', 'continuously'): {'evaluates': 2, 'increases': 1, 'calculates': 1, 'learns': 1, 'adjusts': 1, 'decodes': 1}, ('layer', 'minimizes'): {'statistical': 1, 'large': 2, 'language': 1, 'semantic': 1, 'the': 3, 'word': 1, 'token': 1}, ('decodes', 'syntactic'): {'rules': 15}, ('recursively', 'a'): {'neural': 2, 'deep': 3, 'small': 3, 'pre-trained': 5, 'shallow': 6, 'bidirectional': 4, 'large': 7, 'recurrent': 2, 'statistical': 4, 'powerful': 8, 'efficient': 3, 'lightweight': 6, 'accurate': 4, 'fine-tuned': 5, 'scalable': 4, 'robust': 3, 'autoregressive': 7, 'generative': 4, 'language': 3, 'discriminative': 2, 'transformer-based': 1}, ('trigram', 'correctly'): {'improves': 1, 'predicts': 2, 'increases': 1, 'converges': 1, 'samples': 1, 'tokenizes': 1}, ('automatically', 'learns'): {'from': 6}, ('a', 'transformer-based'): {'the': 127, 'backpropagation': 10}, ('updates', 'word'): {'frequencies': 16, 'embeddings': 15}, ('backpropagation', 'correctly'): {'processes': 1, 'represents': 1, 'learns': 1, 'improves': 1, 'evaluates': 1, 'captures': 1, 'outputs': 1, 'overfits': 1, 'tokenizes': 1, 'decodes': 1}, ('data', 'the'): {'input': 2, 'attention': 1, 'bigram': 3, 'system': 5, 'weight': 2, 'researcher': 4, 'evaluation': 3, 'tokenizer': 2, 'prediction': 4, 'probability': 4, 'corpus': 3, 'vocabulary': 5, 'text': 3, 'embedding': 2, 'gradient': 3, 'optimizer': 2, 'neural': 4, 'frequency': 2, 'model': 2, 'sequence': 3, 'context': 3, 'dataset': 3, 'loss': 1, 'training': 1, 'language': 1, 'output': 2, 'algorithm': 1, 'perplexity': 1, 'trigram': 1, 'n-gram': 1}, ('automatically', 'generates'): {'language': 1, 'the': 1}, ('matrices', 'however'): {'the': 1}, ('prediction', 'predicts'): {'word': 4, 'the': 12, 'sentence': 4, 'semantic': 2, 'language': 1, 'contextual': 1, 'linguistic': 1, 'millions': 1, 'syntactic': 2, 'statistical': 1}, ('sequences', 'statistically'): {'the': 5, 'as': 1, 'feeding': 2, 'a': 3, 'transfer': 1, 'cross': 1}, ('rate', 'transfer'): {'learning': 3}, ('distribution', 'additionally'): {'the': 6}, ('pipeline', 'as'): {'a': 1}, ('states', 'sequentially'): {'the': 3, 'nevertheless': 2, 'backpropagation': 1, 'however': 1, 'overfitting': 1, 'a': 1}, ('iteratively', 'a'): {'scalable': 8, 'autoregressive': 4, 'robust': 4, 'statistical': 3, 'transformer-based': 3, 'small': 4, 'deep': 5, 'bidirectional': 6, 'discriminative': 3, 'efficient': 5, 'lightweight': 5, 'accurate': 4, 'generative': 3, 'recurrent': 2, 'fine-tuned': 5, 'large': 2, 'pre-trained': 4, 'language': 2, 'neural': 2, 'shallow': 3, 'powerful': 1}, ('rapidly', 'in'): {'addition': 7, 'contrast': 5}, ('pipeline', 'for'): {'example': 4}, ('model', 'as'): {'a': 6}, ('matrices', 'statistically'): {'the': 8, 'a': 1, 'subsequently': 1}, ('parameters', 'a'): {'neural': 3, 'recurrent': 3, 'autoregressive': 5, 'scalable': 5, 'generative': 6, 'bidirectional': 2, 'small': 3, 'lightweight': 2, 'deep': 3, 'language': 1, 'efficient': 2, 'powerful': 2, 'discriminative': 1, 'statistical': 4, 'transformer-based': 1, 'accurate': 1, 'shallow': 3, 'fine-tuned': 1, 'pre-trained': 1, 'robust': 1, 'large': 1}, ('sequentially', 'transfer'): {'learning': 5}, ('tokenizes', 'syntactic'): {'rules': 11}, ('a', 'statistical'): {'the': 126, 'backpropagation': 5}, ('sequence', 'automatically'): {'reduces': 2, 'encodes': 1, 'generalizes': 1, 'updates': 1, 'overfits': 1, 'diverges': 1}, ('perplexity', 'maximizes'): {'word': 1, 'the': 5, 'semantic': 2, 'syntactic': 1, 'language': 1, 'statistical': 1}, ('model', 'for'): {'assigning': 111, 'example': 4}, ('perplexity', 'continuously'): {'models': 1, 'adjusts': 1, 'converges': 2, 'represents': 2, 'minimizes': 1, 'trains': 1, 'encodes': 1}, ('continuously', 'nevertheless'): {'the': 4, 'backpropagation': 1}, ('layer', 'computes'): {'the': 4, 'linguistic': 1, 'language': 2, 'millions': 1}, ('statistically', 'data'): {'preprocessing': 3}, ('on', 'token'): {'sequences': 14}, ('metric', 'effectively'): {'updates': 1, 'predicts': 1, 'diverges': 1, 'processes': 1, 'evaluates': 1, 'reduces': 1}, ('structure', 'the'): {'optimizer': 2, 'prediction': 5, 'weight': 2, 'n-gram': 3, 'output': 2, 'system': 6, 'frequency': 4, 'context': 9, 'gradient': 6, 'model': 3, 'vocabulary': 4, 'loss': 4, 'dataset': 3, 'researcher': 4, 'attention': 1, 'probability': 5, 'text': 4, 'corpus': 4, 'language': 1, 'evaluation': 3, 'sequence': 4, 'bigram': 4, 'trigram': 5, 'softmax': 1, 'embedding': 2, 'architecture': 4, 'training': 4, 'perplexity': 1, 'input': 1}, ('information', 'cross'): {'entropy': 4}, ('correctly', 'diverges'): {'contextual': 1, 'the': 2}, ('size', 'data'): {'preprocessing': 4}, ('significantly', 'predicts'): {'the': 9, 'contextual': 2, 'language': 1, 'linguistic': 1, 'sentence': 1}, ('meaning', 'automatically'): {'the': 6, 'a': 2, 'as': 1, 'specifically': 1, 'in': 1, 'feeding': 1, 'word': 1}, ('input', 'tokenizes'): {'contextual': 1, 'the': 3, 'millions': 1, 'semantic': 1}, ('descent', 'specifically'): {'the': 2}, ('rate', 'in'): {'contrast': 1}, ('perplexity', 'captures'): {'token': 1, 'co-occurrence': 2, 'linguistic': 1, 'language': 1, 'the': 4}, ('used', 'to'): {'minimize': 94}, ('the', 'bigram'): {'diverges': 6, 'reduces': 13, 'encodes': 12, 'efficiently': 6, 'tokenizes': 10, 'iteratively': 5, 'rapidly': 6, 'optimizes': 11, 'calculates': 11, 'automatically': 2, 'sequentially': 11, 'represents': 11, 'decodes': 12, 'recursively': 8, 'effectively': 6, 'generalizes': 7, 'trains': 9, 'improves': 11, 'maximizes': 9, 'processes': 7, 'overfits': 7, 'updates': 12, 'evaluates': 12, 'learns': 8, 'models': 6, 'minimizes': 10, 'outputs': 13, 'generates': 7, 'captures': 7, 'predicts': 13, 'statistically': 3, 'computes': 8, 'adjusts': 6, 'probabilistically': 8, 'accurately': 6, 'significantly': 7, 'converges': 10, 'fine-tunes': 9, 'correctly': 2, 'samples': 6, 'continuously': 8, 'gradually': 4, 'increases': 3, 'successfully': 1}, ('matrix', 'the'): {'optimizer': 3, 'gradient': 2, 'context': 7, 'perplexity': 3, 'output': 1, 'vocabulary': 5, 'frequency': 3, 'sequence': 6, 'dataset': 4, 'text': 3, 'training': 3, 'probability': 1, 'tokenizer': 3, 'algorithm': 4, 'loss': 2, 'attention': 3, 'neural': 3, 'weight': 3, 'prediction': 2, 'model': 4, 'architecture': 1, 'softmax': 2, 'trigram': 3, 'language': 1, 'bigram': 2, 'input': 2, 'system': 5, 'evaluation': 3, 'corpus': 3}, ('rate', 'rapidly'): {'however': 2, 'a': 1, 'subsequently': 2, 'the': 11, 'similarly': 1, 'data': 1}, ('terms', 'data'): {'preprocessing': 1}, ('effectively', 'adjusts'): {'statistical': 1, 'semantic': 1, 'millions': 1, 'the': 2}, ('algorithm', 'processes'): {'language': 1, 'millions': 1, 'statistical': 1, 'the': 1, 'contextual': 1}, ('recursively', 'similarly'): {'the': 2}, ('updates', 'linguistic'): {'features': 13}, ('outputs', 'statistical'): {'patterns': 13}, ('output', 'decodes'): {'token': 1, 'the': 5, 'linguistic': 1, 'sentence': 1}, ('sequentially', 'in'): {'addition': 4, 'contrast': 9}, ('however', 'backpropagation'): {'fine-tunes': 1, 'models': 2, 'updates': 1}, ('n-gram', 'learns'): {'from': 6}, ('word', 'combinations'): {'gracefully': 88}, ('recursively', 'bigram'): {'and': 5}, ('n-gram', 'generates'): {'the': 4, 'language': 1, 'word': 1}, ('correctly', 'converges'): {'the': 5, 'sentence': 1, 'semantic': 2}, ('system', 'adjusts'): {'the': 3, 'millions': 1, 'linguistic': 1}, ('text', 'updates'): {'sentence': 2, 'word': 2, 'the': 3, 'linguistic': 1, 'language': 1}, ('patterns', 'overfitting'): {'occurs': 7}, ('window', 'gradually'): {'decodes': 2, 'diverges': 1}, ('directly', 'impacts'): {'the': 108}, ('rapidly', 'additionally'): {'the': 6}, ('sequences', 'moreover'): {'the': 3}, ('iteratively', 'similarly'): {'backpropagation': 1, 'the': 5}, ('effectively', 'subsequently'): {'the': 9}, ('statistically', 'furthermore'): {'the': 5}, ('efficiently', 'reduces'): {'the': 4, 'linguistic': 1, 'syntactic': 1}, ('function', 'represents'): {'linguistic': 1, 'the': 5, 'sentence': 1, 'semantic': 1, 'syntactic': 1, 'word': 1, 'token': 1, 'millions': 1}, ('descent', 'sequentially'): {'cleaning': 1, 'meanwhile': 1, 'training': 1, 'the': 4, 'moreover': 2, 'for': 1, 'however': 1, 'furthermore': 1, 'feeding': 1, 'a': 1}, ('value', 'nevertheless'): {'the': 2}, ('embeddings', 'significantly'): {'a': 3, 'additionally': 2, 'the': 4, 'feeding': 1, 'meanwhile': 1, 'transfer': 1, 'smoothing': 1}, ('output', 'trains'): {'on': 8}, ('network', 'automatically'): {'captures': 1, 'fine-tunes': 1, 'adjusts': 1, 'encodes': 1}, ('size', 'furthermore'): {'the': 9}, ('loss', 'automatically'): {'a': 2, 'the': 9, 'similarly': 3, 'backpropagation': 1, 'consequently': 1, 'as': 1, 'additionally': 1, 'cross': 1, 'however': 1}, ('matrices', 'moreover'): {'the': 2}, ('sequentially', 'however'): {'the': 9}, ('patterns', 'smoothing'): {'techniques': 3}, ('layer', 'successfully'): {'learns': 1, 'predicts': 1, 'adjusts': 1, 'improves': 1, 'optimizes': 1}, ('the', 'perplexity'): {'models': 9, 'correctly': 7, 'captures': 9, 'predicts': 17, 'computes': 13, 'accurately': 7, 'processes': 16, 'diverges': 9, 'minimizes': 7, 'represents': 11, 'fine-tunes': 9, 'optimizes': 9, 'outputs': 9, 'continuously': 9, 'generalizes': 5, 'generates': 10, 'adjusts': 9, 'reduces': 5, 'gradually': 9, 'learns': 10, 'successfully': 6, 'samples': 6, 'decodes': 10, 'increases': 8, 'maximizes': 11, 'trains': 5, 'evaluates': 10, 'iteratively': 6, 'overfits': 9, 'updates': 9, 'statistically': 5, 'sequentially': 7, 'calculates': 9, 'effectively': 12, 'probabilistically': 4, 'improves': 10, 'tokenizes': 7, 'converges': 10, 'automatically': 4, 'efficiently': 5, 'encodes': 5, 'rapidly': 3, 'recursively': 3, 'significantly': 3}, ('rate', 'statistically'): {'the': 7, 'similarly': 1, 'subsequently': 2, 'a': 3, 'consequently': 1, 'feeding': 1}, ('corpus', 'consequently'): {'the': 2}, ('terms', 'furthermore'): {'the': 2}, ('effectively', 'fine-tunes'): {'the': 4, 'millions': 1, 'token': 1}, ('researcher', 'increases'): {'the': 5, 'millions': 1, 'large': 1, 'linguistic': 2, 'co-occurrence': 2, 'sentence': 1}, ('patterns', 'continuously'): {'the': 5, 'cross': 1, 'feeding': 2, 'a': 4, 'specifically': 2, 'tokenization': 1, 'perplexity': 1, 'bigram': 1, 'transfer': 1, 'additionally': 1, 'subsequently': 1}, ('prediction', 'automatically'): {'improves': 1, 'overfits': 1, 'increases': 1, 'decodes': 1, 'outputs': 1}, ('text', 'diverges'): {'the': 5, 'large': 1, 'syntactic': 1, 'linguistic': 1, 'co-occurrence': 1, 'millions': 1, 'contextual': 1}, ('value', 'significantly'): {'the': 6, 'consequently': 1, 'additionally': 1, 'bigram': 1, 'training': 1, 'subsequently': 1}, ('successfully', 'word'): {'embeddings': 1}, ('sequence', 'rapidly'): {'outputs': 1, 'learns': 2, 'increases': 1, 'decodes': 1, 'optimizes': 1, 'adjusts': 1, 'predicts': 1}, ('output', 'models'): {'semantic': 1, 'large': 1, 'the': 2, 'language': 1}, ('size', 'effectively'): {'the': 12, 'similarly': 1, 'a': 3, 'tokenization': 1, 'in': 1, 'subsequently': 1, 'backpropagation': 2, 'as': 1, 'nevertheless': 1, 'perplexity': 1, 'moreover': 1, 'overfitting': 1, 'furthermore': 1}, ('system', 'fine-tunes'): {'the': 4, 'language': 1}, ('process', 'processes'): {'semantic': 1, 'contextual': 1, 'the': 2, 'sentence': 1}, ('n-gram', 'accurately'): {'outputs': 1, 'converges': 2, 'calculates': 1}, ('optimizer', 'diverges'): {'the': 9, 'large': 1, 'contextual': 1}, ('recursively', 'calculates'): {'the': 1, 'contextual': 1}, ('researcher', 'iteratively'): {'generates': 1, 'samples': 1, 'converges': 1, 'calculates': 1, 'diverges': 1, 'learns': 1, 'adjusts': 1}, ('function', 'a'): {'deep': 2, 'small': 2, 'scalable': 6, 'bidirectional': 1, 'transformer-based': 4, 'large': 2, 'shallow': 1, 'statistical': 3, 'recurrent': 2, 'fine-tuned': 2, 'powerful': 4, 'robust': 2, 'neural': 1, 'language': 2, 'efficient': 1, 'discriminative': 1, 'pre-trained': 1}, ('data', 'meanwhile'): {'the': 1}, ('accurately', 'decodes'): {'linguistic': 1, 'the': 1, 'millions': 1, 'token': 1}, ('parameters', 'recursively'): {'in': 1, 'the': 3, 'bigram': 1, 'nevertheless': 2, 'regularization': 1, 'a': 1, 'data': 2, 'moreover': 1}, ('transformer-based', 'backpropagation'): {'outputs': 1, 'tokenizes': 1, 'adjusts': 1, 'calculates': 1, 'evaluates': 1, 'generalizes': 1, 'optimizes': 1, 'minimizes': 1, 'generates': 1, 'diverges': 1}, ('gradually', 'transfer'): {'learning': 2}, ('probabilistically', 'gradient'): {'descent': 3}, ('rapidly', 'moreover'): {'the': 7}, ('tokenizer', 'automatically'): {'predicts': 1, 'captures': 2, 'adjusts': 1, 'represents': 1, 'increases': 1, 'processes': 1, 'calculates': 1}, ('probabilistically', 'tokenizes'): {'the': 2, 'language': 1, 'word': 1}, ('weight', 'correctly'): {'fine-tunes': 1, 'processes': 1, 'converges': 1, 'represents': 2, 'models': 1}, ('system', 'efficiently'): {'samples': 1, 'diverges': 1, 'adjusts': 1, 'trains': 1, 'increases': 1}, ('probabilistically', 'therefore'): {'the': 8}, ('scalable', 'the'): {'vocabulary': 3, 'weight': 9, 'training': 7, 'prediction': 6, 'output': 3, 'researcher': 2, 'input': 9, 'optimizer': 4, 'trigram': 6, 'evaluation': 3, 'algorithm': 4, 'sequence': 9, 'probability': 7, 'context': 2, 'attention': 6, 'loss': 2, 'text': 8, 'neural': 4, 'corpus': 3, 'dataset': 3, 'n-gram': 7, 'architecture': 6, 'perplexity': 6, 'bigram': 5, 'tokenizer': 7, 'system': 4, 'language': 3, 'gradient': 1, 'embedding': 2}, ('optimizes', 'statistical'): {'patterns': 18}, ('samples', 'co-occurrence'): {'matrices': 10}, ('prediction', 'processes'): {'the': 1, 'sentence': 1, 'millions': 1, 'large': 1, 'word': 1, 'statistical': 1, 'contextual': 1}, ('sequence', 'statistically'): {'outputs': 1, 'improves': 1, 'evaluates': 1, 'adjusts': 1}, ('states', 'overfitting'): {'occurs': 2}, ('effectively', 'as'): {'a': 4}, ('meaning', 'however'): {'the': 1}, ('layer', 'updates'): {'contextual': 1, 'the': 8, 'statistical': 1, 'millions': 1}, ('algorithm', 'significantly'): {'optimizes': 1, 'converges': 1}, ('probabilistically', 'learns'): {'from': 5}, ('probabilistically', 'generates'): {'the': 3, 'contextual': 1, 'language': 1}, ('effectively', 'for'): {'example': 5}, ('meaning', 'nevertheless'): {'the': 4}, ('states', 'smoothing'): {'techniques': 3}, ('data', 'automatically'): {'in': 1, 'the': 3, 'smoothing': 1, 'transfer': 1, 'as': 1, 'cross': 1}, ('corpus', 'specifically'): {'the': 3}, ('metric', 'evaluates'): {'linguistic': 1, 'word': 2, 'the': 2, 'contextual': 1, 'large': 1, 'token': 1, 'co-occurrence': 2, 'syntactic': 1}, ('rules', 'training'): {'a': 4}, ('continuously', 'word'): {'embeddings': 4}, ('trigram', 'recursively'): {'maximizes': 1, 'encodes': 1, 'generates': 1, 'processes': 1, 'represents': 1, 'converges': 1, 'fine-tunes': 1, 'minimizes': 1}, ('rate', 'moreover'): {'the': 3}, ('backpropagation', 'recursively'): {'samples': 1, 'overfits': 1, 'converges': 1, 'outputs': 1}, ('states', 'continuously'): {'specifically': 1, 'a': 2, 'in': 1, 'the': 3, 'nevertheless': 1}, ('updates', 'co-occurrence'): {'matrices': 13}, ('correctly', 'predicts'): {'the': 7, 'language': 1, 'millions': 1, 'statistical': 1, 'sentence': 1}, ('gradually', 'in'): {'contrast': 4, 'addition': 7}, ('layer', 'diverges'): {'the': 6, 'word': 1, 'linguistic': 1}, ('information', 'efficiently'): {'the': 3, 'nevertheless': 1, 'consequently': 1, 'a': 4, 'regularization': 1, 'word': 1, 'as': 1}, ('the', 'next'): {'word': 481}, ('researcher', 'rapidly'): {'calculates': 1, 'evaluates': 1, 'optimizes': 1, 'processes': 1}, ('sequentially', 'moreover'): {'the': 6}, ('predicts', 'millions'): {'of': 31}, ('vocabulary', 'efficiently'): {'predicts': 1, 'converges': 1, 'outputs': 1, 'improves': 1, 'optimizes': 1, 'calculates': 1, 'captures': 1, 'minimizes': 1, 'generates': 1, 'maximizes': 1}, ('significantly', 'processes'): {'millions': 1, 'sentence': 1, 'the': 2, 'word': 1}, ('dataset', 'calculates'): {'token': 2, 'linguistic': 1, 'the': 1, 'syntactic': 1}, ('perplexity', 'converges'): {'linguistic': 1, 'co-occurrence': 1, 'the': 5, 'token': 1, 'word': 2}, ('words', 'as'): {'a': 5}, ('contrast', 'the'): {'training': 7, 'architecture': 5, 'perplexity': 4, 'bigram': 6, 'probability': 9, 'input': 10, 'attention': 5, 'embedding': 3, 'text': 5, 'prediction': 6, 'researcher': 8, 'language': 5, 'optimizer': 7, 'dataset': 4, 'loss': 4, 'weight': 9, 'sequence': 10, 'output': 7, 'vocabulary': 8, 'tokenizer': 5, 'model': 5, 'n-gram': 2, 'evaluation': 8, 'corpus': 6, 'system': 3, 'context': 6, 'gradient': 4, 'algorithm': 3, 'neural': 6, 'trigram': 1}, ('loss', 'however'): {'the': 5}, ('function', 'similarly'): {'the': 5}, ('data', 'transfer'): {'learning': 1}, ('gracefully', 'in'): {'contrast': 4, 'addition': 1}, ('words', 'for'): {'example': 1}, ('corpus', 'sequentially'): {'the': 5, 'tokenizes': 1, 'computes': 1, 'backpropagation': 1, 'a': 3, 'nevertheless': 1, 'additionally': 1, 'subsequently': 1, 'transfer': 1, 'minimizes': 1}, ('embeddings', 'word'): {'embeddings': 1}, ('states', 'regularization'): {'techniques': 4}, ('loss', 'nevertheless'): {'the': 3}, ('architecture', 'sequentially'): {'predicts': 1, 'learns': 1, 'encodes': 1, 'improves': 1, 'trains': 1, 'fine-tunes': 1, 'captures': 1}, ('algorithm', 'trains'): {'on': 10}, ('samples', 'semantic'): {'meaning': 19}, ('the', 'cross'): {'entropy': 435}, ('gradually', 'however'): {'the': 3}, ('prediction', 'however'): {'the': 2}, ('structure', 'automatically'): {'in': 2, 'the': 5, 'for': 1, 'a': 1}, ('network', 'statistically'): {'adjusts': 1, 'optimizes': 1, 'overfits': 1, 'maximizes': 1}, ('errors', 'however'): {'the': 1}, ('process', 'significantly'): {'models': 1, 'increases': 1, 'minimizes': 1, 'samples': 1, 'processes': 1}, ('loss', 'statistically'): {'a': 2, 'perplexity': 1, 'overfitting': 1, 'the': 3, 'meanwhile': 1, 'additionally': 1, 'specifically': 1}, ('to', 'dense'): {'vector': 88}, ('prediction', 'nevertheless'): {'the': 2}, ('information', 'for'): {'example': 1}, ('tokenizer', 'rapidly'): {'predicts': 1, 'overfits': 1, 'samples': 1, 'reduces': 1, 'outputs': 1, 'learns': 1, 'computes': 1, 'calculates': 1, 'improves': 1}, ('errors', 'nevertheless'): {'backpropagation': 1}, ('cleaning', 'and'): {'normalizing': 98}, ('value', 'word'): {'embeddings': 4}, ('matrix', 'automatically'): {'the': 6, 'specifically': 1, 'as': 1, 'consequently': 1, 'meanwhile': 1, 'a': 2, 'regularization': 1}, ('n-gram', 'probabilistically'): {'reduces': 1, 'improves': 1}, ('data', 'rather'): {'than': 104}, ('statistically', 'evaluates'): {'syntactic': 1, 'the': 3, 'semantic': 1, 'co-occurrence': 1}, ('structure', 'transfer'): {'learning': 1}, ('updates', 'semantic'): {'meaning': 14}, ('text', 'predicts'): {'word': 3, 'sentence': 1, 'the': 14, 'statistical': 1, 'language': 1, 'token': 1}, ('automatically', 'represents'): {'the': 3, 'word': 1, 'semantic': 1, 'syntactic': 1}, ('outputs', 'linguistic'): {'features': 7}, ('probabilistically', 'data'): {'preprocessing': 1}, ('data', 'in'): {'addition': 3, 'contrast': 1}, ('word', 'nevertheless'): {'the': 2}, ('metric', 'increases'): {'word': 1, 'the': 3}, ('data', 'rapidly'): {'the': 6, 'a': 3, 'moreover': 2, 'backpropagation': 1, 'consequently': 1, 'additionally': 1, 'overfitting': 1, 'perplexity': 1}, ('system', 'learns'): {'from': 7}, ('system', 'generates'): {'large': 1, 'the': 1, 'sentence': 1, 'millions': 1, 'semantic': 1}, ('matrix', 'transfer'): {'learning': 2}, ('dataset', 'outputs'): {'word': 1, 'linguistic': 1, 'the': 3}, ('resources', 'the'): {'prediction': 6, 'researcher': 5, 'gradient': 2, 'vocabulary': 2, 'corpus': 2, 'algorithm': 1, 'trigram': 4, 'optimizer': 2, 'context': 3, 'probability': 5, 'perplexity': 2, 'system': 4, 'model': 1, 'n-gram': 3, 'dataset': 2, 'weight': 2, 'tokenizer': 2, 'input': 1, 'output': 1, 'bigram': 2, 'attention': 2, 'training': 1, 'text': 1, 'evaluation': 1, 'architecture': 1}, ('optimizer', 'predicts'): {'linguistic': 4, 'co-occurrence': 1, 'the': 8, 'token': 1, 'millions': 1, 'semantic': 1, 'language': 1}, ('modeling', 'backpropagation'): {'represents': 1}, ('the', 'probability'): {'distribution': 374, 'sequentially': 8, 'rapidly': 9, 'increases': 18, 'reduces': 9, 'adjusts': 5, 'computes': 9, 'automatically': 10, 'evaluates': 11, 'significantly': 5, 'samples': 7, 'accurately': 5, 'minimizes': 10, 'captures': 10, 'fine-tunes': 9, 'optimizes': 11, 'models': 10, 'predicts': 14, 'effectively': 3, 'represents': 8, 'successfully': 15, 'gradually': 5, 'outputs': 9, 'diverges': 12, 'learns': 9, 'updates': 12, 'processes': 11, 'trains': 6, 'generates': 8, 'converges': 6, 'encodes': 8, 'overfits': 8, 'calculates': 8, 'maximizes': 6, 'statistically': 5, 'improves': 10, 'continuously': 5, 'tokenizes': 11, 'recursively': 6, 'decodes': 11, 'iteratively': 5, 'generalizes': 7, 'probabilistically': 4, 'efficiently': 8, 'correctly': 4}, ('tokenizer', 'statistically'): {'samples': 1, 'models': 1, 'outputs': 1, 'reduces': 1, 'increases': 1, 'decodes': 1, 'predicts': 1, 'converges': 1, 'learns': 1}, ('significantly', 'nevertheless'): {'the': 4}, ('recursively', 'consequently'): {'the': 3}, ('distribution', 'therefore'): {'the': 3}, ('generates', 'statistical'): {'patterns': 13}, ('metric', 'optimizes'): {'word': 3, 'co-occurrence': 1, 'the': 5, 'millions': 1, 'sentence': 1, 'linguistic': 1, 'statistical': 1}, ('metric', 'iteratively'): {'reduces': 1, 'samples': 1, 'maximizes': 1, 'diverges': 1, 'represents': 1}, ('word', 'significantly'): {'a': 4, 'the': 5, 'smoothing': 1, 'specifically': 1}, ('frequencies', 'continuously'): {'the': 6, 'for': 1, 'specifically': 1, 'a': 1}, ('data', 'however'): {'the': 3}, ('sequences', 'training'): {'a': 2}, ('information', 'gradient'): {'descent': 2}, ('descent', 'regularization'): {'techniques': 1}, ('output', 'overfitting'): {'occurs': 2}, ('iteratively', 'consequently'): {'the': 6}, ('successfully', 'captures'): {'the': 2, 'semantic': 1, 'language': 1, 'sentence': 2, 'statistical': 1}, ('encodes', 'syntactic'): {'rules': 7}, ('evaluates', 'sentence'): {'structure': 12}, ('converges', 'word'): {'frequencies': 8, 'embeddings': 16}, ('automatically', 'a'): {'fine-tuned': 4, 'accurate': 5, 'generative': 7, 'lightweight': 3, 'autoregressive': 2, 'robust': 7, 'efficient': 6, 'language': 4, 'bidirectional': 1, 'large': 1, 'small': 3, 'neural': 2, 'transformer-based': 2, 'deep': 3, 'shallow': 4, 'statistical': 1, 'discriminative': 2, 'scalable': 2, 'pre-trained': 1, 'recurrent': 1, 'powerful': 1}, ('matrices', 'training'): {'a': 5}, ('efficiently', 'samples'): {'the': 6}, ('structure', 'in'): {'contrast': 1, 'addition': 4}, ('parameters', 'consequently'): {'the': 2}, ('corpus', 'encodes'): {'the': 6, 'token': 1, 'co-occurrence': 1, 'semantic': 1}, ('matrices', 'therefore'): {'the': 1}, ('data', 'statistically'): {'the': 7, 'tokenization': 1, 'as': 1, 'however': 1, 'cleaning': 1}, ('architecture', 'encodes'): {'word': 2, 'the': 2, 'token': 2}, ('structure', 'rapidly'): {'a': 5, 'the': 10, 'backpropagation': 1, 'tokenization': 2, 'in': 1, 'subsequently': 1}, ('accurately', 'encodes'): {'linguistic': 1, 'large': 1, 'the': 2}, ('fine-tunes', 'co-occurrence'): {'matrices': 7}, ('diverges', 'word'): {'embeddings': 12, 'frequencies': 13}, ('descent', 'successfully'): {'therefore': 1, 'a': 2, 'as': 1, 'the': 6, 'furthermore': 1, 'backpropagation': 1, 'for': 1}, ('efficiently', 'the'): {'training': 9, 'sequence': 9, 'text': 6, 'gradient': 8, 'language': 10, 'neural': 6, 'weight': 7, 'perplexity': 7, 'system': 13, 'vocabulary': 10, 'softmax': 6, 'embedding': 8, 'dataset': 8, 'algorithm': 7, 'probability': 9, 'researcher': 10, 'evaluation': 7, 'prediction': 8, 'attention': 6, 'frequency': 4, 'bigram': 7, 'model': 5, 'trigram': 7, 'loss': 6, 'n-gram': 6, 'input': 3, 'optimizer': 8, 'context': 7, 'output': 2, 'architecture': 4, 'tokenizer': 6, 'corpus': 2}, ('adjusts', 'sentence'): {'structure': 12}, ('output', 'smoothing'): {'techniques': 1}, ('perplexity', 'predicts'): {'the': 7, 'millions': 3, 'semantic': 1, 'co-occurrence': 1, 'word': 1, 'statistical': 2, 'linguistic': 1, 'syntactic': 1}, ('output', 'maximizes'): {'the': 5, 'co-occurrence': 3, 'millions': 3}, ('gradually', 'moreover'): {'the': 7, 'backpropagation': 1}, ('models', 'millions'): {'of': 11}, ('vocabulary', 'learns'): {'from': 14}, ('matrix', 'in'): {'contrast': 3, 'addition': 3}, ('vocabulary', 'generates'): {'contextual': 4, 'the': 1, 'large': 1, 'sentence': 1, 'semantic': 1, 'word': 1}, ('system', 'accurately'): {'represents': 1, 'samples': 1, 'generates': 2, 'models': 1, 'overfits': 1, 'converges': 1, 'outputs': 1}, ('forms', 'the'): {'foundation': 110}, ('output', 'continuously'): {'the': 8, 'a': 3, 'furthermore': 1, 'similarly': 1, 'training': 1, 'decodes': 1, 'represents': 1}, ('features', 'correctly'): {'as': 1, 'the': 4, 'specifically': 1, 'a': 2, 'regularization': 1, 'nevertheless': 1}, ('architecture', 'minimizes'): {'the': 3, 'co-occurrence': 1}, ('matrix', 'rapidly'): {'the': 6, 'nevertheless': 1, 'furthermore': 1, 'a': 1}, ('accurately', 'minimizes'): {'the': 5, 'word': 1, 'sentence': 1}, ('the', 'batch'): {'size': 401}, ('of', 'parameters'): {'the': 90, 'efficiently': 19, 'a': 51, 'continuously': 11, 'effectively': 12, 'probabilistically': 16, 'furthermore': 6, 'similarly': 3, 'feeding': 1, 'gradually': 12, 'significantly': 18, 'correctly': 18, 'sequentially': 15, 'specifically': 6, 'therefore': 2, 'backpropagation': 3, 'subsequently': 3, 'moreover': 4, 'successfully': 17, 'iteratively': 13, 'word': 2, 'statistically': 13, 'as': 3, 'rapidly': 12, 'accurately': 11, 'training': 3, 'nevertheless': 5, 'automatically': 9, 'perplexity': 3, 'smoothing': 3, 'however': 3, 'transfer': 2, 'recursively': 12, 'cross': 2, 'consequently': 2, 'in': 6, 'overfitting': 2, 'cleaning': 3, 'regularization': 1, 'for': 1, 'additionally': 1, 'meanwhile': 1, 'gradient': 1}, ('n-gram', 'represents'): {'the': 6, 'word': 1, 'semantic': 2, 'sentence': 1, 'statistical': 2, 'millions': 1}, ('vocabulary', 'size'): {'directly': 108, 'correctly': 19, 'automatically': 8, 'the': 77, 'statistically': 17, 'a': 33, 'rapidly': 18, 'efficiently': 12, 'successfully': 22, 'gradually': 11, 'recursively': 13, 'feeding': 6, 'meanwhile': 2, 'in': 9, 'nevertheless': 1, 'backpropagation': 2, 'for': 3, 'word': 1, 'probabilistically': 11, 'effectively': 12, 'transfer': 3, 'cross': 5, 'accurately': 9, 'continuously': 12, 'additionally': 4, 'moreover': 2, 'therefore': 3, 'iteratively': 12, 'as': 1, 'specifically': 3, 'sequentially': 12, 'furthermore': 5, 'significantly': 5, 'gradient': 2, 'however': 4, 'bigram': 1, 'subsequently': 5, 'training': 1, 'consequently': 3, 'perplexity': 1, 'similarly': 1, 'smoothing': 1, 'tokenization': 1}, ('structure', 'however'): {'the': 4}, ('samples', 'the'): {'bias': 22, 'learning': 16, 'gradient': 15, 'vocabulary': 14, 'batch': 12, 'cross': 14, 'loss': 15, 'activation': 16, 'softmax': 7, 'weight': 16, 'corpus': 13, 'next': 10, 'hidden': 10, 'training': 8, 'probability': 5}, ('efficiently', 'improves'): {'the': 3, 'contextual': 1, 'linguistic': 1}, ('weight', 'recursively'): {'converges': 1, 'generalizes': 1, 'generates': 1, 'trains': 1, 'reduces': 1}, ('based', 'on'): {'prediction': 104, 'learned': 93}, ('efficiently', 'overfits'): {'the': 4, 'statistical': 1, 'semantic': 2, 'token': 1}, ('statistically', 'bigram'): {'and': 1}, ('rules', 'furthermore'): {'the': 5}, ('gracefully', 'moreover'): {'the': 5}, ('optimizes', 'linguistic'): {'features': 12}, ('gradient', 'correctly'): {'computes': 1, 'overfits': 1, 'generates': 1, 'trains': 1}, ('recursively', 'subsequently'): {'the': 3}, ('probability', 'tokenizes'): {'the': 7, 'large': 2, 'token': 1, 'sentence': 1}, ('learning', 'allows'): {'pre-trained': 104}, ('unseen', 'word'): {'combinations': 88}, ('correctly', 'processes'): {'word': 1, 'co-occurrence': 1, 'the': 4, 'millions': 1, 'large': 1}, ('statistically', 'optimizes'): {'contextual': 1, 'language': 1, 'the': 1}, ('model', 'correctly'): {'processes': 1, 'trains': 1, 'increases': 1, 'updates': 2, 'minimizes': 1, 'computes': 2, 'represents': 2, 'decodes': 1, 'generates': 1, 'improves': 1, 'generalizes': 1}, ('matrix', 'however'): {'the': 3}, ('rapidly', 'tokenizes'): {'the': 2, 'token': 1}, ('significantly', 'trains'): {'on': 4}, ('structure', 'statistically'): {'a': 6, 'the': 5, 'moreover': 1, 'regularization': 1, 'training': 1, 'subsequently': 1, 'perplexity': 1, 'gradient': 1}, ('rapidly', 'therefore'): {'the': 7}, ('bigram', 'decodes'): {'language': 1, 'the': 7, 'syntactic': 2, 'word': 2}, ('captures', 'sentence'): {'structure': 14}, ('terms', 'bigram'): {'and': 3}, ('size', 'iteratively'): {'for': 1, 'a': 7, 'the': 14, 'regularization': 1, 'smoothing': 1, 'data': 1, 'in': 2, 'nevertheless': 1, 'similarly': 1, 'additionally': 1}, ('probability', 'learns'): {'from': 9}, ('addition', 'backpropagation'): {'increases': 1, 'learns': 1, 'generates': 1, 'predicts': 1}, ('probability', 'generates'): {'syntactic': 1, 'language': 1, 'millions': 1, 'the': 4, 'word': 1}, ('accurately', 'overfitting'): {'occurs': 7}, ('rules', 'effectively'): {'the': 5, 'moreover': 1, 'nevertheless': 1, 'feeding': 1, 'cleaning': 2, 'a': 1, 'for': 1, 'tokenization': 1}, ('recursively', 'fine-tunes'): {'the': 4, 'syntactic': 1}, ('input', 'evaluates'): {'the': 4, 'large': 1}, ('information', 'accurately'): {'training': 1, 'the': 5, 'a': 4, 'perplexity': 1, 'transfer': 1, 'in': 1}, ('model', 'represents'): {'the': 8, 'large': 2, 'word': 2, 'statistical': 1, 'token': 1, 'contextual': 1, 'syntactic': 1}, ('matrix', 'statistically'): {'a': 6, 'therefore': 1, 'tokenization': 1, 'subsequently': 2, 'in': 1, 'the': 2, 'cleaning': 1, 'consequently': 1}, ('updates', 'the'): {'training': 15, 'next': 15, 'corpus': 19, 'batch': 7, 'probability': 12, 'activation': 9, 'loss': 9, 'weight': 15, 'cross': 12, 'hidden': 8, 'softmax': 14, 'bias': 17, 'vocabulary': 12, 'learning': 13, 'gradient': 13}, ('iteratively', 'specifically'): {'the': 6}, ('terms', 'iteratively'): {'the': 7, 'feeding': 1, 'for': 2, 'overfitting': 1, 'furthermore': 1, 'transfer': 1, 'cleaning': 1, 'perplexity': 1, 'similarly': 1}, ('corpus', 'computes'): {'the': 6, 'contextual': 1}, ('architecture', 'computes'): {'token': 1, 'the': 4, 'word': 1}, ('vocabulary', 'accurately'): {'converges': 2, 'fine-tunes': 1, 'calculates': 1, 'learns': 2}, ('automatically', 'similarly'): {'the': 6}, ('natural', 'language'): {'text': 104}, ('bigram', 'trains'): {'on': 9}, ('example', 'the'): {'input': 8, 'output': 5, 'attention': 6, 'evaluation': 6, 'corpus': 7, 'system': 6, 'prediction': 3, 'probability': 10, 'optimizer': 7, 'language': 9, 'n-gram': 7, 'context': 10, 'text': 8, 'training': 6, 'architecture': 1, 'loss': 6, 'bigram': 5, 'vocabulary': 5, 'sequence': 8, 'trigram': 9, 'gradient': 6, 'algorithm': 3, 'researcher': 4, 'neural': 6, 'tokenizer': 6, 'weight': 9, 'dataset': 6, 'embedding': 7, 'perplexity': 2, 'model': 2}, ('backpropagation', 'decodes'): {'millions': 3, 'statistical': 2, 'token': 1, 'co-occurrence': 2, 'the': 4, 'large': 1}, ('parameters', 'specifically'): {'the': 6}, ('statistically', 'perplexity'): {'measures': 4}, ('diverges', 'linguistic'): {'features': 11}, ('accurately', 'smoothing'): {'techniques': 2}, ('accurately', 'maximizes'): {'the': 4}, ('distribution', 'data'): {'preprocessing': 2}, ('data', 'moreover'): {'the': 5}, ('rate', 'training'): {'a': 3}, ('dataset', 'adjusts'): {'contextual': 1, 'the': 5, 'millions': 2, 'large': 1, 'statistical': 1, 'sentence': 1, 'word': 1}, ('rate', 'therefore'): {'the': 3}, ('sequentially', 'reduces'): {'contextual': 2, 'the': 2, 'word': 2, 'linguistic': 1, 'sentence': 1, 'syntactic': 1, 'millions': 1}, ('bigram', 'models'): {'word': 1, 'the': 3, 'semantic': 2}, ('regularization', 'techniques'): {'prevent': 92}, ('terms', 'perplexity'): {'measures': 2}, ('on', 'learned'): {'patterns': 93}, ('pipeline', 'a'): {'bidirectional': 1, 'fine-tuned': 2, 'recurrent': 2, 'generative': 3, 'neural': 1, 'shallow': 2, 'discriminative': 1, 'efficient': 3, 'scalable': 1, 'accurate': 1, 'statistical': 1}, ('sequentially', 'training'): {'a': 2}, ('text', 'processes'): {'semantic': 1, 'sentence': 1, 'word': 1, 'language': 1, 'the': 2, 'contextual': 1, 'co-occurrence': 1}, ('mechanism', 'computes'): {'the': 7, 'contextual': 1}, ('features', 'backpropagation'): {'updates': 1, 'generates': 1}, ('parameters', 'sequentially'): {'meanwhile': 1, 'a': 5, 'the': 7, 'regularization': 1, 'backpropagation': 1}, ('probability', 'accurately'): {'models': 1, 'fine-tunes': 1, 'computes': 1, 'generates': 1, 'encodes': 1}, ('successfully', 'generalizes'): {'the': 4, 'co-occurrence': 1}, ('matrices', 'data'): {'preprocessing': 2}, ('evaluates', 'language'): {'patterns': 7}, ('corpus', 'regularization'): {'techniques': 2}, ('model', 'a'): {'shallow': 6, 'fine-tuned': 8, 'deep': 4, 'efficient': 5, 'statistical': 4, 'lightweight': 4, 'small': 5, 'discriminative': 4, 'robust': 4, 'pre-trained': 4, 'autoregressive': 3, 'recurrent': 3, 'accurate': 4, 'transformer-based': 2, 'powerful': 4, 'scalable': 1, 'large': 5, 'neural': 2, 'generative': 2}, ('powerful', 'the'): {'n-gram': 5, 'trigram': 5, 'perplexity': 4, 'attention': 6, 'language': 8, 'researcher': 5, 'algorithm': 4, 'embedding': 7, 'loss': 8, 'tokenizer': 7, 'evaluation': 4, 'architecture': 3, 'prediction': 5, 'text': 4, 'output': 5, 'input': 3, 'weight': 2, 'vocabulary': 3, 'gradient': 2, 'optimizer': 4, 'probability': 2, 'system': 2, 'neural': 5, 'context': 3, 'training': 4, 'dataset': 6, 'corpus': 3}, ('correctly', 'nevertheless'): {'the': 4}, ('function', 'consequently'): {'the': 4}, ('significantly', 'word'): {'embeddings': 5}, ('perplexity', 'automatically'): {'reduces': 1, 'updates': 2, 'processes': 1}, ('statistically', 'cleaning'): {'and': 3}, ('optimizer', 'processes'): {'word': 1, 'the': 6, 'co-occurrence': 1, 'statistical': 1, 'language': 1, 'token': 1}, ('n-gram', 'gradually'): {'processes': 2, 'trains': 1, 'improves': 1, 'models': 1, 'encodes': 1, 'adjusts': 1}, ('a', 'lightweight'): {'the': 144, 'backpropagation': 7}, ('size', 'cleaning'): {'and': 1}, ('structure', 'moreover'): {'the': 1}, ('on', 'large'): {'amounts': 13}, ('sequence', 'reduces'): {'linguistic': 1, 'the': 3, 'language': 1, 'semantic': 1, 'sentence': 1, 'word': 1}, ('dataset', 'fine-tunes'): {'the': 5, 'language': 1}, ('corpus', 'successfully'): {'represents': 1, 'adjusts': 2, 'for': 1, 'the': 9, 'diverges': 1, 'as': 1, 'trains': 1, 'optimizes': 1, 'tokenizes': 1, 'a': 1, 'captures': 2, 'updates': 1, 'maximizes': 1, 'specifically': 1}, ('automatically', 'calculates'): {'language': 1, 'millions': 1, 'sentence': 1, 'the': 1, 'large': 1, 'syntactic': 1}, ('architecture', 'successfully'): {'calculates': 1, 'minimizes': 1, 'overfits': 1, 'tokenizes': 1, 'diverges': 1, 'learns': 1, 'optimizes': 1}, ('sequence', 'tokenizes'): {'statistical': 1, 'the': 10}, ('assigning', 'low'): {'probability': 111}, ('outputs', 'semantic'): {'meaning': 4}, ('descent', 'correctly'): {'meanwhile': 1, 'a': 3, 'the': 3, 'tokenization': 1, 'feeding': 1, 'therefore': 1}, ('terms', 'cleaning'): {'and': 4}, ('efficiently', 'meanwhile'): {'the': 4}, ('matrix', 'moreover'): {'backpropagation': 1, 'the': 1}, ('trigram', 'sequentially'): {'represents': 1, 'maximizes': 1, 'computes': 1, 'converges': 1, 'outputs': 1, 'improves': 1}, ('backpropagation', 'sequentially'): {'processes': 1, 'encodes': 1, 'generalizes': 1, 'optimizes': 1}, ('from', 'sentence'): {'structure': 13}, ('statistically', 'outputs'): {'the': 3, 'word': 1}, ('rapidly', 'data'): {'preprocessing': 6}, ('dataset', 'efficiently'): {'represents': 1, 'updates': 1, 'overfits': 1, 'encodes': 1, 'processes': 1}, ('matrices', 'furthermore'): {'the': 4}, ('distribution', 'probabilistically'): {'the': 3, 'a': 3, 'therefore': 1, 'regularization': 1, 'subsequently': 1, 'in': 1, 'as': 1}, ('the', 'gradient'): {'descent': 396, 'significantly': 5, 'predicts': 14, 'optimizes': 13, 'minimizes': 13, 'trains': 11, 'successfully': 9, 'rapidly': 5, 'efficiently': 7, 'recursively': 6, 'evaluates': 8, 'computes': 10, 'increases': 8, 'captures': 9, 'correctly': 4, 'overfits': 13, 'adjusts': 9, 'represents': 4, 'improves': 14, 'models': 9, 'calculates': 5, 'generates': 19, 'samples': 7, 'decodes': 8, 'outputs': 11, 'tokenizes': 11, 'probabilistically': 7, 'statistically': 8, 'reduces': 16, 'diverges': 6, 'learns': 10, 'iteratively': 8, 'fine-tunes': 9, 'automatically': 5, 'encodes': 13, 'maximizes': 6, 'gradually': 4, 'processes': 12, 'updates': 7, 'converges': 6, 'sequentially': 4, 'generalizes': 4, 'accurately': 4, 'continuously': 5, 'effectively': 5}, ('input', 'optimizes'): {'the': 3, 'linguistic': 1, 'syntactic': 1}, ('perplexity', 'processes'): {'the': 8, 'word': 1, 'co-occurrence': 3, 'linguistic': 1, 'semantic': 3}, ('input', 'iteratively'): {'fine-tunes': 1, 'computes': 1, 'converges': 1}, ('sequences', 'effectively'): {'gradient': 1, 'regularization': 1, 'consequently': 1, 'similarly': 1, 'a': 1, 'the': 4, 'additionally': 1}, ('algorithm', 'captures'): {'contextual': 2, 'the': 4, 'sentence': 1, 'word': 1, 'millions': 1}, ('mechanism', 'successfully'): {'tokenizes': 1, 'increases': 1, 'processes': 1, 'predicts': 1, 'models': 1}, ('successfully', 'samples'): {'semantic': 1, 'sentence': 1, 'large': 1, 'the': 2, 'contextual': 1, 'linguistic': 1, 'statistical': 1}, ('pipeline', 'similarly'): {'the': 1}, ('improves', 'large'): {'amounts': 14}, ('reduces', 'sentence'): {'structure': 10}, ('text', 'nevertheless'): {'the': 7}, ('continuously', 'generalizes'): {'syntactic': 1, 'token': 1, 'the': 2, 'statistical': 1}, ('successfully', 'the'): {'optimizer': 6, 'n-gram': 3, 'text': 8, 'training': 10, 'algorithm': 3, 'corpus': 7, 'loss': 9, 'architecture': 6, 'sequence': 2, 'gradient': 6, 'attention': 6, 'language': 8, 'evaluation': 5, 'probability': 3, 'perplexity': 6, 'model': 7, 'softmax': 4, 'researcher': 3, 'input': 2, 'weight': 8, 'context': 8, 'vocabulary': 11, 'embedding': 6, 'trigram': 7, 'system': 6, 'neural': 3, 'bigram': 5, 'frequency': 3, 'prediction': 2, 'tokenizer': 3, 'dataset': 3, 'output': 1}, ('matrices', 'effectively'): {'the': 3, 'cross': 1, 'therefore': 1, 'for': 1, 'backpropagation': 1, 'additionally': 1, 'smoothing': 1, 'a': 2}, ('size', 'additionally'): {'the': 4}, ('decodes', 'sentence'): {'structure': 17}, ('vocabulary', 'probabilistically'): {'models': 1, 'generalizes': 1, 'evaluates': 1, 'learns': 1, 'updates': 1}, ('computes', 'co-occurrence'): {'matrices': 11}, ('efficiently', 'increases'): {'word': 2, 'the': 1}, ('converges', 'co-occurrence'): {'matrices': 13}, ('function', 'specifically'): {'the': 3}, ('output', 'converges'): {'language': 1, 'sentence': 1, 'the': 4, 'word': 1, 'syntactic': 1}, ('corpus', 'updates'): {'word': 1, 'co-occurrence': 1, 'sentence': 1, 'the': 3}, ('statistically', 'cross'): {'entropy': 2}, ('architecture', 'updates'): {'semantic': 1, 'the': 3, 'statistical': 1}, ('iteratively', 'encodes'): {'the': 1, 'contextual': 1}, ('maximizes', 'large'): {'amounts': 12}, ('accurately', 'updates'): {'co-occurrence': 1, 'the': 2, 'contextual': 1, 'sentence': 1}, ('rate', 'data'): {'preprocessing': 2}, ('network', 'reduces'): {'semantic': 1, 'the': 7, 'millions': 1, 'token': 1, 'contextual': 1}, ('text', 'significantly'): {'the': 8, 'word': 1, 'tokenizes': 2, 'updates': 1, 'in': 1, 'processes': 1, 'a': 2}, ('size', 'cross'): {'entropy': 6}, ('word', 'co-occurrences'): {'forms': 110}, ('rapidly', 'furthermore'): {'the': 3}, ('successfully', 'improves'): {'token': 1, 'large': 1, 'linguistic': 1, 'the': 4}, ('successfully', 'overfits'): {'language': 1, 'the': 6, 'millions': 2, 'large': 1, 'contextual': 1}, ('effectively', 'represents'): {'the': 3, 'semantic': 1}, ('features', 'recursively'): {'backpropagation': 1, 'the': 7, 'regularization': 2, 'a': 2}, ('n-gram', 'calculates'): {'the': 5, 'statistical': 1}, ('tokenizes', 'sentence'): {'structure': 13}, ('terms', 'cross'): {'entropy': 3}, ('adjusts', 'millions'): {'of': 17}, ('gradually', 'reduces'): {'word': 1, 'the': 1, 'millions': 1, 'contextual': 1}, ('optimizer', 'significantly'): {'generates': 1, 'updates': 1, 'represents': 1, 'optimizes': 1}, ('efficiently', 'transfer'): {'learning': 3}, ('gradually', 'training'): {'a': 5}, ('represents', 'syntactic'): {'rules': 18}, ('probability', 'probabilistically'): {'tokenizes': 1, 'adjusts': 1, 'converges': 1, 'fine-tunes': 1}, ('function', 'sequentially'): {'the': 5, 'consequently': 1, 'a': 3, 'generalizes': 2, 'subsequently': 2, 'smoothing': 1, 'represents': 1, 'diverges': 1, 'similarly': 1, 'for': 1, 'in': 2, 'tokenization': 1, 'evaluates': 1, 'encodes': 1}, ('researcher', 'tokenizes'): {'the': 3, 'contextual': 1, 'token': 1, 'statistical': 2, 'millions': 1}, ('gradient', 'recursively'): {'evaluates': 1, 'processes': 1, 'generalizes': 1, 'tokenizes': 1, 'fine-tunes': 1, 'minimizes': 1}, ('system', 'represents'): {'the': 6, 'linguistic': 3, 'contextual': 2, 'millions': 1}, ('architecture', 'diverges'): {'the': 6, 'word': 1}, ('accurately', 'diverges'): {'the': 3, 'co-occurrence': 1, 'millions': 1}, ('minimizes', 'millions'): {'of': 9}, ('descent', 'backpropagation'): {'efficiently': 1, 'decodes': 1, 'samples': 2}, ('process', 'captures'): {'the': 7, 'contextual': 1, 'semantic': 1}, ('model', 'recursively'): {'processes': 1, 'predicts': 1, 'encodes': 1, 'fine-tunes': 1, 'evaluates': 1, 'updates': 1, 'computes': 1, 'maximizes': 1}, ('rules', 'meanwhile'): {'the': 4}, ('continuously', 'samples'): {'the': 4, 'word': 1, 'sentence': 1}, ('rate', 'furthermore'): {'the': 2}, ('recursively', 'computes'): {'the': 2, 'syntactic': 1}, ('outputs', 'contextual'): {'information': 12}, ('gracefully', 'therefore'): {'the': 1}, ('trigram', 'encodes'): {'the': 3, 'word': 3, 'language': 1}, ('adapted', 'to'): {'new': 104}, ('probabilistically', 'bigram'): {'and': 2}, ('backpropagation', 'encodes'): {'the': 3, 'word': 1}, ('continuously', 'the'): {'algorithm': 3, 'gradient': 4, 'vocabulary': 7, 'system': 6, 'input': 4, 'training': 5, 'language': 7, 'model': 4, 'researcher': 2, 'architecture': 8, 'perplexity': 3, 'embedding': 3, 'tokenizer': 4, 'probability': 4, 'bigram': 6, 'text': 4, 'context': 11, 'attention': 3, 'loss': 2, 'trigram': 4, 'frequency': 3, 'prediction': 5, 'evaluation': 6, 'n-gram': 4, 'softmax': 4, 'optimizer': 7, 'output': 4, 'corpus': 4, 'dataset': 6, 'neural': 6, 'sequence': 2, 'weight': 3}, ('tokenizer', 'reduces'): {'the': 2, 'co-occurrence': 1, 'word': 1, 'millions': 1, 'large': 1}, ('text', 'trains'): {'on': 8}, ('fine-tunes', 'millions'): {'of': 11}, ('effectively', 'a'): {'generative': 5, 'shallow': 5, 'efficient': 8, 'autoregressive': 3, 'lightweight': 5, 'recurrent': 6, 'neural': 4, 'small': 3, 'accurate': 6, 'deep': 2, 'statistical': 3, 'scalable': 4, 'pre-trained': 3, 'large': 1, 'discriminative': 2, 'robust': 2, 'transformer-based': 2, 'powerful': 3, 'fine-tuned': 2}, ('converges', 'semantic'): {'meaning': 13}, ('captures', 'millions'): {'of': 12}, ('tokenizer', 'tokenizes'): {'the': 7, 'linguistic': 1, 'syntactic': 1, 'co-occurrence': 1, 'semantic': 1}, ('sequentially', 'furthermore'): {'the': 1}, ('processes', 'co-occurrence'): {'matrices': 13}, ('resources', 'however'): {'the': 1}, ('correctly', 'word'): {'embeddings': 4}, ('iteratively', 'computes'): {'contextual': 1, 'the': 2, 'language': 1}, ('trigram', 'minimizes'): {'the': 4, 'language': 1}, ('as', 'a'): {'result': 194}, ('diverges', 'semantic'): {'meaning': 14}, ('backpropagation', 'minimizes'): {'the': 3, 'sentence': 1, 'word': 1, 'co-occurrence': 1, 'syntactic': 1, 'large': 1, 'semantic': 1}, ('corpus', 'correctly'): {'increases': 1, 'the': 3, 'a': 3, 'calculates': 1, 'furthermore': 1, 'generalizes': 2, 'trains': 1, 'processes': 1, 'therefore': 1, 'represents': 1}, ('foundation', 'of'): {'statistical': 110}, ('efficiently', 'in'): {'addition': 11, 'contrast': 5}, ('continuously', 'improves'): {'sentence': 1, 'word': 1, 'the': 1}, ('continuously', 'overfits'): {'word': 2, 'syntactic': 1}, ('statistically', 'adjusts'): {'the': 5, 'millions': 1, 'word': 1, 'linguistic': 1}, ('text', 'models'): {'linguistic': 2, 'the': 4, 'millions': 1, 'sentence': 1, 'word': 2}, ('dataset', 'learns'): {'from': 13}, ('vocabulary', 'represents'): {'the': 5, 'statistical': 1}, ('predicts', 'word'): {'embeddings': 22, 'frequencies': 32}, ('input', 'outputs'): {'the': 4, 'linguistic': 1, 'contextual': 1}, ('metric', 'efficiently'): {'computes': 1, 'trains': 2, 'outputs': 1, 'calculates': 1, 'learns': 1, 'overfits': 1, 'represents': 1, 'predicts': 1, 'decodes': 1}, ('dataset', 'generates'): {'the': 6, 'syntactic': 1, 'word': 1}, ('large', 'the'): {'optimizer': 7, 'n-gram': 4, 'algorithm': 6, 'vocabulary': 7, 'weight': 7, 'output': 6, 'prediction': 6, 'bigram': 3, 'loss': 2, 'language': 2, 'sequence': 7, 'corpus': 4, 'tokenizer': 3, 'neural': 4, 'system': 3, 'embedding': 5, 'text': 5, 'dataset': 4, 'gradient': 3, 'training': 7, 'trigram': 3, 'researcher': 5, 'probability': 5, 'perplexity': 2, 'attention': 4, 'input': 2, 'architecture': 4, 'evaluation': 1, 'context': 1}, ('n-gram', 'outputs'): {'the': 6, 'contextual': 1, 'semantic': 1}, ('embeddings', 'the'): {'system': 2, 'perplexity': 5, 'text': 2, 'n-gram': 3, 'researcher': 3, 'context': 3, 'trigram': 4, 'training': 7, 'architecture': 1, 'vocabulary': 2, 'dataset': 3, 'neural': 2, 'tokenizer': 3, 'output': 3, 'model': 4, 'loss': 1, 'evaluation': 3, 'optimizer': 2, 'frequency': 1, 'input': 1, 'sequence': 3, 'embedding': 5, 'attention': 1, 'weight': 3, 'prediction': 5, 'gradient': 2, 'corpus': 2, 'probability': 2, 'language': 1, 'softmax': 2}, ('window', 'computes'): {'the': 6, 'sentence': 2, 'millions': 1, 'linguistic': 1}, ('automatically', 'consequently'): {'the': 10}, ('algorithm', 'generalizes'): {'the': 5, 'statistical': 1}, ('a', 'generative'): {'the': 150, 'backpropagation': 1}, ('data', 'training'): {'a': 2}, ('probabilistically', 'perplexity'): {'measures': 3}, ('data', 'therefore'): {'the': 2}, ('words', 'a'): {'accurate': 1, 'generative': 2, 'discriminative': 1, 'lightweight': 3, 'deep': 1, 'scalable': 2, 'bidirectional': 2, 'large': 1, 'pre-trained': 1, 'autoregressive': 2, 'shallow': 2, 'statistical': 1, 'recurrent': 1, 'neural': 2, 'efficient': 1}, ('ability', 'nevertheless'): {'the': 3}, ('rules', 'iteratively'): {'a': 1, 'the': 2, 'in': 1, 'feeding': 1, 'regularization': 1, 'additionally': 1}, ('bigram', 'maximizes'): {'the': 4, 'language': 2, 'token': 1, 'linguistic': 1, 'statistical': 1}, ('probabilistically', 'calculates'): {'the': 3, 'co-occurrence': 1, 'token': 1}, ('significantly', 'captures'): {'the': 3}, ('iteratively', 'regularization'): {'techniques': 7}, ('the', 'bias'): {'terms': 398}, ('value', 'the'): {'attention': 3, 'embedding': 3, 'vocabulary': 5, 'neural': 2, 'tokenizer': 1, 'gradient': 3, 'researcher': 2, 'training': 8, 'weight': 4, 'corpus': 3, 'bigram': 1, 'optimizer': 6, 'language': 3, 'context': 8, 'trigram': 3, 'loss': 4, 'architecture': 3, 'sequence': 1, 'prediction': 4, 'n-gram': 4, 'perplexity': 2, 'system': 2, 'text': 4, 'probability': 1, 'input': 2, 'algorithm': 2, 'evaluation': 1, 'model': 1, 'softmax': 2, 'output': 1}, ('weight', 'sequentially'): {'minimizes': 1, 'optimizes': 1, 'increases': 1, 'predicts': 1, 'samples': 1}, ('output', 'predicts'): {'millions': 2, 'the': 8, 'word': 1, 'contextual': 1, 'co-occurrence': 1, 'language': 1, 'linguistic': 1}, ('bigram', 'continuously'): {'captures': 1, 'outputs': 1, 'updates': 1, 'optimizes': 1, 'trains': 1, 'converges': 1, 'adjusts': 1, 'minimizes': 1}, ('mechanism', 'correctly'): {'captures': 1}, ('critical', 'step'): {'before': 99}, ('trigram', 'computes'): {'sentence': 2, 'the': 5, 'millions': 1, 'word': 1, 'linguistic': 1}, ('parameters', 'regularization'): {'techniques': 1}, ('layer', 'decodes'): {'the': 3, 'contextual': 1, 'language': 1, 'sentence': 1}, ('algorithm', 'converges'): {'the': 5, 'contextual': 1, 'word': 1, 'syntactic': 1, 'language': 1, 'sentence': 1}, ('word', 'embeddings'): {'rapidly': 13, 'map': 88, 'meanwhile': 3, 'continuously': 19, 'probabilistically': 18, 'the': 81, 'efficiently': 19, 'sequentially': 12, 'iteratively': 12, 'significantly': 13, 'moreover': 3, 'in': 6, 'a': 39, 'statistically': 11, 'perplexity': 1, 'effectively': 14, 'successfully': 15, 'correctly': 11, 'recursively': 16, 'automatically': 11, 'as': 4, 'subsequently': 7, 'tokenization': 3, 'specifically': 3, 'feeding': 5, 'additionally': 4, 'cleaning': 3, 'for': 3, 'gradually': 10, 'cross': 3, 'accurately': 9, 'consequently': 4, 'furthermore': 6, 'word': 1, 'regularization': 2, 'data': 1, 'gradient': 1, 'backpropagation': 1, 'therefore': 3, 'similarly': 5, 'however': 1, 'overfitting': 1, 'training': 3, 'smoothing': 2, 'bigram': 1}, ('information', 'a'): {'transformer-based': 4, 'robust': 2, 'large': 3, 'pre-trained': 2, 'efficient': 2, 'autoregressive': 1, 'discriminative': 2, 'bidirectional': 2, 'powerful': 1, 'small': 3, 'shallow': 3, 'scalable': 3, 'language': 5, 'deep': 2, 'lightweight': 3, 'fine-tuned': 1, 'neural': 1}, ('descent', 'feeding'): {'diverse': 1}, ('function', 'encodes'): {'syntactic': 1, 'the': 3, 'millions': 1, 'contextual': 1, 'word': 2}, ('patterns', 'nevertheless'): {'the': 7}, ('system', 'gradually'): {'captures': 1, 'overfits': 1, 'increases': 1}, ('sequence', 'effectively'): {'optimizes': 1, 'outputs': 1, 'converges': 1, 'trains': 1, 'increases': 1, 'predicts': 1}, ('backpropagation', 'maximizes'): {'the': 7, 'linguistic': 1}, ('text', 'word'): {'embeddings': 1}, ('optimizes', 'contextual'): {'information': 11}, ('backpropagation', 'continuously'): {'minimizes': 1, 'calculates': 1, 'generates': 1, 'fine-tunes': 1}, ('bigram', 'captures'): {'the': 4, 'large': 2, 'language': 1}, ('descent', 'recursively'): {'the': 5, 'furthermore': 1, 'cleaning': 1, 'subsequently': 1, 'a': 1, 'training': 1, 'backpropagation': 1}, ('dataset', 'accurately'): {'overfits': 1, 'computes': 1, 'minimizes': 2, 'evaluates': 1, 'predicts': 1, 'trains': 1, 'adjusts': 1}, ('tokenizes', 'language'): {'patterns': 14}, ('parameters', 'successfully'): {'a': 5, 'cross': 1, 'in': 1, 'the': 8, 'nevertheless': 1, 'bigram': 1}, ('structure', 'training'): {'a': 1}, ('layer', 'trains'): {'on': 5}, ('efficiently', 'additionally'): {'the': 3}, ('structure', 'therefore'): {'the': 2}, ('patterns', 'significantly'): {'the': 16, 'in': 2, 'specifically': 2, 'a': 2, 'cleaning': 1, 'as': 1, 'meanwhile': 2, 'perplexity': 1, 'subsequently': 1}, ('meaning', 'effectively'): {'additionally': 1, 'overfitting': 1, 'a': 1, 'regularization': 1, 'feeding': 1, 'data': 1}, ('sequences', 'meanwhile'): {'the': 2}, ('automatically', 'subsequently'): {'the': 4}, ('process', 'generalizes'): {'token': 1, 'the': 1}, ('window', 'successfully'): {'increases': 2, 'maximizes': 1, 'adjusts': 1, 'generates': 1, 'converges': 2}, ('algorithm', 'samples'): {'the': 3, 'language': 1, 'syntactic': 1}, ('outputs', 'token'): {'sequences': 5}, ('small', 'the'): {'corpus': 4, 'embedding': 7, 'perplexity': 3, 'sequence': 5, 'input': 9, 'neural': 6, 'gradient': 6, 'weight': 6, 'tokenizer': 7, 'context': 4, 'algorithm': 5, 'prediction': 3, 'loss': 5, 'dataset': 3, 'evaluation': 3, 'output': 4, 'optimizer': 4, 'language': 3, 'trigram': 1, 'training': 4, 'probability': 4, 'text': 6, 'attention': 2, 'bigram': 10, 'system': 3, 'architecture': 1, 'researcher': 3, 'vocabulary': 3, 'n-gram': 4}, ('size', 'efficiently'): {'the': 11, 'a': 2, 'bigram': 1, 'smoothing': 1, 'similarly': 1, 'specifically': 1, 'consequently': 1, 'subsequently': 1, 'in': 1, 'nevertheless': 1}, ('corpus', 'backpropagation'): {'statistically': 1}, ('matrix', 'therefore'): {'the': 4}, ('matrices', 'meanwhile'): {'backpropagation': 1, 'the': 2}, ('layer', 'models'): {'semantic': 2, 'word': 2, 'the': 5, 'statistical': 1, 'contextual': 1}, ('samples', 'statistical'): {'patterns': 7}, ('from', 'millions'): {'of': 11}, ('information', 'gradually'): {'a': 2, 'similarly': 1, 'the': 4, 'in': 1, 'however': 1, 'word': 1}, ('rapidly', 'evaluates'): {'the': 6, 'linguistic': 1, 'word': 1}, ('terms', 'efficiently'): {'the': 9, 'a': 2, 'furthermore': 1, 'however': 1}, ('automatically', 'fine-tunes'): {'millions': 1, 'co-occurrence': 1, 'sentence': 1, 'token': 1, 'linguistic': 1}, ('vocabulary', 'gradually'): {'predicts': 2, 'models': 1, 'generalizes': 1, 'samples': 1}, ('diverges', 'contextual'): {'information': 21}, ('converges', 'the'): {'cross': 14, 'next': 11, 'training': 14, 'bias': 16, 'softmax': 11, 'hidden': 13, 'activation': 11, 'loss': 15, 'probability': 12, 'learning': 8, 'batch': 6, 'corpus': 16, 'gradient': 15, 'weight': 12, 'vocabulary': 13}, ('accurately', 'predicts'): {'word': 1, 'the': 6, 'semantic': 2, 'linguistic': 1, 'syntactic': 1, 'statistical': 1, 'co-occurrence': 1, 'language': 1, 'sentence': 1, 'millions': 1}, ('probabilistically', 'outputs'): {'the': 1, 'large': 1, 'syntactic': 1}, ('statistically', 'as'): {'a': 7}, ('the', 'optimization'): {'algorithm': 94}, ('trigram', 'successfully'): {'predicts': 2, 'generates': 1, 'evaluates': 1, 'fine-tunes': 1}, ('gradually', 'furthermore'): {'the': 11}, ('distribution', 'bigram'): {'and': 1}, ('algorithm', 'improves'): {'the': 7, 'sentence': 2, 'statistical': 1, 'syntactic': 1}, ('algorithm', 'overfits'): {'the': 1}, ('statistically', 'for'): {'example': 3}, ('diverges', 'the'): {'probability': 18, 'learning': 14, 'softmax': 18, 'next': 15, 'corpus': 17, 'activation': 10, 'weight': 12, 'vocabulary': 14, 'gradient': 17, 'cross': 10, 'bias': 7, 'hidden': 14, 'loss': 10, 'batch': 7, 'training': 7}, ('function', 'computes'): {'co-occurrence': 2, 'word': 1, 'the': 3, 'millions': 1, 'language': 1}, ('iteratively', 'updates'): {'semantic': 1, 'statistical': 1, 'large': 1, 'language': 1, 'the': 2}, ('a', 'accurate'): {'the': 144, 'backpropagation': 6}, ('meaning', 'the'): {'dataset': 1, 'algorithm': 6, 'vocabulary': 8, 'training': 5, 'n-gram': 3, 'architecture': 5, 'input': 3, 'sequence': 6, 'loss': 3, 'embedding': 3, 'corpus': 3, 'prediction': 4, 'researcher': 3, 'gradient': 4, 'text': 1, 'perplexity': 4, 'bigram': 3, 'tokenizer': 5, 'optimizer': 3, 'context': 6, 'trigram': 3, 'evaluation': 2, 'softmax': 1, 'neural': 2, 'attention': 5, 'language': 1, 'frequency': 2, 'model': 1, 'probability': 1}, ('continuously', 'meanwhile'): {'the': 7, 'backpropagation': 1}, ('pipeline', 'consequently'): {'the': 1}, ('network', 'effectively'): {'adjusts': 1}, ('size', 'for'): {'example': 6}, ('loss', 'effectively'): {'a': 4, 'feeding': 1, 'the': 4, 'consequently': 2, 'similarly': 1, 'overfitting': 1}, ('information', 'similarly'): {'the': 3, 'backpropagation': 1}, ('successfully', 'transfer'): {'learning': 3}, ('input', 'adjusts'): {'the': 8, 'contextual': 1, 'linguistic': 1}, ('terms', 'as'): {'a': 3}, ('updates', 'statistical'): {'patterns': 12}, ('models', 'word'): {'frequencies': 12, 'embeddings': 13}, ('metric', 'learns'): {'from': 15}, ('model', 'consequently'): {'the': 8}, ('n-gram', 'adjusts'): {'the': 7, 'syntactic': 1, 'sentence': 1, 'statistical': 1}, ('metric', 'generates'): {'the': 5, 'contextual': 1, 'millions': 1, 'linguistic': 1}, ('efficiently', 'moreover'): {'the': 4, 'backpropagation': 1}, ('weight', 'encodes'): {'co-occurrence': 1, 'word': 2, 'statistical': 1, 'the': 5, 'large': 1, 'millions': 1}, ('units', 'for'): {'the': 82}, ('prediction', 'effectively'): {'converges': 1, 'reduces': 1, 'processes': 1, 'captures': 1, 'tokenizes': 1, 'learns': 1, 'predicts': 1}, ('increases', 'large'): {'amounts': 14}, ('probability', 'gradually'): {'converges': 2, 'tokenizes': 1, 'outputs': 1, 'decodes': 1}, ('sequences', 'iteratively'): {'meanwhile': 2, 'the': 3, 'subsequently': 1, 'a': 2, 'furthermore': 1, 'transfer': 1, 'nevertheless': 1}, ('process', 'samples'): {'the': 8, 'co-occurrence': 1, 'word': 1, 'semantic': 1}, ('researcher', 'probabilistically'): {'outputs': 1, 'encodes': 1, 'updates': 1, 'optimizes': 1, 'models': 1, 'improves': 1, 'predicts': 1}, ('weight', 'minimizes'): {'the': 6, 'linguistic': 1, 'large': 1, 'word': 2, 'language': 1}, ('states', 'significantly'): {'additionally': 1, 'the': 5, 'in': 1, 'therefore': 1, 'overfitting': 1}, ('network', 'samples'): {'the': 6, 'word': 1, 'linguistic': 1, 'sentence': 2, 'contextual': 1, 'millions': 1}, ('significantly', 'generalizes'): {'the': 3, 'statistical': 1, 'language': 1}, ('sequentially', 'evaluates'): {'sentence': 1, 'the': 5, 'semantic': 1, 'syntactic': 1}, ('sequences', 'transfer'): {'learning': 2}, ('statistically', 'tokenization'): {'is': 5}, ('matrices', 'iteratively'): {'the': 8, 'a': 3, 'similarly': 1, 'in': 1, 'for': 1, 'however': 1, 'tokenization': 1}, ('distribution', 'perplexity'): {'measures': 1}, ('function', 'regularization'): {'techniques': 4}, ('size', 'tokenization'): {'is': 4}, ('optimizes', 'token'): {'sequences': 12}, ('loss', 'the'): {'algorithm': 3, 'weight': 7, 'model': 5, 'neural': 7, 'dataset': 4, 'tokenizer': 4, 'training': 8, 'context': 5, 'input': 5, 'probability': 6, 'prediction': 6, 'attention': 5, 'system': 5, 'vocabulary': 7, 'gradient': 2, 'architecture': 2, 'perplexity': 8, 'output': 7, 'corpus': 6, 'bigram': 3, 'optimizer': 3, 'n-gram': 3, 'researcher': 6, 'sequence': 7, 'embedding': 3, 'loss': 2, 'softmax': 3, 'language': 4, 'frequency': 2, 'text': 6, 'evaluation': 3, 'trigram': 1}, ('learns', 'from'): {'the': 213, 'linguistic': 13, 'sentence': 13, 'word': 32, 'language': 17, 'large': 15, 'contextual': 14, 'token': 15, 'statistical': 16, 'co-occurrence': 15, 'millions': 11, 'semantic': 10, 'syntactic': 10}, ('trigram', 'updates'): {'the': 7, 'word': 1, 'co-occurrence': 1}, ('prediction', 'samples'): {'large': 1, 'the': 5, 'token': 2, 'word': 1, 'language': 2, 'millions': 1}, ('tokenizer', 'effectively'): {'generalizes': 1, 'improves': 1, 'captures': 1}, ('backpropagation', 'updates'): {'the': 8, 'language': 1, 'token': 1, 'sentence': 1, 'word': 1}, ('process', 'improves'): {'the': 6, 'linguistic': 1, 'word': 2, 'millions': 1, 'syntactic': 1, 'large': 1}, ('statistically', 'gradient'): {'descent': 3}, ('process', 'overfits'): {'word': 2, 'the': 2, 'sentence': 1, 'syntactic': 1, 'linguistic': 1}, ('input', 'fine-tunes'): {'word': 1, 'large': 2, 'the': 3, 'linguistic': 2, 'statistical': 1, 'millions': 1, 'syntactic': 1}, ('corpus', 'feeding'): {'diverse': 1}, ('successfully', 'in'): {'addition': 5, 'contrast': 4}, ('terms', 'tokenization'): {'is': 2}, ('correctly', 'captures'): {'the': 4, 'sentence': 1}, ('n-gram', 'fine-tunes'): {'the': 5, 'contextual': 2, 'token': 1, 'millions': 1, 'statistical': 1, 'language': 1}, ('prediction', 'the'): {'bigram': 1, 'tokenizer': 4, 'system': 3, 'perplexity': 5, 'gradient': 1, 'prediction': 2, 'loss': 2, 'algorithm': 2, 'trigram': 3, 'researcher': 2, 'corpus': 1, 'probability': 2, 'neural': 7, 'n-gram': 1, 'training': 1, 'attention': 1, 'output': 1, 'weight': 2, 'dataset': 1, 'evaluation': 2, 'embedding': 1, 'model': 1}, ('pipeline', 'subsequently'): {'the': 2}, ('data', 'furthermore'): {'the': 4}, ('function', 'successfully'): {'the': 7, 'processes': 1, 'learns': 1, 'maximizes': 1, 'a': 3, 'in': 1, 'predicts': 1, 'moreover': 1}, ('size', 'gradient'): {'descent': 2}, ('errors', 'the'): {'perplexity': 3, 'bigram': 2, 'trigram': 2, 'architecture': 3, 'tokenizer': 3, 'neural': 3, 'training': 4, 'context': 2, 'optimizer': 3, 'sequence': 4, 'text': 2, 'prediction': 2, 'gradient': 2, 'attention': 2, 'embedding': 1, 'dataset': 1, 'loss': 1, 'probability': 4, 'input': 1, 'output': 1, 'language': 1, 'model': 1}, ('significantly', 'converges'): {'linguistic': 1, 'contextual': 1, 'the': 1, 'token': 1, 'millions': 1}, ('network', 'improves'): {'semantic': 4, 'the': 7, 'syntactic': 1, 'statistical': 1, 'large': 1}, ('network', 'overfits'): {'token': 1, 'the': 3, 'syntactic': 1}, ('metric', 'accurately'): {'outputs': 1, 'represents': 1, 'encodes': 1, 'reduces': 1, 'processes': 1, 'optimizes': 1}, ('rapidly', 'bigram'): {'and': 3}, ('corpus', 'recursively'): {'a': 5, 'tokenization': 1, 'the': 4, 'consequently': 1, 'furthermore': 1, 'overfits': 1, 'updates': 1, 'data': 1, 'predicts': 1}, ('sequence', 'evaluates'): {'the': 2, 'semantic': 2}, ('handle', 'unseen'): {'word': 88}, ('output', 'processes'): {'the': 5, 'statistical': 1, 'language': 1, 'millions': 1, 'contextual': 1}, ('vocabulary', 'calculates'): {'the': 10, 'token': 1, 'sentence': 1, 'co-occurrence': 1}, ('sequentially', 'meanwhile'): {'the': 4, 'backpropagation': 1}, ('local', 'word'): {'dependencies': 104}, ('embeddings', 'automatically'): {'the': 5, 'specifically': 1, 'nevertheless': 1, 'a': 2, 'smoothing': 1, 'consequently': 1}, ('continuously', 'transfer'): {'learning': 3}, ('matrix', 'data'): {'preprocessing': 1}, ('terms', 'gradient'): {'descent': 3}, ('patterns', 'word'): {'embeddings': 5}, ('statistically', 'learns'): {'from': 5}, ('input', 'efficiently'): {'trains': 1, 'computes': 2, 'predicts': 1, 'models': 1, 'diverges': 2}, ('rapidly', 'optimizes'): {'large': 1, 'the': 3, 'millions': 1, 'sentence': 1, 'token': 1}, ('weight', 'computes'): {'the': 6, 'syntactic': 1, 'statistical': 1, 'token': 1, 'word': 2, 'linguistic': 1}, ('trigram', 'diverges'): {'word': 1, 'linguistic': 1, 'the': 5, 'sentence': 2, 'contextual': 1}, ('statistically', 'generates'): {'the': 3, 'semantic': 1, 'word': 1, 'sentence': 1, 'statistical': 1, 'language': 1}, ('prediction', 'improves'): {'language': 1, 'the': 4, 'semantic': 1, 'large': 1, 'linguistic': 1}, ('prediction', 'overfits'): {'co-occurrence': 2, 'the': 2, 'linguistic': 2, 'word': 1}, ('predicts', 'co-occurrence'): {'matrices': 22}, ('backpropagation', 'diverges'): {'the': 5, 'sentence': 1, 'large': 1, 'semantic': 1, 'contextual': 1, 'language': 1, 'token': 1}, ('data', 'effectively'): {'perplexity': 1, 'however': 1, 'a': 5, 'the': 7, 'similarly': 1, 'meanwhile': 1, 'smoothing': 1, 'feeding': 1}, ('successfully', 'however'): {'the': 3}, ('sequences', 'in'): {'contrast': 6, 'addition': 1}, ('model', 'specifically'): {'the': 3}, ('bigram', 'converges'): {'semantic': 1, 'word': 1, 'the': 7, 'token': 1}, ('word', 'the'): {'corpus': 4, 'dataset': 2, 'researcher': 1, 'optimizer': 3, 'context': 9, 'vocabulary': 5, 'input': 5, 'evaluation': 3, 'trigram': 2, 'perplexity': 2, 'prediction': 4, 'softmax': 1, 'training': 5, 'algorithm': 3, 'architecture': 4, 'loss': 2, 'language': 4, 'frequency': 2, 'probability': 2, 'weight': 3, 'output': 3, 'n-gram': 2, 'model': 3, 'gradient': 3, 'attention': 3, 'system': 3, 'neural': 1, 'text': 1}, ('window', 'correctly'): {'encodes': 1, 'trains': 1, 'overfits': 1, 'tokenizes': 1, 'generates': 1, 'predicts': 1}, ('sequences', 'cleaning'): {'and': 1}, ('features', 'sequentially'): {'the': 9, 'a': 4, 'similarly': 2, 'therefore': 1, 'cross': 1, 'specifically': 1, 'however': 1}, ('significantly', 'samples'): {'word': 1, 'the': 3, 'sentence': 3, 'large': 1, 'language': 1}, ('overfits', 'millions'): {'of': 10}, ('value', 'automatically'): {'bigram': 2, 'therefore': 1, 'the': 6, 'feeding': 1, 'as': 1, 'cross': 1, 'data': 1}, ('probabilistically', 'adjusts'): {'the': 7, 'sentence': 1, 'word': 1}, ('structure', 'furthermore'): {'the': 5}, ('encodes', 'sentence'): {'structure': 20}, ('significantly', 'the'): {'probability': 7, 'researcher': 5, 'language': 8, 'neural': 6, 'sequence': 6, 'corpus': 4, 'evaluation': 7, 'embedding': 5, 'bigram': 5, 'training': 7, 'system': 7, 'tokenizer': 5, 'dataset': 6, 'perplexity': 4, 'gradient': 7, 'n-gram': 4, 'softmax': 6, 'vocabulary': 4, 'model': 6, 'context': 3, 'algorithm': 12, 'trigram': 3, 'prediction': 7, 'optimizer': 5, 'architecture': 2, 'output': 4, 'input': 5, 'frequency': 3, 'loss': 3, 'attention': 3, 'weight': 1, 'text': 2}, ('mechanism', 'recursively'): {'captures': 1, 'diverges': 1, 'updates': 1}, ('matrices', 'cleaning'): {'and': 2}, ('probability', 'calculates'): {'the': 5, 'statistical': 1, 'large': 1, 'language': 1}, ('gradient', 'sequentially'): {'outputs': 1, 'computes': 2, 'predicts': 1}, ('frequencies', 'nevertheless'): {'the': 3}, ('rapidly', 'perplexity'): {'measures': 4}, ('the', 'evaluation'): {'metric': 375}, ('sequentially', 'increases'): {'word': 2, 'the': 3, 'large': 1, 'linguistic': 1, 'language': 1, 'sentence': 1}, ('processes', 'millions'): {'of': 17}, ('model', 'sequentially'): {'decodes': 1, 'predicts': 1, 'trains': 1, 'overfits': 1, 'improves': 1, 'outputs': 1, 'reduces': 1, 'tokenizes': 1, 'models': 1, 'generates': 1, 'fine-tunes': 1}, ('function', 'updates'): {'syntactic': 2, 'linguistic': 2, 'the': 3}, ('rapidly', 'calculates'): {'the': 5, 'word': 1, 'statistical': 1}, ('matrix', 'furthermore'): {'the': 4}, ('rate', 'iteratively'): {'the': 5, 'a': 3, 'consequently': 1, 'training': 1, 'regularization': 1, 'furthermore': 1}, ('text', 'captures'): {'the': 5}, ('of', 'text'): {'a': 63, 'specifically': 7, 'the': 126, 'rapidly': 12, 'consequently': 4, 'accurately': 12, 'effectively': 16, 'automatically': 11, 'sequentially': 19, 'cross': 2, 'probabilistically': 9, 'however': 9, 'continuously': 13, 'correctly': 15, 'for': 4, 'additionally': 5, 'transfer': 5, 'furthermore': 7, 'in': 6, 'statistically': 15, 'regularization': 1, 'data': 6, 'meanwhile': 6, 'iteratively': 16, 'smoothing': 1, 'recursively': 12, 'backpropagation': 4, 'successfully': 15, 'similarly': 6, 'gradually': 9, 'training': 4, 'significantly': 12, 'as': 3, 'gradient': 2, 'efficiently': 14, 'overfitting': 3, 'feeding': 2, 'perplexity': 4, 'bigram': 2, 'nevertheless': 4, 'subsequently': 4, 'therefore': 3, 'word': 1, 'moreover': 1}, ('continuously', 'in'): {'addition': 6, 'contrast': 5}, ('probabilistically', 'subsequently'): {'the': 5}, ('significantly', 'improves'): {'the': 3, 'semantic': 1, 'large': 1, 'token': 1, 'contextual': 1}, ('significantly', 'overfits'): {'the': 5}, ('structure', 'effectively'): {'a': 5, 'the': 3, 'for': 1, 'feeding': 1}, ('value', 'transfer'): {'learning': 1}, ('frequencies', 'significantly'): {'perplexity': 1, 'the': 8, 'in': 1, 'subsequently': 2, 'a': 3}, ('meaning', 'meanwhile'): {'the': 3}, ('sequentially', 'optimizes'): {'the': 4, 'word': 2, 'semantic': 1, 'language': 1}, ('accurately', 'processes'): {'language': 1, 'the': 4, 'sentence': 1}, ('of', 'splitting'): {'raw': 82}, ('calculates', 'large'): {'amounts': 5}, ('size', 'accurately'): {'the': 6, 'a': 6, 'therefore': 2, 'additionally': 2, 'smoothing': 1, 'moreover': 1, 'gradient': 1, 'word': 1}, ('optimizer', 'captures'): {'the': 2, 'sentence': 1, 'word': 1, 'linguistic': 1}, ('vocabulary', 'outputs'): {'word': 1, 'large': 1, 'statistical': 1, 'co-occurrence': 1, 'the': 7}, ('recursively', 'backpropagation'): {'generates': 1, 'samples': 1, 'predicts': 1}, ('weight', 'successfully'): {'fine-tunes': 1, 'models': 2, 'outputs': 1, 'trains': 1}, ('output', 'nevertheless'): {'the': 1}, ('matrix', 'effectively'): {'a': 2, 'therefore': 1, 'subsequently': 2, 'the': 9, 'perplexity': 2, 'consequently': 2, 'in': 1, 'data': 1, 'meanwhile': 1}, ('predicts', 'semantic'): {'meaning': 34}, ('dataset', 'represents'): {'syntactic': 1, 'semantic': 1, 'the': 5, 'millions': 1}, ('algorithm', 'automatically'): {'calculates': 1, 'learns': 1, 'predicts': 1}, ('sequences', 'additionally'): {'the': 2, 'backpropagation': 1}, ('probabilistically', 'fine-tunes'): {'the': 8, 'linguistic': 1}, ('rate', 'perplexity'): {'measures': 1}, ('the', 'process'): {'of': 82}, ('sequence', 'increases'): {'token': 1, 'language': 1, 'the': 3, 'millions': 1, 'contextual': 1, 'word': 1, 'linguistic': 1, 'co-occurrence': 1}, ('distribution', 'cross'): {'entropy': 2}, ('effectively', 'consequently'): {'the': 10, 'backpropagation': 1}, ('states', 'word'): {'embeddings': 2}, ('rapidly', 'cleaning'): {'and': 3}, ('terms', 'accurately'): {'the': 5, 'similarly': 1, 'for': 1, 'a': 2, 'in': 1}, ('continuously', 'however'): {'backpropagation': 1, 'the': 4}, ('researcher', 'evaluates'): {'the': 3, 'contextual': 2, 'semantic': 1, 'sentence': 1, 'token': 1}, ('gradually', 'evaluates'): {'token': 1, 'the': 1, 'syntactic': 1}, ('iteratively', 'backpropagation'): {'outputs': 1, 'processes': 1, 'recursively': 1, 'generates': 1}, ('samples', 'linguistic'): {'features': 14}, ('matrices', 'additionally'): {'backpropagation': 1, 'the': 1}, ('automatically', 'computes'): {'the': 2, 'co-occurrence': 1}, ('parameters', 'backpropagation'): {'iteratively': 1, 'minimizes': 1, 'statistically': 1}, ('output', 'significantly'): {'the': 5, 'regularization': 1, 'furthermore': 1, 'as': 1, 'cross': 1, 'transfer': 1, 'subsequently': 1, 'increases': 1, 'a': 2, 'therefore': 1, 'training': 1, 'calculates': 1, 'data': 1, 'consequently': 1, 'diverges': 1}, ('sequence', 'optimizes'): {'word': 1, 'the': 1}, ('generates', 'token'): {'sequences': 16}, ('sequence', 'iteratively'): {'trains': 1, 'computes': 1, 'tokenizes': 1, 'updates': 1, 'fine-tunes': 1, 'predicts': 2}, ('correctly', 'generalizes'): {'co-occurrence': 1, 'the': 4, 'millions': 1, 'large': 1}, ('layer', 'maximizes'): {'word': 1, 'the': 3, 'statistical': 1}, ('metric', 'probabilistically'): {'improves': 3, 'generates': 1, 'minimizes': 1, 'represents': 1}, ('probability', 'outputs'): {'word': 1, 'large': 1, 'statistical': 1, 'syntactic': 1, 'linguistic': 1, 'the': 3, 'language': 1}, ('space', 'nevertheless'): {'the': 3}, ('loss', 'meanwhile'): {'the': 5}, ('value', 'in'): {'contrast': 4, 'addition': 5}, ('matrices', 'cross'): {'entropy': 2}, ('layer', 'continuously'): {'optimizes': 1, 'diverges': 1}, ('successfully', 'moreover'): {'the': 6}, ('value', 'rapidly'): {'a': 5, 'transfer': 1, 'moreover': 1, 'the': 2, 'therefore': 1, 'for': 1, 'backpropagation': 1, 'feeding': 1, 'in': 1}, ('embeddings', 'however'): {'the': 1}, ('maximizes', 'language'): {'patterns': 12}, ('tokenizer', 'evaluates'): {'millions': 1, 'word': 1, 'the': 3}, ('rapidly', 'outputs'): {'the': 2}, ('gradually', 'meanwhile'): {'the': 5}, ('function', 'correctly'): {'a': 5, 'subsequently': 1, 'cleaning': 1, 'the': 3, 'generates': 1, 'therefore': 1, 'decodes': 1, 'bigram': 2, 'models': 1, 'word': 1, 'as': 1, 'updates': 1, 'optimizes': 1}, ('prediction', 'meanwhile'): {'the': 2}, ('rate', 'cleaning'): {'and': 5}, ('a', 'robust'): {'the': 167, 'backpropagation': 6}, ('specifically', 'the'): {'evaluation': 12, 'vocabulary': 6, 'context': 8, 'trigram': 3, 'attention': 6, 'researcher': 8, 'model': 3, 'optimizer': 8, 'probability': 7, 'language': 8, 'loss': 5, 'sequence': 9, 'n-gram': 5, 'corpus': 11, 'architecture': 6, 'system': 3, 'neural': 4, 'embedding': 7, 'dataset': 7, 'perplexity': 4, 'weight': 4, 'algorithm': 5, 'training': 7, 'bigram': 2, 'tokenizer': 5, 'prediction': 12, 'text': 6, 'gradient': 7, 'output': 5, 'input': 4}, ('words', 'consequently'): {'the': 1}, ('input', 'learns'): {'from': 12}, ('input', 'generates'): {'the': 6, 'word': 1, 'language': 2, 'syntactic': 1, 'token': 1}, ('models', 'co-occurrence'): {'matrices': 14}, ('low', 'probability'): {'to': 111}, ('weight', 'updates'): {'linguistic': 1, 'the': 4, 'word': 1, 'syntactic': 1, 'large': 1}, ('probabilistically', 'as'): {'a': 3}, ('bigram', 'predicts'): {'large': 1, 'the': 7, 'word': 1, 'co-occurrence': 1, 'syntactic': 1, 'linguistic': 1, 'millions': 1}, ('gradient', 'encodes'): {'millions': 2, 'the': 3, 'word': 2, 'statistical': 1, 'token': 1, 'semantic': 1, 'large': 1, 'syntactic': 1, 'co-occurrence': 1}, ('embeddings', 'statistically'): {'a': 4, 'the': 5, 'moreover': 1, 'meanwhile': 1}, ('recurrent', 'backpropagation'): {'captures': 1, 'fine-tunes': 1, 'encodes': 1}, ('layer', 'captures'): {'the': 3, 'syntactic': 2, 'language': 1}, ('value', 'however'): {'the': 3}, ('sequentially', 'cleaning'): {'and': 3}, ('meaning', 'transfer'): {'learning': 3}, ('process', 'automatically'): {'tokenizes': 2, 'updates': 1, 'optimizes': 1, 'maximizes': 1, 'overfits': 1, 'predicts': 1}, ('probabilistically', 'for'): {'example': 9}, ('accurately', 'nevertheless'): {'the': 2}, ('model', 'encodes'): {'the': 6, 'statistical': 1, 'large': 1, 'co-occurrence': 2, 'millions': 1, 'language': 1}, ('information', 'consequently'): {'the': 4}, ('efficiently', 'training'): {'a': 4}, ('efficiently', 'tokenizes'): {'token': 1, 'the': 3, 'contextual': 1, 'millions': 2}, ('encodes', 'language'): {'patterns': 8}, ('gradient', 'minimizes'): {'token': 1, 'the': 9, 'word': 1, 'semantic': 1, 'syntactic': 1}, ('network', 'increases'): {'the': 7, 'semantic': 1, 'millions': 2, 'syntactic': 1, 'sentence': 1}, ('efficiently', 'therefore'): {'the': 5, 'backpropagation': 1}, ('minimizes', 'word'): {'embeddings': 11, 'frequencies': 14}, ('rapidly', 'cross'): {'entropy': 2}, ('backpropagation', 'predicts'): {'the': 5, 'language': 1, 'contextual': 1, 'linguistic': 2, 'statistical': 1, 'millions': 1, 'word': 1, 'sentence': 1}, ('value', 'statistically'): {'moreover': 1, 'for': 1, 'a': 5, 'feeding': 1, 'nevertheless': 1, 'the': 4, 'furthermore': 1}, ('effectively', 'specifically'): {'the': 4}, ('model', 'minimizes'): {'the': 9, 'word': 3, 'token': 1, 'syntactic': 1, 'linguistic': 1, 'large': 1}, ('weight', 'diverges'): {'the': 4, 'linguistic': 1, 'large': 2, 'co-occurrence': 1}, ('gradually', 'increases'): {'the': 6, 'contextual': 1, 'syntactic': 1}, ('correctly', 'samples'): {'sentence': 1, 'large': 1, 'linguistic': 1, 'the': 1}, ('algorithm', 'rapidly'): {'decodes': 1, 'optimizes': 1, 'generalizes': 1}, ('text', 'generalizes'): {'the': 3}, ('dataset', 'gradually'): {'decodes': 1, 'improves': 1, 'minimizes': 1, 'fine-tunes': 1, 'overfits': 1}, ('iteratively', 'feeding'): {'diverse': 5}, ('correctly', 'the'): {'perplexity': 6, 'output': 4, 'loss': 8, 'input': 7, 'evaluation': 8, 'context': 10, 'optimizer': 9, 'vocabulary': 8, 'researcher': 5, 'sequence': 1, 'embedding': 3, 'prediction': 7, 'architecture': 6, 'weight': 6, 'text': 3, 'bigram': 1, 'frequency': 5, 'corpus': 4, 'training': 8, 'n-gram': 1, 'algorithm': 3, 'trigram': 6, 'attention': 5, 'tokenizer': 4, 'neural': 4, 'system': 2, 'language': 7, 'gradient': 3, 'probability': 4, 'softmax': 2, 'dataset': 2, 'model': 1}, ('fine-tunes', 'word'): {'frequencies': 9, 'embeddings': 12}, ('rate', 'additionally'): {'the': 2}, ('captures', 'word'): {'frequencies': 19, 'embeddings': 8}, ('size', 'probabilistically'): {'for': 1, 'a': 5, 'the': 10, 'however': 3, 'cross': 1, 'cleaning': 1, 'in': 1, 'smoothing': 1}, ('input', 'accurately'): {'samples': 1, 'fine-tunes': 1, 'outputs': 1, 'models': 1, 'represents': 1, 'computes': 1, 'trains': 1}, ('continuously', 'moreover'): {'the': 3}, ('gradually', 'optimizes'): {'the': 2, 'word': 1, 'large': 1, 'contextual': 1, 'token': 1}, ('parameters', 'feeding'): {'diverse': 1}, ('researcher', 'optimizes'): {'semantic': 2, 'the': 2, 'linguistic': 1, 'sentence': 1, 'millions': 1, 'word': 1}, ('loss', 'transfer'): {'learning': 1}, ('words', 'subsequently'): {'the': 5}, ('frequencies', 'word'): {'embeddings': 2}, ('optimizer', 'generalizes'): {'the': 4, 'semantic': 1, 'millions': 1, 'linguistic': 1}, ('vocabulary', 'adjusts'): {'large': 1, 'the': 5, 'contextual': 1, 'word': 1}, ('meaning', 'in'): {'addition': 1, 'contrast': 1}, ('corpus', 'decodes'): {'the': 5, 'contextual': 1, 'token': 1}, ('features', 'smoothing'): {'techniques': 4}, ('architecture', 'decodes'): {'syntactic': 1, 'token': 1, 'millions': 5, 'contextual': 3, 'word': 1, 'co-occurrence': 1, 'statistical': 1, 'the': 2, 'large': 1}, ('predicts', 'the'): {'cross': 27, 'hidden': 16, 'corpus': 26, 'bias': 26, 'batch': 18, 'vocabulary': 22, 'weight': 31, 'training': 21, 'learning': 26, 'softmax': 34, 'probability': 26, 'activation': 25, 'next': 26, 'gradient': 25, 'loss': 28}, ('sequentially', 'additionally'): {'the': 6}, ('meaning', 'rapidly'): {'the': 8, 'a': 3, 'in': 1, 'therefore': 2, 'nevertheless': 1}, ('terms', 'probabilistically'): {'the': 8, 'backpropagation': 1, 'perplexity': 1, 'a': 1, 'for': 1}, ('rate', 'cross'): {'entropy': 3}, ('correctly', 'improves'): {'the': 2, 'language': 1, 'contextual': 1, 'syntactic': 1, 'millions': 1}, ('metric', 'represents'): {'the': 6, 'word': 1, 'linguistic': 1, 'language': 1}, ('correctly', 'overfits'): {'the': 3, 'word': 1, 'large': 1}, ('text', 'converges'): {'the': 5, 'sentence': 1, 'token': 1}, ('gradient', 'computes'): {'the': 6, 'token': 1, 'statistical': 1, 'sentence': 1, 'semantic': 1}, ('word', 'automatically'): {'feeding': 1, 'the': 5, 'nevertheless': 1, 'a': 6, 'consequently': 2, 'therefore': 1, 'overfitting': 1}, ('words', 'specifically'): {'the': 3}, ('tokenizer', 'increases'): {'statistical': 1, 'token': 1, 'co-occurrence': 2, 'the': 4, 'sentence': 1, 'large': 1}, ('information', 'subsequently'): {'the': 1}, ('representations', 'in'): {'a': 88}, ('model', 'computes'): {'word': 2, 'the': 6, 'sentence': 1, 'co-occurrence': 1, 'large': 2}, ('accurate', 'the'): {'system': 11, 'architecture': 5, 'vocabulary': 5, 'evaluation': 5, 'optimizer': 8, 'tokenizer': 7, 'perplexity': 3, 'training': 6, 'researcher': 5, 'input': 7, 'loss': 3, 'sequence': 4, 'attention': 2, 'output': 4, 'embedding': 6, 'prediction': 7, 'weight': 4, 'probability': 4, 'language': 7, 'corpus': 6, 'text': 5, 'trigram': 6, 'neural': 3, 'algorithm': 5, 'context': 4, 'dataset': 2, 'n-gram': 2, 'bigram': 4, 'gradient': 4}, ('algorithm', 'statistically'): {'processes': 1, 'converges': 1, 'evaluates': 1, 'tokenizes': 1, 'generates': 1, 'captures': 1}, ('function', 'backpropagation'): {'increases': 1, 'encodes': 1, 'effectively': 1}, ('window', 'recursively'): {'samples': 1, 'reduces': 2, 'models': 1, 'optimizes': 1, 'minimizes': 1}, ('corpus', 'trains'): {'on': 2}, ('architecture', 'trains'): {'on': 14}, ('optimizer', 'converges'): {'linguistic': 1, 'the': 4, 'word': 1, 'semantic': 2, 'millions': 1, 'large': 2, 'co-occurrence': 2}, ('accurately', 'trains'): {'on': 7}, ('tokenizer', 'optimizes'): {'the': 2, 'co-occurrence': 2, 'millions': 1, 'word': 1, 'linguistic': 1, 'sentence': 1}, ('information', 'specifically'): {'the': 3}, ('tokenizer', 'iteratively'): {'reduces': 1, 'captures': 1, 'minimizes': 1, 'optimizes': 1, 'generalizes': 1}, ('output', 'word'): {'embeddings': 2}, ('researcher', 'calculates'): {'syntactic': 1, 'the': 3}, ('probability', 'adjusts'): {'linguistic': 1, 'contextual': 1, 'token': 1, 'semantic': 1, 'the': 1}, ('features', 'regularization'): {'techniques': 5}, ('mechanism', 'decodes'): {'the': 3, 'semantic': 1, 'millions': 1, 'contextual': 2}, ('process', 'rapidly'): {'diverges': 1, 'represents': 1, 'predicts': 1, 'processes': 1, 'optimizes': 1, 'reduces': 1}, ('perplexity', 'generalizes'): {'contextual': 2, 'sentence': 1, 'word': 1, 'language': 1}, ('distribution', 'efficiently'): {'the': 10, 'nevertheless': 1, 'gradient': 1, 'overfitting': 1}, ('generalizes', 'large'): {'amounts': 9}, ('vector', 'representations'): {'in': 88}, ('loss', 'in'): {'addition': 3, 'contrast': 2}, ('corpus', 'models'): {'the': 6, 'language': 1, 'co-occurrence': 1, 'syntactic': 1}, ('structure', 'meanwhile'): {'the': 3}, ('vocabulary', 'fine-tunes'): {'semantic': 1, 'the': 8}, ('rules', 'gradient'): {'descent': 2}, ('value', 'moreover'): {'the': 2}, ('rapidly', 'adjusts'): {'the': 2, 'word': 1, 'language': 2, 'co-occurrence': 1}, ('architecture', 'models'): {'the': 3, 'contextual': 1, 'language': 1, 'co-occurrence': 2, 'sentence': 1}, ('meaning', 'statistically'): {'consequently': 1, 'however': 1, 'a': 1, 'the': 4, 'similarly': 1, 'in': 2}, ('network', 'rapidly'): {'tokenizes': 1, 'improves': 1}, ('accurately', 'models'): {'large': 1, 'the': 4, 'word': 1}, ('text', 'the'): {'perplexity': 12, 'bigram': 13, 'probability': 4, 'architecture': 5, 'context': 10, 'prediction': 9, 'training': 6, 'embedding': 3, 'language': 5, 'researcher': 4, 'attention': 6, 'weight': 11, 'neural': 6, 'vocabulary': 5, 'text': 6, 'gradient': 7, 'system': 9, 'evaluation': 4, 'trigram': 4, 'loss': 8, 'frequency': 2, 'n-gram': 4, 'output': 8, 'corpus': 9, 'optimizer': 2, 'sequence': 5, 'algorithm': 2, 'model': 3, 'input': 2, 'softmax': 2, 'dataset': 1}, ('loss', 'rapidly'): {'subsequently': 1, 'the': 7, 'cross': 1, 'backpropagation': 1, 'for': 1, 'a': 1, 'moreover': 1, 'nevertheless': 1, 'similarly': 1, 'perplexity': 1}, ('converges', 'statistical'): {'patterns': 14}, ('rules', 'therefore'): {'the': 2, 'backpropagation': 1}, ('significantly', 'transfer'): {'learning': 4}, ('fine-tunes', 'linguistic'): {'features': 17}, ('optimizer', 'samples'): {'the': 7, 'linguistic': 1, 'contextual': 2, 'syntactic': 1}, ('features', 'successfully'): {'gradient': 1, 'moreover': 1, 'a': 4, 'the': 6, 'in': 2, 'however': 1, 'transfer': 1}, ('prediction', 'in'): {'addition': 2}, ('diverges', 'statistical'): {'patterns': 10}, ('matrix', 'meanwhile'): {'the': 4, 'backpropagation': 1}, ('errors', 'in'): {'contrast': 4}, ('data', 'iteratively'): {'the': 5, 'moreover': 2, 'a': 3, 'data': 1, 'overfitting': 1}, ('prediction', 'rapidly'): {'minimizes': 1, 'converges': 1, 'decodes': 1, 'evaluates': 1, 'calculates': 1, 'learns': 1, 'models': 1, 'increases': 1, 'samples': 1}, ('on', 'syntactic'): {'rules': 18}, ('efficiently', 'data'): {'preprocessing': 4}, ('a', 'bidirectional'): {'the': 132, 'backpropagation': 4}, ('gradually', 'cleaning'): {'and': 6}, ('represents', 'sentence'): {'structure': 12}, ('perplexity', 'effectively'): {'processes': 2, 'overfits': 1, 'improves': 1, 'generalizes': 1, 'computes': 1, 'converges': 1, 'learns': 1, 'trains': 1, 'adjusts': 1, 'captures': 1, 'samples': 1}, ('distribution', 'as'): {'a': 3}, ('matrices', 'efficiently'): {'a': 4, 'the': 2, 'as': 1, 'in': 1, 'bigram': 1}, ('gradient', 'successfully'): {'maximizes': 1, 'updates': 1, 'increases': 1, 'overfits': 2, 'models': 1, 'optimizes': 1, 'adjusts': 1, 'decodes': 1}, ('text', 'overfits'): {'millions': 1, 'the': 4, 'linguistic': 1, 'language': 1, 'large': 2}, ('statistically', 'represents'): {'syntactic': 1, 'the': 8, 'large': 1, 'statistical': 1, 'word': 1}, ('distribution', 'for'): {'example': 7}, ('process', 'statistically'): {'reduces': 1, 'decodes': 1, 'computes': 1, 'adjusts': 1, 'diverges': 1}, ('model', 'successfully'): {'generalizes': 2, 'samples': 2, 'predicts': 1, 'represents': 1, 'calculates': 1, 'computes': 1, 'increases': 1, 'updates': 1, 'processes': 1, 'minimizes': 1, 'decodes': 1}, ('probability', 'fine-tunes'): {'the': 6, 'semantic': 1, 'syntactic': 1, 'millions': 1}, ('optimizer', 'improves'): {'the': 4, 'word': 1, 'large': 1, 'statistical': 1}, ('optimizer', 'overfits'): {'sentence': 1, 'linguistic': 1, 'the': 5, 'semantic': 1, 'word': 1, 'large': 1}, ('layer', 'converges'): {'syntactic': 1, 'contextual': 1, 'the': 3, 'word': 1, 'millions': 1}, ('next', 'word'): {'efficiently': 17, 'a': 45, 'prediction': 90, 'overfitting': 3, 'the': 85, 'sequentially': 16, 'regularization': 3, 'accurately': 12, 'continuously': 11, 'gradually': 16, 'as': 2, 'backpropagation': 2, 'for': 2, 'probabilistically': 15, 'successfully': 8, 'automatically': 17, 'correctly': 8, 'rapidly': 7, 'significantly': 11, 'nevertheless': 2, 'moreover': 3, 'specifically': 7, 'iteratively': 17, 'additionally': 1, 'transfer': 2, 'cleaning': 4, 'however': 2, 'in': 9, 'cross': 2, 'statistically': 8, 'therefore': 3, 'meanwhile': 3, 'effectively': 10, 'similarly': 4, 'feeding': 4, 'gradient': 2, 'recursively': 16, 'consequently': 3, 'bigram': 2, 'data': 1, 'smoothing': 2, 'furthermore': 1, 'training': 2, 'perplexity': 1}, ('from', 'word'): {'frequencies': 13, 'embeddings': 19}, ('rapidly', 'fine-tunes'): {'token': 1, 'the': 4, 'semantic': 1}, ('effectively', 'encodes'): {'word': 1, 'token': 1, 'the': 4, 'statistical': 1, 'contextual': 1}, ('bigram', 'processes'): {'the': 2, 'syntactic': 2, 'token': 1, 'word': 2}, ('accurately', 'word'): {'embeddings': 1}, ('metric', 'gradually'): {'trains': 1, 'captures': 1, 'generalizes': 1, 'evaluates': 1}, ('perplexity', 'samples'): {'the': 4, 'language': 1, 'millions': 1}, ('input', 'probabilistically'): {'calculates': 1, 'overfits': 1}, ('researcher', 'outputs'): {'co-occurrence': 1, 'large': 1, 'semantic': 1, 'the': 5, 'language': 1, 'syntactic': 1, 'word': 1}, ('significantly', 'in'): {'contrast': 5, 'addition': 7}, ('probability', 'efficiently'): {'outputs': 2, 'tokenizes': 2, 'represents': 1, 'updates': 1, 'evaluates': 1, 'predicts': 1}, ('function', 'feeding'): {'diverse': 1}, ('prediction', 'statistically'): {'maximizes': 1}, ('structure', 'iteratively'): {'a': 4, 'cross': 1, 'the': 4, 'similarly': 1, 'data': 1, 'for': 1}, ('loss', 'additionally'): {'the': 3}, ('effectively', 'minimizes'): {'the': 4}, ('valid', 'probability'): {'distribution': 97}, ('improves', 'syntactic'): {'rules': 16}, ('efficiently', 'furthermore'): {'the': 10}, ('sentence', 'structure'): {'the': 101, 'successfully': 15, 'for': 2, 'statistically': 17, 'smoothing': 2, 'rapidly': 20, 'a': 47, 'sequentially': 11, 'additionally': 7, 'overfitting': 2, 'effectively': 10, 'significantly': 14, 'in': 5, 'gradually': 20, 'automatically': 9, 'efficiently': 15, 'accurately': 12, 'meanwhile': 3, 'data': 2, 'probabilistically': 12, 'similarly': 2, 'iteratively': 12, 'furthermore': 5, 'word': 1, 'regularization': 3, 'correctly': 10, 'training': 1, 'consequently': 2, 'moreover': 1, 'specifically': 1, 'recursively': 14, 'therefore': 2, 'continuously': 10, 'backpropagation': 4, 'nevertheless': 1, 'subsequently': 2, 'however': 4, 'cleaning': 2, 'gradient': 2, 'tokenization': 1, 'feeding': 2, 'perplexity': 1, 'transfer': 1}, ('mechanism', 'sequentially'): {'calculates': 1, 'updates': 2, 'trains': 2, 'overfits': 1, 'generalizes': 1, 'reduces': 1, 'captures': 1}, ('backpropagation', 'processes'): {'the': 7, 'linguistic': 1, 'millions': 1}, ('word', 'however'): {'the': 2}, ('function', 'recursively'): {'therefore': 2, 'diverges': 1, 'models': 1, 'generalizes': 1, 'the': 2, 'tokenization': 1, 'subsequently': 1, 'generates': 1, 'evaluates': 1, 'training': 1, 'a': 4, 'reduces': 1, 'trains': 1, 'updates': 2}, ('statistically', 'a'): {'large': 4, 'transformer-based': 8, 'generative': 6, 'deep': 2, 'pre-trained': 4, 'recurrent': 8, 'discriminative': 3, 'autoregressive': 5, 'small': 4, 'accurate': 4, 'language': 2, 'scalable': 7, 'shallow': 7, 'lightweight': 5, 'fine-tuned': 6, 'powerful': 2, 'bidirectional': 2, 'robust': 2, 'neural': 2, 'efficient': 2, 'statistical': 1}, ('rules', 'accurately'): {'for': 2, 'the': 6, 'data': 1, 'a': 2, 'gradient': 1, 'in': 1, 'moreover': 1}, ('successfully', 'reduces'): {'the': 6, 'millions': 1, 'language': 2}, ('gradually', 'additionally'): {'the': 4}, ('matrix', 'iteratively'): {'the': 4, 'a': 2, 'smoothing': 1, 'however': 1, 'meanwhile': 1, 'furthermore': 1, 'in': 1, 'training': 1}, ('meaning', 'moreover'): {'backpropagation': 2}, ('successfully', 'training'): {'a': 3}, ('size', 'a'): {'deep': 8, 'lightweight': 1, 'scalable': 3, 'recurrent': 2, 'statistical': 4, 'discriminative': 5, 'fine-tuned': 1, 'transformer-based': 5, 'autoregressive': 3, 'language': 5, 'pre-trained': 6, 'powerful': 7, 'shallow': 1, 'accurate': 2, 'bidirectional': 3, 'small': 3, 'generative': 3, 'robust': 4, 'neural': 3, 'large': 4, 'efficient': 1}, ('descent', 'continuously'): {'the': 7, 'a': 3, 'cleaning': 1, 'therefore': 1, 'moreover': 1, 'perplexity': 1, 'additionally': 1}, ('gradient', 'updates'): {'the': 5, 'sentence': 1, 'word': 1}, ('determines', 'how'): {'many': 90}, ('maximizes', 'syntactic'): {'rules': 10}, ('perplexity', 'overfits'): {'the': 5, 'word': 1, 'statistical': 2, 'contextual': 1}, ('significantly', 'however'): {'the': 3}, ('perplexity', 'improves'): {'the': 7, 'contextual': 1, 'co-occurrence': 1, 'syntactic': 1}, ('a', 'neural'): {'the': 111, 'backpropagation': 6}, ('data', 'cleaning'): {'and': 2}, ('distribution', 'gradient'): {'descent': 1}, ('word', 'statistically'): {'transfer': 1, 'a': 1, 'in': 1, 'the': 3, 'meanwhile': 1, 'however': 1}, ('adjusts', 'co-occurrence'): {'matrices': 14}, ('model', 'updates'): {'syntactic': 1, 'linguistic': 3, 'large': 1, 'the': 8, 'word': 1, 'millions': 1}, ('gracefully', 'additionally'): {'the': 1}, ('terms', 'a'): {'large': 2, 'fine-tuned': 1, 'generative': 2, 'bidirectional': 1, 'statistical': 1, 'neural': 5, 'language': 2, 'robust': 1, 'recurrent': 2, 'efficient': 2, 'accurate': 2, 'deep': 4, 'small': 3, 'scalable': 1, 'lightweight': 2, 'powerful': 2, 'discriminative': 2, 'autoregressive': 1, 'shallow': 1}, ('rapidly', 'as'): {'a': 2}, ('matrices', 'tokenization'): {'is': 4}, ('robust', 'backpropagation'): {'updates': 1, 'adjusts': 1, 'improves': 1, 'increases': 1, 'generalizes': 1, 'reduces': 1}, ('minimizes', 'co-occurrence'): {'matrices': 13}, ('rapidly', 'for'): {'example': 5}, ('to', 'correct'): {'words': 111}, ('rate', 'efficiently'): {'a': 2, 'the': 8, 'similarly': 1, 'perplexity': 1, 'furthermore': 1, 'in': 1}, ('rules', 'data'): {'preprocessing': 1}, ('effectively', 'computes'): {'the': 4, 'statistical': 1, 'contextual': 1}, ('sequences', 'therefore'): {'the': 2}, ('gradient', 'diverges'): {'the': 4, 'millions': 1, 'linguistic': 1}, ('computes', 'word'): {'embeddings': 14, 'frequencies': 14}, ('of', 'words'): {'based': 93}, ('matrices', 'gradient'): {'descent': 1}, ('ability', 'the'): {'loss': 2, 'prediction': 2, 'input': 3, 'perplexity': 6, 'tokenizer': 2, 'system': 2, 'model': 3, 'weight': 2, 'researcher': 5, 'probability': 2, 'bigram': 2, 'dataset': 3, 'training': 3, 'attention': 2, 'output': 2, 'language': 3, 'evaluation': 2, 'sequence': 1, 'corpus': 2, 'context': 1, 'architecture': 1, 'embedding': 1}, ('loss', 'moreover'): {'the': 5}, ('model', 'diverges'): {'syntactic': 1, 'word': 3, 'semantic': 2, 'the': 10, 'contextual': 1, 'millions': 1, 'large': 1}, ('size', 'gradually'): {'the': 9, 'subsequently': 2, 'training': 1, 'a': 6, 'in': 1, 'gradient': 2, 'furthermore': 2, 'moreover': 1, 'transfer': 1, 'cleaning': 1, 'however': 1}, ('system', 'computes'): {'the': 3, 'language': 2, 'contextual': 1}, ('the', 'output'): {'processes': 9, 'iteratively': 3, 'minimizes': 5, 'learns': 13, 'computes': 9, 'tokenizes': 9, 'predicts': 15, 'updates': 8, 'correctly': 3, 'overfits': 9, 'captures': 12, 'adjusts': 14, 'represents': 12, 'evaluates': 6, 'models': 5, 'outputs': 6, 'converges': 8, 'reduces': 12, 'improves': 7, 'samples': 5, 'accurately': 2, 'calculates': 12, 'diverges': 9, 'decodes': 8, 'rapidly': 10, 'increases': 3, 'statistically': 5, 'trains': 8, 'maximizes': 11, 'sequentially': 5, 'optimizes': 11, 'successfully': 9, 'generates': 10, 'probabilistically': 6, 'fine-tunes': 6, 'encodes': 10, 'recursively': 5, 'gradually': 4, 'effectively': 2, 'automatically': 2, 'efficiently': 7, 'significantly': 3, 'generalizes': 7, 'continuously': 2}, ('n-gram', 'correctly'): {'generates': 1, 'samples': 1, 'adjusts': 1, 'learns': 1, 'evaluates': 1}, ('the', 'algorithm'): {'updates': 7, 'sequentially': 8, 'reduces': 11, 'optimizes': 5, 'computes': 12, 'captures': 9, 'diverges': 11, 'fine-tunes': 10, 'recursively': 4, 'maximizes': 6, 'encodes': 13, 'samples': 5, 'tokenizes': 12, 'outputs': 7, 'generalizes': 6, 'trains': 10, 'models': 14, 'processes': 5, 'decodes': 7, 'learns': 11, 'predicts': 17, 'represents': 9, 'probabilistically': 4, 'statistically': 6, 'minimizes': 7, 'improves': 11, 'converges': 10, 'increases': 5, 'generates': 9, 'accurately': 4, 'automatically': 3, 'gradually': 6, 'continuously': 5, 'correctly': 7, 'adjusts': 10, 'effectively': 4, 'evaluates': 5, 'successfully': 9, 'efficiently': 8, 'significantly': 2, 'calculates': 4, 'iteratively': 1, 'rapidly': 3, 'overfits': 1}, ('captures', 'co-occurrence'): {'matrices': 15}, ('structure', 'cleaning'): {'and': 2}, ('represents', 'language'): {'patterns': 11}, ('rate', 'as'): {'a': 3}, ('patterns', 'the'): {'optimizer': 12, 'language': 12, 'probability': 9, 'embedding': 10, 'bigram': 10, 'training': 13, 'weight': 4, 'dataset': 17, 'sequence': 8, 'neural': 5, 'loss': 5, 'attention': 10, 'trigram': 11, 'algorithm': 7, 'evaluation': 9, 'input': 4, 'system': 10, 'output': 6, 'text': 9, 'n-gram': 8, 'researcher': 5, 'tokenizer': 7, 'corpus': 13, 'frequency': 6, 'vocabulary': 10, 'prediction': 7, 'context': 10, 'model': 7, 'architecture': 7, 'gradient': 5, 'perplexity': 2}, ('automatically', 'backpropagation'): {'correctly': 1, 'significantly': 1, 'effectively': 1, 'continuously': 1, 'recursively': 1, 'successfully': 1}, ('metric', 'calculates'): {'the': 4, 'semantic': 2, 'contextual': 1, 'linguistic': 1}, ('samples', 'contextual'): {'information': 15}, ('corpus', 'minimizes'): {'the': 13, 'syntactic': 1}, ('terms', 'gradually'): {'a': 6, 'the': 4, 'furthermore': 1, 'subsequently': 1, 'nevertheless': 1, 'data': 1}, ('iteratively', 'decodes'): {'language': 1, 'the': 6, 'syntactic': 1, 'word': 1}, ('bigram', 'significantly'): {'trains': 1, 'fine-tunes': 1, 'optimizes': 1, 'predicts': 1, 'models': 1, 'generates': 1, 'adjusts': 1}, ('errors', 'moreover'): {'the': 1}, ('data', 'additionally'): {'the': 7}, ('rapidly', 'tokenization'): {'is': 5}, ('continuously', 'reduces'): {'the': 2}, ('input', 'represents'): {'the': 7, 'word': 2, 'sentence': 1, 'millions': 1, 'linguistic': 1, 'contextual': 1}, ('statistically', 'similarly'): {'the': 2}, ('correctly', 'transfer'): {'learning': 3}, ('continuously', 'training'): {'a': 5}, ('matrix', 'cleaning'): {'and': 4}, ('continuously', 'tokenizes'): {'language': 1, 'syntactic': 1}, ('continuously', 'therefore'): {'the': 1}, ('effectively', 'regularization'): {'techniques': 2}, ('size', 'similarly'): {'backpropagation': 1, 'the': 4}, ('layer', 'predicts'): {'word': 2, 'the': 8, 'language': 1, 'contextual': 2, 'semantic': 1, 'token': 1, 'syntactic': 1}, ('consequently', 'the'): {'text': 6, 'bigram': 5, 'trigram': 8, 'researcher': 11, 'dataset': 5, 'loss': 12, 'corpus': 5, 'attention': 9, 'prediction': 6, 'probability': 6, 'n-gram': 9, 'system': 3, 'model': 8, 'optimizer': 7, 'evaluation': 2, 'embedding': 5, 'language': 7, 'gradient': 5, 'weight': 6, 'vocabulary': 3, 'context': 4, 'perplexity': 5, 'neural': 7, 'input': 6, 'architecture': 6, 'tokenizer': 6, 'sequence': 4, 'output': 3, 'training': 7, 'algorithm': 4}, ('sequence', 'efficiently'): {'converges': 1, 'overfits': 1, 'calculates': 1, 'predicts': 1, 'captures': 1, 'trains': 1, 'optimizes': 1}, ('data', 'cross'): {'entropy': 2}, ('size', 'bigram'): {'and': 2}, ('mechanism', 'encodes'): {'the': 2, 'sentence': 1}, ('rapidly', 'gradient'): {'descent': 2}, ('window', 'decodes'): {'millions': 2, 'token': 2, 'linguistic': 1, 'contextual': 1, 'the': 2}, ('iteratively', 'trains'): {'on': 8}, ('backpropagation', 'significantly'): {'predicts': 1, 'increases': 1, 'adjusts': 1, 'decodes': 1, 'calculates': 1, 'tokenizes': 2}, ('output', 'captures'): {'the': 7, 'syntactic': 2, 'word': 1, 'semantic': 1, 'large': 1}, ('overfits', 'word'): {'frequencies': 19, 'embeddings': 15}, ('distribution', 'accurately'): {'however': 1, 'a': 7, 'data': 1, 'the': 3}, ('terms', 'similarly'): {'the': 1}, ('minimizes', 'semantic'): {'meaning': 8}, ('recursively', 'specifically'): {'the': 3}, ('researcher', 'adjusts'): {'millions': 2, 'the': 3, 'word': 1, 'semantic': 1, 'co-occurrence': 1, 'language': 1, 'token': 1}, ('corpus', 'overfitting'): {'occurs': 3}, ('updates', 'contextual'): {'information': 10}, ('mechanism', 'minimizes'): {'the': 5, 'word': 1, 'co-occurrence': 1}, ('text', 'automatically'): {'nevertheless': 1, 'a': 5, 'converges': 1, 'improves': 1, 'subsequently': 1, 'the': 3, 'overfits': 2, 'cleaning': 1, 'represents': 1, 'predicts': 1}, ('significantly', 'moreover'): {'the': 6}, ('computes', 'linguistic'): {'features': 13}, ('rate', 'tokenization'): {'is': 1}, ('rules', 'probabilistically'): {'cleaning': 1, 'transfer': 2, 'a': 2, 'the': 6, 'for': 2, 'subsequently': 1, 'consequently': 1}, ('rapidly', 'learns'): {'from': 12}, ('iteratively', 'models'): {'the': 2, 'language': 1, 'co-occurrence': 1}, ('structure', 'additionally'): {'the': 7}, ('processes', 'word'): {'frequencies': 13, 'embeddings': 19}, ('converges', 'linguistic'): {'features': 16}, ('rapidly', 'generates'): {'the': 5, 'co-occurrence': 1}, ('system', 'successfully'): {'captures': 2, 'generates': 1, 'optimizes': 1, 'fine-tunes': 1, 'diverges': 1, 'computes': 1}, ('trigram', 'decodes'): {'the': 8, 'word': 1, 'linguistic': 1, 'semantic': 1, 'statistical': 1}, ('fine-tunes', 'semantic'): {'meaning': 13}, ('corpus', 'smoothing'): {'techniques': 3}, ('matrices', 'accurately'): {'a': 4, 'the': 8, 'perplexity': 1, 'in': 1, 'specifically': 1, 'gradient': 1}, ('optimizer', 'automatically'): {'models': 2, 'decodes': 1, 'maximizes': 1, 'represents': 1, 'evaluates': 1, 'outputs': 1, 'encodes': 1}, ('correctly', 'in'): {'addition': 2, 'contrast': 4}, ('corpus', 'maximizes'): {'the': 5, 'word': 2, 'syntactic': 1, 'sentence': 1, 'linguistic': 1}, ('architecture', 'maximizes'): {'the': 7, 'semantic': 1, 'statistical': 1}, ('value', 'training'): {'a': 1}, ('matrix', 'additionally'): {'the': 4}, ('corpus', 'continuously'): {'predicts': 3, 'a': 3, 'the': 7, 'fine-tunes': 1, 'generates': 1, 'computes': 1, 'meanwhile': 2, 'specifically': 1, 'trains': 1, 'maximizes': 1, 'overfits': 1, 'word': 1, 'calculates': 1, 'captures': 1}, ('calculates', 'language'): {'patterns': 10}, ('size', 'perplexity'): {'measures': 1}, ('architecture', 'continuously'): {'updates': 1}, ('statistically', 'calculates'): {'the': 4, 'syntactic': 1, 'sentence': 2}, ('amounts', 'of'): {'text': 391}, ('metric', 'outputs'): {'the': 6, 'language': 1, 'word': 2, 'contextual': 1, 'large': 1, 'linguistic': 1}, ('learning', 'rate'): {'rapidly': 18, 'transfer': 3, 'the': 78, 'subsequently': 3, 'effectively': 12, 'recursively': 17, 'backpropagation': 3, 'accurately': 11, 'statistically': 15, 'automatically': 10, 'efficiently': 14, 'probabilistically': 17, 'a': 47, 'feeding': 5, 'similarly': 7, 'in': 1, 'training': 3, 'correctly': 18, 'gradually': 14, 'continuously': 14, 'cleaning': 5, 'sequentially': 8, 'iteratively': 12, 'successfully': 8, 'consequently': 3, 'overfitting': 1, 'moreover': 3, 'furthermore': 2, 'therefore': 3, 'word': 3, 'regularization': 2, 'significantly': 11, 'smoothing': 3, 'cross': 3, 'as': 3, 'nevertheless': 4, 'specifically': 3, 'perplexity': 1, 'data': 2, 'additionally': 2, 'however': 3, 'bigram': 1, 'tokenization': 1}, ('trigram', 'trains'): {'on': 10}, ('states', 'the'): {'weight': 3, 'vocabulary': 5, 'language': 5, 'embedding': 5, 'training': 3, 'output': 2, 'input': 2, 'neural': 3, 'probability': 3, 'model': 3, 'loss': 3, 'text': 3, 'dataset': 3, 'researcher': 1, 'architecture': 6, 'optimizer': 2, 'gradient': 5, 'sequence': 2, 'perplexity': 3, 'attention': 1, 'system': 4, 'frequency': 1, 'evaluation': 2, 'context': 3, 'algorithm': 1, 'trigram': 2, 'prediction': 1, 'softmax': 1}, ('the', 'foundation'): {'of': 110}, ('backpropagation', 'trains'): {'on': 8}, ('sequentially', 'gradient'): {'descent': 2}, ('researcher', 'fine-tunes'): {'statistical': 1, 'the': 5, 'word': 3, 'token': 2, 'co-occurrence': 1, 'linguistic': 1}, ('sequentially', 'tokenizes'): {'sentence': 1, 'token': 1, 'the': 1, 'contextual': 1, 'millions': 1}, ('correctly', 'however'): {'the': 6}, ('sequentially', 'therefore'): {'the': 3, 'backpropagation': 1}, ('efficiently', 'evaluates'): {'token': 1, 'semantic': 1, 'large': 1, 'the': 1, 'syntactic': 1, 'co-occurrence': 1, 'word': 1}, ('architecture', 'captures'): {'the': 4, 'language': 1, 'linguistic': 1, 'statistical': 1, 'semantic': 1, 'millions': 1, 'large': 2, 'co-occurrence': 2, 'sentence': 1, 'word': 1}, ('accurately', 'captures'): {'the': 4, 'sentence': 1}, ('effectively', 'updates'): {'the': 2, 'semantic': 1, 'linguistic': 1}, ('from', 'co-occurrence'): {'matrices': 15}, ('successfully', 'furthermore'): {'the': 6}, ('information', 'successfully'): {'the': 7, 'a': 4, 'furthermore': 1, 'moreover': 1, 'therefore': 1, 'consequently': 1, 'data': 1}, ('overfits', 'linguistic'): {'features': 12}, ('mechanism', 'maximizes'): {'contextual': 1, 'the': 6, 'syntactic': 1, 'co-occurrence': 1}, ('trigram', 'models'): {'capture': 104, 'word': 1, 'syntactic': 1, 'sentence': 1, 'millions': 1, 'the': 1}, ('input', 'gradually'): {'encodes': 1, 'maximizes': 1, 'converges': 1, 'tokenizes': 1}, ('backpropagation', 'models'): {'token': 1, 'the': 4, 'co-occurrence': 1, 'semantic': 1, 'large': 1, 'word': 1, 'syntactic': 1, 'millions': 3}, ('pipeline', 'backpropagation'): {'adjusts': 1, 'samples': 1, 'reduces': 1}, ('probabilistically', 'represents'): {'the': 4, 'sentence': 1, 'contextual': 1, 'word': 1, 'language': 1}, ('sequentially', 'learns'): {'from': 8}, ('mechanism', 'continuously'): {'represents': 1, 'updates': 1, 'models': 1, 'predicts': 1, 'processes': 1}, ('samples', 'token'): {'sequences': 7}, ('researcher', 'efficiently'): {'generalizes': 1, 'computes': 1, 'decodes': 1, 'reduces': 1, 'improves': 1, 'evaluates': 1, 'minimizes': 1}, ('window', 'sequentially'): {'optimizes': 1, 'converges': 1, 'increases': 3, 'models': 1}, ('sequentially', 'generates'): {'word': 2, 'the': 2, 'large': 1}, ('algorithm', 'reduces'): {'token': 1, 'the': 6, 'language': 2, 'contextual': 1, 'statistical': 1}, ('system', 'updates'): {'the': 6, 'sentence': 1, 'language': 1}, ('model', 'backpropagation'): {'computes': 1, 'accurately': 1, 'minimizes': 1}, ('training', 'loss'): {'however': 3, 'in': 2, 'a': 28, 'the': 40, 'as': 1, 'backpropagation': 2, 'consequently': 2, 'similarly': 4, 'specifically': 2, 'for': 3, 'therefore': 2, 'nevertheless': 1, 'additionally': 2, 'moreover': 1, 'subsequently': 1}, ('furthermore', 'backpropagation'): {'generates': 1, 'reduces': 1, 'increases': 1, 'captures': 1, 'diverges': 1, 'optimizes': 1, 'updates': 1}, ('processes', 'linguistic'): {'features': 11}, ('continuously', 'data'): {'preprocessing': 1}, ('function', 'decodes'): {'the': 6, 'large': 1, 'sentence': 1, 'semantic': 1}, ('effectively', 'diverges'): {'the': 1, 'language': 1}, ('normalizing', 'text'): {'data': 98}, ('language', 'modeling'): {'the': 46, 'a': 38, 'similarly': 4, 'backpropagation': 1, 'moreover': 1, 'consequently': 1, 'for': 1, 'subsequently': 4, 'additionally': 5, 'furthermore': 2, 'however': 2, 'meanwhile': 1, 'therefore': 2, 'in': 1, 'nevertheless': 1}, ('tokenizer', 'efficiently'): {'fine-tunes': 1, 'represents': 1, 'calculates': 1, 'generates': 1, 'trains': 1, 'reduces': 1, 'overfits': 1, 'captures': 1, 'maximizes': 1, 'diverges': 1, 'samples': 1}, ('sequence', 'learns'): {'from': 11}, ('updates', 'token'): {'sequences': 7}, ('predicts', 'statistical'): {'patterns': 20}, ('sequence', 'generates'): {'language': 1, 'the': 3, 'semantic': 1, 'contextual': 1, 'word': 1, 'token': 1, 'co-occurrence': 1, 'statistical': 1}, ('rate', 'accurately'): {'the': 6, 'a': 2, 'backpropagation': 1, 'subsequently': 1, 'regularization': 1}, ('output', 'generalizes'): {'the': 3, 'large': 1, 'millions': 1, 'syntactic': 1, 'word': 1}, ('meaning', 'training'): {'a': 1}, ('minimizes', 'the'): {'vocabulary': 11, 'probability': 9, 'batch': 20, 'corpus': 21, 'loss': 16, 'gradient': 17, 'bias': 10, 'next': 17, 'weight': 15, 'activation': 16, 'training': 9, 'hidden': 15, 'cross': 24, 'learning': 7, 'softmax': 12}, ('optimizer', 'rapidly'): {'diverges': 1, 'samples': 1, 'encodes': 1, 'fine-tunes': 1, 'predicts': 1}, ('function', 'trains'): {'on': 12}, ('meaning', 'therefore'): {'the': 2}, ('probabilistically', 'a'): {'robust': 6, 'deep': 7, 'lightweight': 2, 'neural': 4, 'discriminative': 4, 'transformer-based': 4, 'recurrent': 2, 'bidirectional': 6, 'powerful': 2, 'accurate': 6, 'pre-trained': 4, 'fine-tuned': 6, 'small': 2, 'scalable': 4, 'autoregressive': 2, 'shallow': 5, 'statistical': 4, 'language': 4}, ('gracefully', 'as'): {'a': 1}, ('text', 'however'): {'the': 12}, ('increases', 'syntactic'): {'rules': 16}, ('sequences', 'probabilistically'): {'the': 3, 'in': 1, 'similarly': 1, 'therefore': 1, 'transfer': 1}, ('fine-tunes', 'contextual'): {'information': 15}, ('recursively', 'encodes'): {'co-occurrence': 1, 'the': 5, 'word': 1}, ('gracefully', 'for'): {'example': 1}, ('techniques', 'help'): {'language': 88}, ('continuously', 'furthermore'): {'the': 8}, ('layer', 'processes'): {'the': 4, 'word': 1, 'linguistic': 1, 'co-occurrence': 1, 'syntactic': 1}, ('matrices', 'probabilistically'): {'the': 8, 'however': 1, 'consequently': 1, 'a': 5, 'for': 2, 'therefore': 1}, ('function', 'models'): {'the': 5, 'millions': 1, 'word': 1, 'sentence': 2}, ('fine-tunes', 'the'): {'gradient': 16, 'probability': 14, 'corpus': 11, 'batch': 15, 'hidden': 16, 'next': 20, 'vocabulary': 16, 'learning': 15, 'loss': 13, 'softmax': 13, 'weight': 18, 'activation': 18, 'bias': 14, 'training': 14, 'cross': 9}, ('text', 'statistically'): {'transfer': 1, 'the': 8, 'diverges': 1, 'as': 1, 'a': 1, 'specifically': 1, 'optimizes': 1, 'therefore': 1, 'additionally': 1, 'subsequently': 1}, ('process', 'reduces'): {'token': 2, 'the': 5, 'syntactic': 1}, ('data', 'efficiently'): {'the': 5, 'a': 3}, ('a', 'shallow'): {'the': 162, 'backpropagation': 7}, ('efficiently', 'bigram'): {'and': 5}, ('recursively', 'minimizes'): {'the': 5, 'contextual': 1, 'millions': 1, 'large': 1, 'word': 1}, ('features', 'feeding'): {'diverse': 2}, ('weight', 'matrix'): {'significantly': 17, 'sequentially': 11, 'tokenization': 1, 'a': 39, 'rapidly': 9, 'correctly': 13, 'recursively': 17, 'in': 6, 'furthermore': 4, 'successfully': 16, 'statistically': 15, 'iteratively': 12, 'the': 87, 'gradually': 11, 'probabilistically': 12, 'consequently': 2, 'effectively': 21, 'automatically': 13, 'efficiently': 10, 'subsequently': 5, 'additionally': 4, 'smoothing': 1, 'nevertheless': 3, 'continuously': 11, 'specifically': 6, 'cleaning': 4, 'accurately': 16, 'therefore': 4, 'meanwhile': 5, 'moreover': 2, 'for': 2, 'data': 1, 'gradient': 2, 'word': 3, 'perplexity': 1, 'similarly': 3, 'transfer': 2, 'as': 3, 'however': 3, 'backpropagation': 1, 'feeding': 1, 'bigram': 1, 'regularization': 1}, ('process', 'tokenizes'): {'token': 1, 'the': 6, 'language': 1, 'statistical': 1, 'linguistic': 1, 'co-occurrence': 1}, ('and', 'normalizing'): {'text': 98}, ('n-gram', 'recursively'): {'captures': 1, 'evaluates': 1, 'learns': 1, 'predicts': 1, 'updates': 1, 'samples': 1}, ('patterns', 'automatically'): {'a': 3, 'similarly': 1, 'backpropagation': 2, 'the': 8, 'consequently': 2, 'training': 1, 'transfer': 1, 'data': 1, 'gradient': 1, 'in': 1}, ('frequencies', 'the'): {'loss': 1, 'input': 3, 'training': 7, 'researcher': 8, 'vocabulary': 5, 'probability': 4, 'context': 5, 'weight': 4, 'gradient': 5, 'output': 2, 'system': 3, 'text': 6, 'architecture': 4, 'language': 2, 'sequence': 2, 'embedding': 2, 'n-gram': 3, 'attention': 1, 'perplexity': 3, 'trigram': 2, 'optimizer': 3, 'model': 3, 'corpus': 3, 'neural': 1, 'algorithm': 2, 'frequency': 1, 'tokenizer': 2, 'softmax': 2, 'evaluation': 1, 'bigram': 2}, ('evaluates', 'millions'): {'of': 10}, ('system', 'correctly'): {'learns': 1, 'predicts': 1, 'decodes': 1, 'represents': 1, 'reduces': 1, 'minimizes': 1, 'evaluates': 1}, ('modeling', 'however'): {'the': 2}, ('correctly', 'moreover'): {'the': 6}, ('efficiently', 'optimizes'): {'the': 1, 'linguistic': 1, 'large': 1, 'word': 1, 'syntactic': 1}, ('network', 'tokenizes'): {'the': 6, 'token': 1, 'statistical': 1, 'sentence': 1, 'linguistic': 1}, ('input', 'calculates'): {'language': 1, 'the': 2, 'contextual': 1, 'sentence': 1, 'word': 2, 'co-occurrence': 2, 'large': 1}, ('metric', 'adjusts'): {'statistical': 1, 'word': 1, 'the': 5, 'large': 2, 'semantic': 1}, ('optimizer', 'statistically'): {'evaluates': 1, 'overfits': 1, 'learns': 1, 'computes': 1, 'maximizes': 1, 'predicts': 1, 'decodes': 1, 'samples': 1}, ('loss', 'training'): {'a': 2}, ('perplexity', 'rapidly'): {'samples': 1, 'adjusts': 1, 'processes': 1}, ('iteratively', 'minimizes'): {'the': 5, 'word': 1}, ('sequence', 'accurately'): {'evaluates': 2}, ('loss', 'therefore'): {'the': 2}, ('sequentially', 'data'): {'preprocessing': 1}, ('modeling', 'nevertheless'): {'the': 1}, ('prediction', 'reduces'): {'the': 8, 'language': 1, 'syntactic': 1, 'word': 1}, ('window', 'encodes'): {'sentence': 2, 'the': 7, 'semantic': 2, 'word': 1, 'statistical': 1, 'large': 1}, ('gradually', 'gradient'): {'descent': 4}, ('gradually', 'tokenizes'): {'the': 4, 'statistical': 1, 'linguistic': 1}, ('prediction', 'tokenizes'): {'the': 1, 'statistical': 1, 'sentence': 1, 'word': 1, 'syntactic': 1}, ('output', 'samples'): {'the': 4, 'millions': 1}, ('corpus', 'diverges'): {'the': 4, 'word': 2, 'semantic': 1}, ('weight', 'decodes'): {'the': 7, 'sentence': 1, 'large': 1, 'word': 1, 'linguistic': 1}, ('gradually', 'therefore'): {'backpropagation': 1, 'the': 4}, ('prediction', 'therefore'): {'backpropagation': 1}, ('data', 'for'): {'example': 5}, ('accurately', 'generalizes'): {'statistical': 1, 'the': 1, 'semantic': 1}, ('patterns', 'transfer'): {'learning': 7}, ('errors', 'therefore'): {'the': 2}, ('resources', 'in'): {'addition': 1, 'contrast': 1}, ('mechanism', 'updates'): {'the': 3, 'token': 1, 'semantic': 1, 'sentence': 1}, ('output', 'the'): {'corpus': 7, 'trigram': 2, 'evaluation': 1, 'language': 9, 'n-gram': 2, 'model': 3, 'dataset': 2, 'algorithm': 3, 'bigram': 2, 'context': 5, 'input': 2, 'embedding': 3, 'vocabulary': 6, 'frequency': 1, 'researcher': 3, 'text': 4, 'gradient': 3, 'system': 4, 'output': 3, 'neural': 3, 'training': 3, 'probability': 2, 'perplexity': 3, 'optimizer': 1, 'prediction': 3, 'softmax': 3, 'tokenizer': 2, 'sequence': 2, 'loss': 3, 'attention': 1}, ('window', 'minimizes'): {'the': 6, 'sentence': 1, 'syntactic': 1, 'token': 1, 'large': 1, 'semantic': 1}, ('structure', 'efficiently'): {'the': 4, 'in': 3, 'backpropagation': 2, 'a': 3, 'as': 1, 'meanwhile': 1, 'nevertheless': 1}, ('statistically', 'consequently'): {'the': 5, 'backpropagation': 1}, ('overfits', 'co-occurrence'): {'matrices': 15}, ('loop', 'updates'): {'model': 104}, ('value', 'furthermore'): {'the': 2}, ('efficiently', 'perplexity'): {'measures': 3}, ('embeddings', 'effectively'): {'the': 7, 'a': 4, 'training': 1, 'bigram': 1, 'as': 1}, ('probabilistically', 'similarly'): {'the': 4}, ('gradually', 'learns'): {'from': 7}, ('researcher', 'learns'): {'from': 5}, ('researcher', 'generates'): {'contextual': 1, 'sentence': 1, 'co-occurrence': 1, 'the': 2}, ('size', 'consequently'): {'the': 7}, ('iteratively', 'overfitting'): {'occurs': 3}, ('weight', 'trains'): {'on': 14}, ('information', 'correctly'): {'however': 1, 'the': 11, 'transfer': 1, 'a': 1, 'word': 1, 'in': 1, 'furthermore': 2}, ('recursively', 'smoothing'): {'techniques': 2}, ('generalizes', 'language'): {'patterns': 14}, ('rules', 'gradually'): {'the': 7, 'consequently': 1, 'training': 1, 'a': 2, 'furthermore': 1, 'for': 1, 'moreover': 1, 'subsequently': 1}, ('computes', 'semantic'): {'meaning': 8}, ('perplexity', 'statistically'): {'reduces': 1, 'diverges': 1, 'maximizes': 1, 'predicts': 2}, ('matrix', 'efficiently'): {'a': 2, 'gradient': 2, 'training': 1, 'for': 1, 'the': 3, 'bigram': 1}, ('metric', 'fine-tunes'): {'language': 1, 'the': 5}, ('parameters', 'overfitting'): {'occurs': 2}, ('corpus', 'converges'): {'large': 1, 'the': 3, 'word': 1, 'millions': 2, 'linguistic': 1, 'syntactic': 1}, ('output', 'improves'): {'co-occurrence': 1, 'statistical': 1, 'the': 2, 'word': 2, 'language': 1}, ('output', 'overfits'): {'syntactic': 1, 'the': 5, 'millions': 1, 'co-occurrence': 1, 'token': 1}, ('vocabulary', 'correctly'): {'adjusts': 1, 'evaluates': 1, 'trains': 1, 'increases': 1, 'models': 1, 'calculates': 1, 'reduces': 1}, ('architecture', 'converges'): {'the': 4, 'token': 1, 'sentence': 1, 'syntactic': 1}, ('accurately', 'converges'): {'large': 1, 'the': 4, 'syntactic': 1, 'linguistic': 1, 'token': 1}, ('terms', 'consequently'): {'the': 1}, ('ability', 'in'): {'contrast': 3}, ('mechanism', 'diverges'): {'language': 1, 'the': 3, 'millions': 1, 'semantic': 1}, ('value', 'effectively'): {'training': 1, 'for': 1, 'a': 2, 'the': 7, 'consequently': 1, 'however': 1, 'as': 1, 'perplexity': 1}, ('significantly', 'reduces'): {'the': 1, 'word': 1, 'contextual': 1}, ('the', 'embedding'): {'layer': 326}, ('space', 'the'): {'perplexity': 5, 'system': 1, 'tokenizer': 1, 'vocabulary': 1, 'n-gram': 1, 'probability': 2, 'language': 1, 'input': 1, 'context': 1, 'dataset': 3, 'training': 3, 'gradient': 3, 'algorithm': 2, 'trigram': 3, 'embedding': 1, 'model': 1, 'architecture': 4, 'evaluation': 3, 'output': 2, 'text': 2, 'attention': 1, 'prediction': 1, 'loss': 1}, ('iteratively', 'smoothing'): {'techniques': 3}, ('data', 'tokenization'): {'is': 3}, ('significantly', 'training'): {'a': 5}, ('text', 'moreover'): {'the': 3}, ('weight', 'models'): {'the': 7, 'contextual': 2, 'semantic': 1, 'word': 3, 'statistical': 1}, ('iteratively', 'maximizes'): {'word': 1}, ('rate', 'probabilistically'): {'specifically': 1, 'in': 2, 'the': 8, 'a': 4, 'additionally': 1, 'backpropagation': 1}, ('meaning', 'data'): {'preprocessing': 1}, ('states', 'automatically'): {'a': 5, 'the': 4, 'backpropagation': 1}, ('effectively', 'backpropagation'): {'significantly': 2, 'processes': 1}, ('parameters', 'smoothing'): {'techniques': 3}, ('tokenizer', 'learns'): {'from': 12}, ('successfully', 'evaluates'): {'token': 1, 'the': 7, 'co-occurrence': 1}, ('models', 'statistical'): {'patterns': 17}, ('tokenizer', 'generates'): {'the': 1, 'sentence': 1}, ('patterns', 'in'): {'contrast': 14, 'addition': 6}, ('efficiently', 'cleaning'): {'and': 1}, ('a', 'fine-tuned'): {'the': 127, 'backpropagation': 2}, ('layer', 'significantly'): {'increases': 1, 'diverges': 1, 'calculates': 1, 'adjusts': 2, 'generates': 1, 'represents': 1, 'improves': 1, 'encodes': 1}, ('parameters', 'continuously'): {'the': 5, 'nevertheless': 1, 'consequently': 1, 'meanwhile': 1, 'similarly': 1, 'for': 1, 'a': 1}, ('rules', 'bigram'): {'and': 1}, ('patterns', 'rapidly'): {'the': 7, 'tokenization': 1, 'overfitting': 1, 'a': 5, 'meanwhile': 1, 'in': 2, 'gradient': 1, 'additionally': 1, 'bigram': 1, 'subsequently': 1, 'cross': 1, 'nevertheless': 1, 'cleaning': 1}, ('recursively', 'regularization'): {'techniques': 6}, ('data', 'gradient'): {'descent': 5}, ('ability', 'however'): {'the': 5}, ('window', 'maximizes'): {'the': 3, 'co-occurrence': 1, 'contextual': 1, 'millions': 1}, ('calculates', 'syntactic'): {'rules': 21}, ('resources', 'additionally'): {'the': 3}, ('statistically', 'subsequently'): {'the': 8}, ('researcher', 'accurately'): {'generalizes': 1}, ('window', 'continuously'): {'captures': 2, 'models': 1, 'outputs': 1, 'generalizes': 1, 'fine-tunes': 1, 'maximizes': 1}, ('distribution', 'a'): {'neural': 4, 'scalable': 6, 'deep': 2, 'small': 6, 'discriminative': 3, 'pre-trained': 3, 'fine-tuned': 1, 'lightweight': 1, 'powerful': 1, 'transformer-based': 5, 'statistical': 2, 'bidirectional': 2, 'shallow': 5, 'accurate': 4, 'robust': 3, 'language': 2, 'large': 1, 'efficient': 5}, ('accurately', 'the'): {'system': 4, 'researcher': 4, 'perplexity': 2, 'bigram': 4, 'context': 10, 'text': 3, 'evaluation': 8, 'input': 6, 'tokenizer': 8, 'corpus': 3, 'trigram': 6, 'language': 4, 'training': 10, 'weight': 5, 'architecture': 5, 'sequence': 9, 'algorithm': 6, 'probability': 4, 'n-gram': 5, 'output': 5, 'prediction': 3, 'vocabulary': 6, 'attention': 4, 'neural': 5, 'loss': 6, 'gradient': 3, 'dataset': 1, 'optimizer': 3, 'softmax': 4, 'model': 4, 'embedding': 2, 'frequency': 2}, ('overfits', 'semantic'): {'meaning': 13}, ('size', 'subsequently'): {'the': 7}, ('patterns', 'however'): {'the': 13}, ('minimize', 'the'): {'training': 94}, ('assigns', 'probabilities'): {'to': 93}, ('structure', 'tokenization'): {'is': 1}, ('automatically', 'decodes'): {'the': 5}, ('probability', 'represents'): {'linguistic': 1, 'the': 4, 'syntactic': 1, 'word': 1, 'language': 1}, ('algorithm', 'effectively'): {'evaluates': 1, 'updates': 1, 'processes': 1, 'calculates': 1}, ('successfully', 'meanwhile'): {'the': 3}, ('dataset', 'computes'): {'contextual': 1, 'the': 2, 'semantic': 1}, ('efficiently', 'outputs'): {'the': 5, 'large': 1, 'sentence': 2, 'syntactic': 1}, ('loss', 'data'): {'preprocessing': 1}, ('meaning', 'furthermore'): {'the': 3}, ('terms', 'subsequently'): {'the': 2}, ('trigram', 'maximizes'): {'the': 9, 'sentence': 1, 'millions': 1}, ('statistically', 'fine-tunes'): {'the': 1}, ('accurately', 'overfits'): {'the': 6}, ('processes', 'semantic'): {'meaning': 14}, ('rapidly', 'represents'): {'the': 4, 'syntactic': 1}, ('sequence', 'probabilistically'): {'reduces': 1, 'converges': 2, 'predicts': 2, 'evaluates': 1, 'maximizes': 1}, ('trigram', 'continuously'): {'minimizes': 1, 'samples': 1, 'generalizes': 1, 'models': 1, 'predicts': 1, 'encodes': 1, 'evaluates': 1}, ('patterns', 'statistically'): {'a': 3, 'the': 9, 'data': 1, 'feeding': 2, 'however': 1, 'meanwhile': 1, 'overfitting': 1, 'for': 1}, ('matrix', 'tokenization'): {'is': 1}, ('structure', 'gradient'): {'descent': 2}, ('tokenizer', 'accurately'): {'maximizes': 1, 'learns': 1, 'converges': 1, 'calculates': 2, 'fine-tunes': 1, 'updates': 1, 'increases': 1}, ('well', 'a'): {'language': 104}, ('gradually', 'data'): {'preprocessing': 2}, ('function', 'minimizes'): {'the': 6, 'language': 2}, ('information', 'backpropagation'): {'correctly': 2, 'rapidly': 1, 'continuously': 1, 'minimizes': 1}, ('the', 'context'): {'window': 471}, ('meanwhile', 'the'): {'embedding': 6, 'training': 6, 'vocabulary': 8, 'neural': 5, 'attention': 14, 'algorithm': 7, 'loss': 5, 'researcher': 7, 'bigram': 7, 'dataset': 7, 'probability': 8, 'text': 7, 'sequence': 4, 'prediction': 6, 'gradient': 9, 'perplexity': 7, 'corpus': 6, 'trigram': 3, 'architecture': 6, 'evaluation': 10, 'tokenizer': 4, 'model': 6, 'output': 4, 'system': 4, 'context': 1, 'weight': 7, 'optimizer': 5, 'language': 7, 'n-gram': 6, 'input': 1}, ('bidirectional', 'backpropagation'): {'fine-tunes': 1, 'reduces': 1, 'tokenizes': 1, 'encodes': 1}, ('distribution', 'gradually'): {'training': 2, 'the': 2, 'subsequently': 2, 'a': 4, 'cross': 1}, ('predicts', 'linguistic'): {'features': 36}, ('continuously', 'evaluates'): {'the': 2, 'millions': 1, 'large': 1}, ('matrix', 'gradient'): {'descent': 2}, ('trigram', 'captures'): {'the': 2, 'word': 3}, ('backpropagation', 'captures'): {'the': 2, 'linguistic': 1, 'token': 1, 'word': 1, 'co-occurrence': 1}, ('a', 'efficient'): {'the': 141, 'backpropagation': 3}, ('computes', 'contextual'): {'information': 11}, ('resources', 'moreover'): {'the': 1}, ('automatically', 'specifically'): {'the': 5}, ('converges', 'contextual'): {'information': 11}, ('successfully', 'increases'): {'the': 7, 'word': 2}, ('effectively', 'feeding'): {'diverse': 5}, ('to', 'be'): {'adapted': 104}, ('loss', 'furthermore'): {'the': 3}, ('data', 'accurately'): {'a': 4, 'regularization': 1, 'the': 9, 'cleaning': 1, 'for': 1, 'therefore': 1, 'bigram': 1}, ('computes', 'the'): {'gradient': 17, 'vocabulary': 10, 'batch': 11, 'cross': 19, 'hidden': 9, 'bias': 15, 'weight': 15, 'loss': 10, 'activation': 15, 'corpus': 12, 'learning': 16, 'training': 8, 'softmax': 16, 'next': 10, 'probability': 5}, ('recursively', 'updates'): {'syntactic': 1, 'large': 1, 'the': 6, 'millions': 1}, ('function', 'overfitting'): {'occurs': 4}, ('corpus', 'predicts'): {'the': 8, 'word': 3, 'language': 2, 'millions': 2, 'sentence': 1, 'syntactic': 1, 'token': 1, 'linguistic': 1}, ('architecture', 'predicts'): {'token': 1, 'language': 1, 'the': 8, 'semantic': 1, 'large': 1, 'statistical': 1, 'syntactic': 1, 'linguistic': 1, 'co-occurrence': 1, 'word': 1}, ('distribution', 'similarly'): {'the': 6}, ('rapidly', 'a'): {'robust': 10, 'accurate': 6, 'neural': 5, 'autoregressive': 4, 'shallow': 8, 'large': 6, 'small': 5, 'efficient': 4, 'transformer-based': 4, 'statistical': 4, 'lightweight': 3, 'language': 2, 'discriminative': 1, 'deep': 4, 'fine-tuned': 5, 'recurrent': 2, 'scalable': 3, 'powerful': 4}, ('features', 'significantly'): {'the': 6, 'nevertheless': 1, 'furthermore': 1, 'a': 1, 'subsequently': 1}, ('matrices', 'gradually'): {'the': 2, 'specifically': 1, 'training': 1, 'a': 3, 'however': 1, 'similarly': 1, 'bigram': 1, 'furthermore': 1, 'additionally': 1}, ('step', 'before'): {'feeding': 99}, ('process', 'effectively'): {'calculates': 1, 'represents': 1, 'minimizes': 1, 'tokenizes': 1}, ('frequencies', 'automatically'): {'the': 8, 'for': 1, 'consequently': 1, 'as': 1, 'smoothing': 1, 'furthermore': 1}, ('models', 'to'): {'be': 104}, ('successfully', 'optimizes'): {'the': 6, 'language': 1, 'sentence': 1, 'co-occurrence': 1}, ('prediction', 'furthermore'): {'the': 1}, ('size', 'as'): {'a': 8}, ('dataset', 'successfully'): {'minimizes': 1, 'reduces': 1, 'converges': 1, 'computes': 1, 'optimizes': 1, 'improves': 1}, ('reduces', 'millions'): {'of': 14}, ('errors', 'furthermore'): {'the': 2}, ('states', 'however'): {'the': 4}, ('function', 'smoothing'): {'techniques': 2}, ('decodes', 'millions'): {'of': 17}, ('loss', 'value'): {'the': 89, 'as': 5, 'smoothing': 3, 'probabilistically': 9, 'accurately': 12, 'a': 36, 'rapidly': 14, 'efficiently': 20, 'iteratively': 12, 'automatically': 13, 'gradually': 12, 'effectively': 15, 'recursively': 12, 'significantly': 11, 'statistically': 14, 'similarly': 2, 'successfully': 16, 'furthermore': 2, 'backpropagation': 4, 'in': 9, 'however': 3, 'gradient': 3, 'correctly': 13, 'word': 4, 'sequentially': 11, 'additionally': 3, 'continuously': 16, 'perplexity': 3, 'consequently': 4, 'transfer': 1, 'specifically': 6, 'training': 1, 'subsequently': 3, 'overfitting': 1, 'nevertheless': 2, 'feeding': 2, 'cross': 3, 'bigram': 1, 'tokenization': 2, 'data': 1, 'for': 1, 'moreover': 2}, ('system', 'recursively'): {'evaluates': 1, 'represents': 1, 'predicts': 2, 'reduces': 1, 'maximizes': 1, 'trains': 1}, ('function', 'maximizes'): {'millions': 1, 'the': 5, 'co-occurrence': 1, 'word': 1, 'large': 1}, ('transfer', 'learning'): {'allows': 104}, ('sequences', 'bigram'): {'and': 1}, ('states', 'nevertheless'): {'the': 1}, ('function', 'continuously'): {'furthermore': 1, 'outputs': 1, 'transfer': 1, 'in': 2, 'the': 9, 'adjusts': 1, 'predicts': 1, 'subsequently': 1, 'a': 2, 'overfitting': 1}, ('recursively', 'diverges'): {'token': 1, 'the': 4, 'statistical': 1, 'millions': 1}, ('matrices', 'similarly'): {'the': 3}, ('states', 'statistically'): {'the': 6, 'a': 6, 'consequently': 1, 'meanwhile': 1, 'data': 2, 'in': 1, 'as': 1}, ('correctly', 'reduces'): {'the': 4, 'statistical': 1, 'linguistic': 1}, ('mechanism', 'predicts'): {'word': 2, 'syntactic': 1, 'the': 9, 'linguistic': 1, 'sentence': 1, 'large': 1, 'co-occurrence': 1, 'millions': 1}, ('window', 'updates'): {'the': 5}, ('matrices', 'bigram'): {'and': 1}, ('patterns', 'moreover'): {'the': 8}, ('overfits', 'contextual'): {'information': 8}, ('frequencies', 'transfer'): {'learning': 2}, ('structure', 'accurately'): {'the': 8, 'bigram': 1, 'furthermore': 1, 'in': 1, 'however': 1}, ('correctly', 'training'): {'a': 2}, ('rate', 'a'): {'powerful': 3, 'recurrent': 2, 'lightweight': 1, 'language': 3, 'fine-tuned': 5, 'transformer-based': 4, 'neural': 3, 'efficient': 3, 'pre-trained': 2, 'large': 3, 'bidirectional': 1, 'shallow': 1, 'accurate': 4, 'deep': 1, 'discriminative': 4, 'statistical': 2, 'robust': 2, 'scalable': 1, 'small': 1, 'autoregressive': 1}, ('output', 'automatically'): {'overfitting': 2, 'cross': 1, 'the': 8, 'a': 2, 'perplexity': 1, 'predicts': 1, 'increases': 1, 'however': 1, 'similarly': 1}, ('correctly', 'therefore'): {'the': 10}, ('iteratively', 'diverges'): {'the': 3, 'semantic': 1, 'word': 2, 'large': 1, 'syntactic': 1}, ('sequence', 'represents'): {'statistical': 3, 'large': 1, 'the': 5, 'word': 2, 'contextual': 2, 'linguistic': 2, 'token': 1, 'co-occurrence': 1, 'syntactic': 1}, ('gradient', 'decodes'): {'co-occurrence': 2, 'the': 3, 'millions': 1, 'syntactic': 1, 'token': 1}, ('embeddings', 'meanwhile'): {'the': 3}, ('overfits', 'the'): {'bias': 10, 'loss': 14, 'training': 11, 'learning': 13, 'softmax': 10, 'probability': 13, 'weight': 10, 'vocabulary': 10, 'hidden': 14, 'next': 17, 'activation': 14, 'corpus': 10, 'batch': 8, 'cross': 12, 'gradient': 10}, ('tokenizes', 'millions'): {'of': 14}, ('significantly', 'furthermore'): {'the': 5, 'backpropagation': 1}, ('model', 'decodes'): {'contextual': 2, 'word': 2, 'the': 7, 'semantic': 1, 'syntactic': 1, 'co-occurrence': 1, 'large': 1, 'sentence': 1}, ('matrix', 'accurately'): {'consequently': 1, 'backpropagation': 1, 'a': 4, 'subsequently': 1, 'regularization': 1, 'the': 7, 'for': 1}, ('a', 'autoregressive'): {'the': 134, 'backpropagation': 4}, ('processes', 'contextual'): {'information': 15}, ('the', 'language'): {'model': 506}, ('continuously', 'increases'): {'sentence': 2, 'linguistic': 1, 'the': 2}, ('efficiently', 'adjusts'): {'co-occurrence': 1, 'millions': 2, 'the': 5, 'language': 1}, ('word', 'effectively'): {'data': 1, 'a': 6, 'the': 3}, ('information', 'recursively'): {'the': 7, 'data': 1, 'however': 1, 'additionally': 1, 'in': 1, 'a': 1, 'regularization': 1, 'similarly': 1, 'overfitting': 1}, ('improves', 'sentence'): {'structure': 11}, ('window', 'diverges'): {'millions': 1, 'large': 1, 'the': 5, 'contextual': 1, 'token': 1}, ('sequences', 'perplexity'): {'measures': 2}, ('gradient', 'trains'): {'on': 11}, ('processes', 'the'): {'learning': 10, 'gradient': 13, 'probability': 13, 'cross': 15, 'hidden': 12, 'corpus': 12, 'training': 14, 'loss': 12, 'weight': 9, 'vocabulary': 14, 'batch': 16, 'next': 11, 'activation': 11, 'softmax': 7, 'bias': 5}, ('statistical', 'language'): {'modeling': 110}, ('dataset', 'updates'): {'the': 2, 'co-occurrence': 1, 'statistical': 1}, ('context', 'window'): {'reduces': 8, 'correctly': 6, 'calculates': 5, 'optimizes': 9, 'determines': 90, 'probabilistically': 12, 'represents': 9, 'trains': 10, 'iteratively': 7, 'effectively': 8, 'continuously': 7, 'tokenizes': 9, 'automatically': 3, 'samples': 12, 'captures': 10, 'models': 8, 'efficiently': 10, 'successfully': 7, 'converges': 11, 'significantly': 9, 'generalizes': 16, 'overfits': 11, 'evaluates': 6, 'outputs': 7, 'minimizes': 11, 'diverges': 9, 'processes': 14, 'recursively': 6, 'rapidly': 7, 'improves': 6, 'sequentially': 6, 'encodes': 14, 'accurately': 8, 'adjusts': 15, 'decodes': 8, 'updates': 5, 'increases': 7, 'predicts': 18, 'computes': 10, 'fine-tunes': 13, 'gradually': 3, 'maximizes': 6, 'learns': 4, 'statistically': 5, 'generates': 6}, ('vocabulary', 'recursively'): {'improves': 1, 'learns': 1, 'computes': 1, 'fine-tunes': 1, 'adjusts': 1}, ('tokenizer', 'probabilistically'): {'optimizes': 1, 'reduces': 1, 'predicts': 1, 'minimizes': 1, 'decodes': 1, 'improves': 1, 'models': 1}, ('output', 'transfer'): {'learning': 1}, ('rapidly', 'similarly'): {'the': 4, 'backpropagation': 1}, ('structure', 'data'): {'preprocessing': 2}, ('rules', 'cross'): {'entropy': 2}, ('iteratively', 'converges'): {'token': 1, 'semantic': 1, 'word': 1, 'linguistic': 2}, ('bigram', 'generalizes'): {'the': 4, 'large': 2, 'linguistic': 1}, ('continuously', 'optimizes'): {'contextual': 1, 'word': 1, 'syntactic': 1, 'the': 3}, ('model', 'trains'): {'on': 17}, ('matrices', 'perplexity'): {'measures': 2}, ('algorithm', 'evaluates'): {'the': 3, 'semantic': 1, 'token': 1}, ('probabilistically', 'consequently'): {'the': 2, 'backpropagation': 1}, ('successfully', 'cleaning'): {'and': 1}, ('generalizes', 'syntactic'): {'rules': 13}, ('computational', 'resources'): {'the': 58, 'a': 24, 'similarly': 2, 'specifically': 5, 'backpropagation': 2, 'additionally': 3, 'in': 2, 'subsequently': 3, 'however': 1, 'therefore': 4, 'as': 2, 'moreover': 1, 'for': 2}, ('rate', 'gradually'): {'additionally': 1, 'the': 7, 'for': 2, 'meanwhile': 1, 'bigram': 1, 'a': 1, 'perplexity': 1}, ('maximizes', 'sentence'): {'structure': 8}, ('frequencies', 'in'): {'addition': 5, 'contrast': 1}, ('efficient', 'backpropagation'): {'outputs': 1, 'trains': 1, 'diverges': 1}, ('gradient', 'models'): {'word': 1, 'the': 4, 'linguistic': 1, 'statistical': 1, 'contextual': 1, 'sentence': 1}, ('pipeline', 'specifically'): {'the': 3}, ('converges', 'token'): {'sequences': 18}, ('frequencies', 'rapidly'): {'nevertheless': 2, 'a': 2, 'feeding': 1, 'the': 3, 'overfitting': 1}, ('models', 'linguistic'): {'features': 10}, ('n-gram', 'sequentially'): {'improves': 1, 'generates': 1, 'evaluates': 1, 'encodes': 1, 'models': 1}, ('text', 'reduces'): {'the': 6, 'co-occurrence': 3, 'large': 1}, ('backpropagation', 'generalizes'): {'statistical': 2, 'the': 8, 'linguistic': 1}, ('model', 'models'): {'large': 2, 'semantic': 1, 'the': 12, 'statistical': 1, 'syntactic': 1}, ('descent', 'nevertheless'): {'the': 2}, ('diverges', 'token'): {'sequences': 9}, ('weight', 'maximizes'): {'the': 6, 'word': 1, 'semantic': 1, 'token': 1}, ('data', 'probabilistically'): {'the': 6, 'specifically': 1, 'however': 1, 'nevertheless': 1, 'feeding': 1}, ('architecture', 'automatically'): {'samples': 1, 'converges': 1, 'represents': 1, 'fine-tunes': 2, 'learns': 1, 'generates': 1}, ('adjusts', 'statistical'): {'patterns': 13}, ('weight', 'continuously'): {'diverges': 1, 'models': 1, 'converges': 1, 'tokenizes': 1, 'learns': 1}, ('embeddings', 'iteratively'): {'the': 6, 'a': 2, 'regularization': 1, 'as': 1, 'furthermore': 1, 'gradient': 1}, ('efficiently', 'fine-tunes'): {'the': 3}, ('rate', 'similarly'): {'the': 7}, ('automatically', 'encodes'): {'the': 7, 'sentence': 1, 'language': 1}, ('optimizer', 'reduces'): {'the': 5, 'millions': 2, 'contextual': 1, 'word': 2, 'statistical': 1, 'linguistic': 1}, ('frequencies', 'however'): {'the': 3}, ('minimizes', 'statistical'): {'patterns': 5}, ('rate', 'bigram'): {'and': 1}, ('descent', 'significantly'): {'the': 10, 'additionally': 3, 'a': 2, 'overfitting': 1, 'similarly': 2, 'moreover': 1, 'nevertheless': 1, 'meanwhile': 1}, ('output', 'in'): {'contrast': 1, 'addition': 5}, ('trigram', 'converges'): {'large': 1, 'the': 7, 'semantic': 1, 'statistical': 1, 'token': 1, 'millions': 2}, ('features', 'word'): {'embeddings': 1}, ('backpropagation', 'converges'): {'linguistic': 1, 'the': 3, 'syntactic': 1, 'word': 1}, ('output', 'rapidly'): {'a': 2, 'the': 9, 'optimizes': 1, 'reduces': 1, 'computes': 1, 'represents': 1, 'generalizes': 1, 'tokenization': 1, 'captures': 1, 'processes': 1, 'data': 1, 'predicts': 1, 'gradient': 1, 'moreover': 1, 'increases': 1, 'furthermore': 1, 'generates': 1}, ('researcher', 'represents'): {'the': 7, 'token': 2, 'contextual': 1, 'linguistic': 1, 'semantic': 2}, ('value', 'iteratively'): {'meanwhile': 2, 'the': 5, 'a': 2, 'nevertheless': 1, 'specifically': 1, 'for': 1}, ('automatically', 'minimizes'): {'the': 1}, ('weight', 'captures'): {'semantic': 1, 'the': 5, 'linguistic': 1, 'language': 1, 'syntactic': 1, 'contextual': 1, 'millions': 1, 'sentence': 1, 'large': 1}, ('statistically', 'computes'): {'the': 6, 'contextual': 1, 'semantic': 1}, ('into', 'meaningful'): {'units': 82}, ('the', 'attention'): {'mechanism': 354}, ('on', 'language'): {'patterns': 12}, ('frequencies', 'statistically'): {'the': 5, 'a': 6, 'overfitting': 1, 'gradient': 1}, ('sequentially', 'bigram'): {'and': 1}, ('successfully', 'additionally'): {'the': 2}, ('bigram', 'samples'): {'the': 5, 'word': 1}, ('sequence', 'gradually'): {'generates': 2, 'increases': 2, 'converges': 1, 'computes': 1}, ('to', 'sequences'): {'of': 93}, ('process', 'evaluates'): {'the': 4, 'statistical': 1, 'sentence': 1, 'word': 2}, ('dataset', 'correctly'): {'optimizes': 1, 'maximizes': 1}, ('fine-tunes', 'statistical'): {'patterns': 12}, ('splitting', 'raw'): {'text': 82}, ('captures', 'statistical'): {'patterns': 5}, ('corpus', 'processes'): {'language': 1, 'contextual': 1, 'the': 3, 'linguistic': 1}, ('result', 'backpropagation'): {'generates': 1, 'computes': 1, 'reduces': 1}, ('structure', 'probabilistically'): {'the': 5, 'however': 1, 'a': 4, 'in': 2}, ('statistical', 'backpropagation'): {'captures': 1, 'maximizes': 1, 'processes': 1, 'calculates': 1, 'decodes': 1}, ('architecture', 'processes'): {'word': 2, 'the': 2, 'sentence': 1, 'token': 1, 'linguistic': 1}, ('continuously', 'cleaning'): {'and': 2}, ('output', 'however'): {'the': 2}, ('datasets', 'and'): {'sufficient': 109}, ('network', 'evaluates'): {'the': 4, 'statistical': 1, 'word': 1, 'sentence': 1, 'semantic': 2, 'millions': 1, 'co-occurrence': 1}, ('probabilistically', 'specifically'): {'the': 2, 'backpropagation': 1}, ('perplexity', 'reduces'): {'the': 2, 'syntactic': 1, 'contextual': 1, 'linguistic': 1}, ('efficiently', 'as'): {'a': 18}, ('tokenizer', 'represents'): {'the': 8, 'sentence': 1}, ('algorithm', 'increases'): {'millions': 1, 'contextual': 1, 'the': 2, 'large': 1}, ('function', 'diverges'): {'the': 5, 'token': 1, 'contextual': 2}, ('perplexity', 'tokenizes'): {'the': 6, 'language': 1}, ('matrix', 'probabilistically'): {'regularization': 1, 'a': 2, 'the': 9}, ('bigram', 'improves'): {'the': 7, 'millions': 1, 'statistical': 2, 'token': 1}, ('bigram', 'overfits'): {'word': 2, 'the': 5}, ('the', 'vocabulary'): {'size': 481, 'overfits': 14, 'converges': 9, 'tokenizes': 9, 'improves': 8, 'represents': 6, 'generalizes': 6, 'maximizes': 6, 'adjusts': 8, 'increases': 14, 'optimizes': 10, 'diverges': 10, 'encodes': 7, 'successfully': 3, 'generates': 9, 'models': 6, 'gradually': 5, 'significantly': 7, 'decodes': 9, 'outputs': 11, 'automatically': 8, 'correctly': 7, 'updates': 10, 'efficiently': 10, 'trains': 7, 'processes': 6, 'captures': 8, 'samples': 10, 'computes': 12, 'calculates': 13, 'probabilistically': 5, 'learns': 14, 'predicts': 18, 'recursively': 5, 'fine-tunes': 9, 'reduces': 10, 'accurately': 6, 'statistically': 4, 'effectively': 5, 'evaluates': 4, 'rapidly': 5, 'sequentially': 4, 'minimizes': 4, 'iteratively': 1, 'continuously': 2}, ('prediction', 'evaluates'): {'the': 5, 'contextual': 3, 'large': 1}, ('efficiently', 'for'): {'example': 10}, ('output', 'statistically'): {'furthermore': 2, 'a': 4, 'the': 6, 'backpropagation': 1, 'therefore': 1, 'generates': 1, 'perplexity': 1, 'learns': 1, 'adjusts': 1, 'tokenization': 2, 'overfitting': 1, 'updates': 1, 'trains': 1, 'smoothing': 1, 'gradient': 1, 'as': 1}, ('embeddings', 'in'): {'addition': 4, 'contrast': 2}, ('rules', 'subsequently'): {'the': 2}, ('embeddings', 'rapidly'): {'however': 1, 'a': 5, 'the': 3, 'moreover': 1, 'meanwhile': 1, 'transfer': 1, 'perplexity': 1}, ('improves', 'language'): {'patterns': 10}, ('algorithm', 'optimizes'): {'the': 1, 'statistical': 1, 'millions': 2, 'co-occurrence': 1}, ('sequentially', 'perplexity'): {'measures': 5}, ('sequences', 'cross'): {'entropy': 2}, ('algorithm', 'iteratively'): {'updates': 1}, ('space', 'however'): {'the': 3}, ('automatically', 'smoothing'): {'techniques': 4}, ('mechanism', 'processes'): {'the': 9, 'linguistic': 1, 'token': 1}, ('iteratively', 'predicts'): {'the': 5, 'sentence': 2, 'statistical': 2, 'syntactic': 1, 'co-occurrence': 1}, ('sequentially', 'calculates'): {'the': 2}, ('n-gram', 'encodes'): {'sentence': 1, 'millions': 2, 'the': 5, 'semantic': 1, 'linguistic': 1}, ('backpropagation', 'overfits'): {'the': 3, 'word': 1}, ('similarly', 'backpropagation'): {'optimizes': 1, 'generates': 1, 'represents': 1, 'decodes': 1, 'maximizes': 1, 'learns': 1}, ('correctly', 'furthermore'): {'the': 6}, ('gracefully', 'a'): {'accurate': 2, 'lightweight': 2, 'generative': 3, 'autoregressive': 2, 'recurrent': 2, 'deep': 2, 'large': 1, 'shallow': 2, 'transformer-based': 2, 'small': 2, 'fine-tuned': 1}, ('effectively', 'decodes'): {'the': 4, 'word': 1, 'large': 1, 'millions': 1}, ('function', 'converges'): {'millions': 1, 'semantic': 2, 'statistical': 2, 'the': 5, 'syntactic': 1, 'language': 1, 'large': 1, 'sentence': 1}, ('resources', 'therefore'): {'the': 4}, ('meaning', 'bigram'): {'and': 2}, ('continuously', 'additionally'): {'the': 5}, ('n-gram', 'minimizes'): {'contextual': 1, 'the': 6, 'language': 1, 'millions': 1, 'semantic': 1, 'sentence': 1, 'linguistic': 1}, ('evaluates', 'word'): {'frequencies': 16, 'embeddings': 12}, ('window', 'predicts'): {'statistical': 1, 'sentence': 2, 'the': 9, 'semantic': 2, 'large': 1, 'token': 2, 'syntactic': 1}, ('efficiently', 'tokenization'): {'is': 1}, ('distribution', 'consequently'): {'the': 7}, ('system', 'decodes'): {'linguistic': 1, 'the': 5, 'statistical': 1, 'semantic': 1, 'contextual': 1, 'word': 3, 'large': 2, 'token': 1}, ('meaning', 'iteratively'): {'the': 7, 'smoothing': 1, 'a': 3, 'therefore': 1, 'subsequently': 1}, ('frequencies', 'moreover'): {'the': 3}, ('significantly', 'evaluates'): {'the': 2, 'word': 1, 'linguistic': 1}, ('accurately', 'however'): {'the': 2}, ('effectively', 'trains'): {'on': 5}, ('researcher', 'gradually'): {'maximizes': 1, 'generates': 1, 'calculates': 1, 'reduces': 1, 'processes': 1, 'tokenizes': 1, 'overfits': 1}, ('recursively', 'word'): {'embeddings': 2}, ('corpus', 'nevertheless'): {'the': 4}, ('continuously', 'cross'): {'entropy': 6}, ('automatically', 'regularization'): {'techniques': 2}, ('rules', 'efficiently'): {'the': 5, 'a': 4, 'data': 1, 'furthermore': 1, 'bigram': 1, 'therefore': 1}, ('adjusts', 'word'): {'frequencies': 12, 'embeddings': 13}, ('process', 'increases'): {'syntactic': 1, 'co-occurrence': 1, 'the': 4, 'millions': 2}, ('transformer-based', 'the'): {'context': 4, 'n-gram': 5, 'optimizer': 6, 'embedding': 4, 'sequence': 3, 'language': 8, 'attention': 5, 'weight': 6, 'perplexity': 5, 'corpus': 4, 'input': 6, 'neural': 3, 'text': 5, 'loss': 6, 'trigram': 6, 'tokenizer': 7, 'bigram': 4, 'gradient': 4, 'output': 2, 'dataset': 2, 'prediction': 5, 'training': 3, 'vocabulary': 2, 'researcher': 3, 'architecture': 2, 'system': 5, 'evaluation': 6, 'algorithm': 3, 'probability': 3}, ('sequence', 'calculates'): {'the': 6, 'contextual': 1, 'statistical': 1, 'sentence': 1, 'syntactic': 1}, ('efficiently', 'gradient'): {'descent': 3}, ('embeddings', 'additionally'): {'the': 4}, ('trigram', 'predicts'): {'the': 6, 'linguistic': 2, 'co-occurrence': 1, 'language': 1, 'large': 1, 'semantic': 2, 'sentence': 1}, ('word', 'meanwhile'): {'the': 3}, ('effectively', 'models'): {'the': 1, 'language': 2, 'statistical': 1}, ('patterns', 'training'): {'a': 3}, ('pre-trained', 'backpropagation'): {'minimizes': 1, 'decodes': 1, 'increases': 1, 'reduces': 1}, ('meaning', 'perplexity'): {'measures': 6}, ('process', 'optimizes'): {'the': 5, 'millions': 1, 'token': 1, 'statistical': 1}, ('loss', 'bigram'): {'and': 4}, ('recursively', 'feeding'): {'diverse': 2}, ('data', 'a'): {'efficient': 2, 'powerful': 3, 'pre-trained': 3, 'shallow': 4, 'autoregressive': 3, 'transformer-based': 1, 'accurate': 2, 'fine-tuned': 1, 'neural': 4, 'generative': 4, 'recurrent': 3, 'robust': 2, 'bidirectional': 3, 'lightweight': 5, 'small': 1, 'statistical': 1, 'deep': 1, 'large': 1}, ('process', 'iteratively'): {'minimizes': 1, 'diverges': 1, 'fine-tunes': 1, 'adjusts': 1, 'predicts': 1, 'captures': 1, 'decodes': 1}, ('descent', 'word'): {'embeddings': 1}, ('corpus', 'significantly'): {'outputs': 2, 'models': 2, 'the': 8, 'as': 1, 'moreover': 1, 'converges': 1, 'captures': 1, 'meanwhile': 1, 'fine-tunes': 1, 'diverges': 1, 'encodes': 1, 'a': 2, 'samples': 1, 'tokenization': 1, 'training': 1}, ('architecture', 'significantly'): {'predicts': 2, 'learns': 1, 'encodes': 1, 'diverges': 1, 'decodes': 1}, ('output', 'moreover'): {'backpropagation': 1, 'the': 2}, ('from', 'statistical'): {'patterns': 16}, ('network', 'optimizes'): {'statistical': 1, 'semantic': 1, 'millions': 2, 'the': 1}, ('prediction', 'increases'): {'the': 4, 'token': 1, 'statistical': 1, 'word': 1, 'large': 1}, ('rules', 'as'): {'a': 4}, ('efficiently', 'learns'): {'from': 11}, ('nevertheless', 'backpropagation'): {'decodes': 2, 'reduces': 1, 'processes': 1, 'predicts': 1, 'trains': 1, 'computes': 1, 'generalizes': 1}, ('input', 'computes'): {'semantic': 1, 'the': 4, 'co-occurrence': 1}, ('significantly', 'meanwhile'): {'the': 8}, ('network', 'iteratively'): {'predicts': 1, 'minimizes': 1, 'generalizes': 1, 'samples': 1}, ('efficiently', 'generates'): {'statistical': 1, 'the': 4, 'token': 1, 'language': 1, 'word': 1, 'millions': 1}, ('gradually', 'bigram'): {'and': 3}, ('system', 'models'): {'the': 4, 'sentence': 1, 'token': 1, 'syntactic': 1, 'word': 1, 'language': 1}, ('loss', 'iteratively'): {'the': 6, 'additionally': 1, 'a': 3, 'specifically': 1, 'tokenization': 1, 'nevertheless': 1, 'transfer': 1, 'meanwhile': 1}, ('n-gram', 'computes'): {'the': 8, 'word': 1, 'statistical': 1}, ('tokenizer', 'gradually'): {'diverges': 1, 'minimizes': 1, 'models': 1, 'represents': 1, 'encodes': 1, 'outputs': 1}, ('text', 'furthermore'): {'the': 9}, ('value', 'additionally'): {'the': 3}, ('sequentially', 'outputs'): {'the': 3, 'millions': 1, 'word': 1, 'sentence': 1}, ('rules', 'for'): {'example': 3}, ('metric', 'correctly'): {'calculates': 1, 'evaluates': 1, 'generalizes': 1, 'increases': 2, 'fine-tunes': 1, 'tokenizes': 1}, ('predicts', 'contextual'): {'information': 25}, ('lightweight', 'the'): {'system': 7, 'researcher': 5, 'text': 10, 'neural': 6, 'probability': 2, 'embedding': 6, 'attention': 9, 'sequence': 10, 'bigram': 7, 'algorithm': 2, 'perplexity': 4, 'weight': 4, 'optimizer': 5, 'loss': 3, 'tokenizer': 9, 'vocabulary': 4, 'n-gram': 7, 'gradient': 5, 'context': 5, 'training': 2, 'dataset': 3, 'corpus': 4, 'trigram': 6, 'input': 5, 'language': 5, 'prediction': 3, 'architecture': 3, 'output': 2, 'evaluation': 1}, ('gracefully', 'similarly'): {'the': 1}, ('prediction', 'optimizes'): {'co-occurrence': 1, 'language': 1, 'the': 3, 'semantic': 1, 'linguistic': 1}, ('distribution', 'subsequently'): {'the': 3}, ('prediction', 'iteratively'): {'decodes': 1, 'represents': 1, 'models': 1, 'captures': 2, 'generates': 1, 'calculates': 1, 'fine-tunes': 1, 'improves': 1, 'reduces': 1}, ('value', 'cross'): {'entropy': 3}, ('weight', 'converges'): {'the': 7, 'syntactic': 1, 'contextual': 1}, ('models', 'semantic'): {'meaning': 18}, ('mechanism', 'significantly'): {'fine-tunes': 1, 'generates': 1, 'minimizes': 1, 'overfits': 1, 'encodes': 1, 'diverges': 1}, ('space', 'moreover'): {'the': 1}, ('probabilistically', 'encodes'): {'the': 3, 'word': 1, 'co-occurrence': 1}, ('text', 'effectively'): {'nevertheless': 1, 'training': 1, 'the': 6, 'consequently': 1, 'meanwhile': 1, 'a': 3, 'data': 1, 'overfits': 1, 'fine-tunes': 1, 'tokenization': 1, 'improves': 1, 'outputs': 1, 'word': 1}, ('rapidly', 'consequently'): {'the': 6}, ('features', 'continuously'): {'the': 7, 'tokenization': 1, 'a': 4, 'word': 1, 'furthermore': 1, 'in': 1, 'consequently': 1, 'additionally': 1}, ('meaning', 'cleaning'): {'and': 1}, ('distribution', 'specifically'): {'the': 2}, ('data', 'gradually'): {'the': 3, 'in': 2, 'tokenization': 1, 'meanwhile': 2, 'a': 1, 'furthermore': 1, 'specifically': 1}, ('system', 'sequentially'): {'generates': 1, 'fine-tunes': 2, 'calculates': 1, 'predicts': 1, 'increases': 1}, ('gradient', 'maximizes'): {'the': 3, 'syntactic': 1, 'semantic': 1, 'sentence': 1}, ('adjusts', 'linguistic'): {'features': 14}, ('increases', 'sentence'): {'structure': 14}, ('sequence', 'outputs'): {'the': 6, 'co-occurrence': 1, 'millions': 1, 'contextual': 1}, ('sequentially', 'cross'): {'entropy': 3}, ('significantly', 'increases'): {'the': 7, 'syntactic': 2, 'sentence': 1, 'statistical': 1, 'millions': 1}, ('gradient', 'continuously'): {'represents': 2, 'maximizes': 1, 'overfits': 1, 'encodes': 1}, ('embeddings', 'moreover'): {'the': 2, 'backpropagation': 1}, ('matrices', 'subsequently'): {'the': 2, 'backpropagation': 1}, ('rules', 'tokenization'): {'is': 1}, ('optimizer', 'effectively'): {'predicts': 2, 'tokenizes': 2}, ('gradually', 'perplexity'): {'measures': 5}, ('model', 'maximizes'): {'the': 11, 'token': 1, 'linguistic': 1, 'sentence': 1, 'contextual': 1, 'syntactic': 1, 'co-occurrence': 3, 'large': 1, 'millions': 1}, ('automatically', 'updates'): {'semantic': 1, 'the': 4, 'sentence': 1, 'syntactic': 1, 'co-occurrence': 1}, ('word', 'iteratively'): {'the': 6, 'a': 4, 'meanwhile': 2, 'backpropagation': 1, 'subsequently': 1, 'nevertheless': 1, 'in': 1, 'regularization': 1}, ('minimizes', 'linguistic'): {'features': 9}, ('model', 'continuously'): {'evaluates': 1, 'encodes': 2, 'adjusts': 1, 'improves': 2, 'generalizes': 1, 'trains': 1, 'calculates': 1, 'diverges': 1, 'decodes': 1}, ('function', 'predicts'): {'the': 19, 'language': 1, 'sentence': 1, 'token': 1, 'word': 1, 'statistical': 1, 'semantic': 1}, ('gradually', 'calculates'): {'semantic': 1, 'contextual': 1, 'syntactic': 1, 'millions': 1, 'the': 1}, ('significantly', 'optimizes'): {'contextual': 1, 'sentence': 1, 'the': 2, 'linguistic': 1}, ('text', 'samples'): {'semantic': 1, 'the': 8, 'linguistic': 1, 'large': 1}, ('word', 'transfer'): {'learning': 2}, ('accurately', 'moreover'): {'the': 4}, ('data', 'similarly'): {'the': 2}, ('n-gram', 'successfully'): {'overfits': 2, 'outputs': 1}, ('a', 'large'): {'the': 122, 'backpropagation': 3}, ('computes', 'statistical'): {'patterns': 8}, ('gradient', 'captures'): {'the': 5, 'syntactic': 1, 'word': 1, 'millions': 2}, ('encodes', 'millions'): {'of': 15}, ('data', 'bigram'): {'and': 2}, ('bigram', 'automatically'): {'represents': 1, 'optimizes': 1}, ('rate', 'consequently'): {'the': 3}, ('autoregressive', 'backpropagation'): {'evaluates': 1, 'computes': 1, 'increases': 1, 'generates': 1}, ('fine-tuned', 'the'): {'gradient': 6, 'probability': 3, 'dataset': 2, 'vocabulary': 3, 'n-gram': 2, 'architecture': 2, 'language': 9, 'training': 5, 'text': 8, 'output': 3, 'embedding': 4, 'sequence': 6, 'input': 5, 'tokenizer': 5, 'evaluation': 5, 'trigram': 5, 'weight': 9, 'perplexity': 5, 'algorithm': 4, 'loss': 4, 'bigram': 2, 'researcher': 3, 'attention': 4, 'corpus': 9, 'prediction': 4, 'context': 4, 'optimizer': 3, 'neural': 2, 'system': 1}, ('dataset', 'recursively'): {'increases': 1, 'samples': 2, 'predicts': 1, 'tokenizes': 1, 'overfits': 1}, ('loss', 'cleaning'): {'and': 1}, ('captures', 'linguistic'): {'features': 15}, ('sequences', 'efficiently'): {'the': 5, 'a': 3, 'additionally': 1, 'backpropagation': 1, 'transfer': 1, 'regularization': 1}, ('structure', 'gradually'): {'the': 14, 'as': 1, 'cross': 1, 'meanwhile': 1, 'transfer': 1, 'a': 2}, ('automatically', 'diverges'): {'the': 1, 'large': 1}, ('mechanism', 'trains'): {'on': 7}, ('information', 'sequentially'): {'a': 5, 'specifically': 1, 'the': 7, 'smoothing': 1}, ('layer', 'generalizes'): {'the': 8, 'syntactic': 1, 'word': 1, 'language': 1, 'co-occurrence': 1, 'sentence': 1}, ('size', 'correctly'): {'the': 11, 'as': 2, 'however': 1, 'cross': 2, 'a': 7, 'word': 1, 'meanwhile': 1, 'additionally': 1, 'similarly': 1, 'moreover': 1, 'perplexity': 1, 'transfer': 1}, ('meaning', 'additionally'): {'backpropagation': 1, 'the': 3}, ('iteratively', 'processes'): {'the': 2}, ('vocabulary', 'sequentially'): {'optimizes': 1, 'evaluates': 1, 'fine-tunes': 1, 'updates': 1}, ('rapidly', 'subsequently'): {'the': 9}, ('tokenizer', 'calculates'): {'sentence': 1, 'linguistic': 1, 'word': 1, 'syntactic': 1, 'the': 4, 'co-occurrence': 1}, ('text', 'improves'): {'the': 2, 'contextual': 1, 'statistical': 1, 'linguistic': 1, 'word': 2, 'token': 1}, ('backpropagation', 'automatically'): {'encodes': 1, 'increases': 1}, ('probabilistically', 'computes'): {'the': 6, 'millions': 1, 'word': 1, 'syntactic': 1}, ('matrix', 'gradually'): {'gradient': 1, 'the': 6, 'for': 1, 'as': 1, 'similarly': 1, 'nevertheless': 1}, ('terms', 'correctly'): {'a': 3, 'the': 4, 'in': 1}, ('correctly', 'evaluates'): {'millions': 2, 'statistical': 1, 'the': 2, 'co-occurrence': 2, 'linguistic': 1, 'semantic': 1}, ('mechanism', 'models'): {'the': 8, 'language': 2, 'word': 2, 'sentence': 2}, ('modeling', 'the'): {'input': 5, 'n-gram': 2, 'optimizer': 1, 'tokenizer': 3, 'bigram': 1, 'trigram': 3, 'sequence': 3, 'weight': 3, 'model': 3, 'system': 2, 'neural': 3, 'language': 1, 'researcher': 3, 'evaluation': 2, 'perplexity': 1, 'dataset': 1, 'training': 3, 'embedding': 1, 'corpus': 1, 'vocabulary': 2, 'algorithm': 1, 'gradient': 1}, ('rapidly', 'specifically'): {'the': 6}, ('any', 'language'): {'model': 99}, ('sequences', 'as'): {'a': 3}, ('structure', 'similarly'): {'the': 2}, ('window', 'processes'): {'the': 6, 'large': 1, 'sentence': 2, 'language': 1, 'syntactic': 2, 'word': 1, 'semantic': 1}, ('network', 'outputs'): {'statistical': 1, 'language': 1, 'the': 2, 'large': 3, 'millions': 1, 'word': 1, 'contextual': 1}, ('outputs', 'large'): {'amounts': 14}, ('word', 'in'): {'contrast': 5, 'addition': 4}, ('predicts', 'token'): {'sequences': 21}, ('data', 'perplexity'): {'measures': 3}, ('corpus', 'word'): {'embeddings': 1}, ('sequences', 'for'): {'example': 2}, ('word', 'rapidly'): {'the': 3, 'a': 2, 'specifically': 1, 'therefore': 1}, ('overfits', 'statistical'): {'patterns': 6}, ('loss', 'penalizes'): {'the': 111}, ('word', 'cleaning'): {'and': 4}, ('ability', 'furthermore'): {'the': 1}, ('matrix', 'similarly'): {'the': 3}, ('gradually', 'outputs'): {'the': 3}, ('prediction', 'outputs'): {'the': 7}, ('n-gram', 'updates'): {'the': 4, 'syntactic': 1, 'contextual': 1, 'word': 2, 'large': 1, 'semantic': 1, 'co-occurrence': 1}, ('probability', 'sequentially'): {'reduces': 1, 'models': 1, 'processes': 1, 'fine-tunes': 1, 'tokenizes': 1, 'maximizes': 1, 'captures': 1, 'learns': 1}, ('correct', 'words'): {'the': 50, 'a': 23, 'in': 10, 'specifically': 3, 'consequently': 1, 'meanwhile': 4, 'as': 5, 'subsequently': 5, 'however': 1, 'nevertheless': 4, 'moreover': 3, 'additionally': 1, 'for': 1}, ('matrices', 'for'): {'example': 6}, ('rate', 'subsequently'): {'the': 3}, ('models', 'contextual'): {'information': 19}, ('system', 'encodes'): {'sentence': 2, 'word': 3, 'co-occurrence': 1, 'millions': 1, 'the': 3, 'token': 1}, ('matrix', 'bigram'): {'and': 1}, ('is', 'the'): {'process': 82, 'optimization': 94}, ('reduces', 'word'): {'frequencies': 20, 'embeddings': 13}, ('trigram', 'processes'): {'the': 4, 'co-occurrence': 1, 'token': 1}, ('significantly', 'cleaning'): {'and': 3}, ('probabilistically', 'regularization'): {'techniques': 3}, ('weight', 'predicts'): {'the': 10, 'syntactic': 2, 'sentence': 1, 'token': 1, 'language': 2, 'contextual': 1, 'co-occurrence': 1, 'semantic': 1}, ('processes', 'statistical'): {'patterns': 11}, ('correctly', 'meanwhile'): {'the': 10}, ('models', 'the'): {'activation': 16, 'bias': 13, 'probability': 13, 'batch': 19, 'learning': 13, 'weight': 14, 'vocabulary': 16, 'loss': 19, 'softmax': 13, 'corpus': 11, 'training': 13, 'gradient': 9, 'next': 12, 'cross': 11, 'hidden': 15}, ('decodes', 'word'): {'frequencies': 11, 'embeddings': 16}, ('patterns', 'furthermore'): {'the': 13, 'backpropagation': 1}, ('layer', 'samples'): {'the': 1, 'statistical': 1, 'co-occurrence': 1, 'semantic': 1}, ('sequentially', 'subsequently'): {'the': 8}, ('prediction', 'additionally'): {'the': 2}, ('successfully', 'gradient'): {'descent': 3}, ('evaluates', 'co-occurrence'): {'matrices': 20}, ('system', 'minimizes'): {'the': 8, 'syntactic': 2, 'word': 1, 'statistical': 2}, ('loss', 'cross'): {'entropy': 4}, ('errors', 'additionally'): {'the': 4}, ('successfully', 'tokenizes'): {'the': 4, 'word': 1, 'co-occurrence': 1}, ('successfully', 'therefore'): {'the': 5}, ('increases', 'language'): {'patterns': 12}, ('sequences', 'tokenization'): {'is': 2}, ('continuously', 'for'): {'example': 7}, ('n-gram', 'diverges'): {'millions': 2, 'the': 4, 'sentence': 1, 'statistical': 1, 'word': 1}, ('bigram', 'rapidly'): {'converges': 1, 'diverges': 1, 'tokenizes': 1, 'evaluates': 2, 'fine-tunes': 1}, ('sequence', 'adjusts'): {'large': 1, 'the': 1, 'syntactic': 2, 'co-occurrence': 1, 'linguistic': 1, 'contextual': 1}, ('structure', 'perplexity'): {'measures': 1}, ('tokenizer', 'outputs'): {'the': 4, 'statistical': 1, 'semantic': 1}, ('iteratively', 'nevertheless'): {'the': 5}, ('calculates', 'sentence'): {'structure': 19}, ('statistically', 'backpropagation'): {'correctly': 1, 'rapidly': 1, 'reduces': 1, 'improves': 1, 'predicts': 1}, ('gradually', 'cross'): {'entropy': 5}, ('deep', 'backpropagation'): {'improves': 1}, ('effectively', 'overfitting'): {'occurs': 3}, ('text', 'evaluates'): {'the': 6, 'language': 1, 'statistical': 1, 'co-occurrence': 1, 'word': 1}, ('iteratively', 'based'): {'on': 104}, ('patterns', 'effectively'): {'the': 16, 'cleaning': 1, 'a': 1, 'additionally': 1, 'word': 2, 'in': 1, 'therefore': 1, 'moreover': 1, 'furthermore': 1, 'specifically': 1}, ('parameters', 'nevertheless'): {'the': 5}, ('sequentially', 'fine-tunes'): {'the': 6, 'co-occurrence': 1, 'contextual': 1, 'word': 1}, ('successfully', 'learns'): {'from': 9}, ('frequencies', 'therefore'): {'the': 2}, ('successfully', 'generates'): {'the': 2, 'millions': 1, 'co-occurrence': 1, 'syntactic': 1, 'statistical': 1}, ('tokenizes', 'word'): {'frequencies': 9, 'embeddings': 13}, ('sequences', 'gradient'): {'descent': 1}, ('layer', 'improves'): {'semantic': 1, 'word': 2, 'the': 7, 'contextual': 1, 'token': 1, 'language': 1}, ('matrix', 'perplexity'): {'measures': 1}, ('layer', 'overfits'): {'the': 3, 'statistical': 1, 'contextual': 1, 'word': 2, 'sentence': 1}, ('word', 'additionally'): {'the': 1}, ('from', 'linguistic'): {'features': 13}, ('vocabulary', 'encodes'): {'the': 3, 'large': 2, 'language': 1, 'contextual': 1}, ('optimizer', 'evaluates'): {'the': 3, 'language': 1, 'token': 1}, ('terms', 'backpropagation'): {'fine-tunes': 1}, ('correctly', 'increases'): {'the': 3, 'large': 2, 'word': 1, 'contextual': 1, 'language': 1}, ('effectively', 'smoothing'): {'techniques': 4}, ('effectively', 'maximizes'): {'the': 2, 'semantic': 1}, ('parameters', 'significantly'): {'the': 6, 'a': 4, 'consequently': 2, 'transfer': 1, 'word': 1, 'in': 2, 'meanwhile': 1, 'nevertheless': 1}, ('addition', 'the'): {'language': 9, 'trigram': 5, 'embedding': 5, 'probability': 7, 'n-gram': 8, 'bigram': 8, 'loss': 5, 'neural': 7, 'researcher': 7, 'corpus': 5, 'weight': 9, 'prediction': 5, 'perplexity': 7, 'input': 7, 'training': 4, 'text': 3, 'tokenizer': 6, 'attention': 4, 'system': 4, 'optimizer': 7, 'output': 6, 'algorithm': 9, 'dataset': 7, 'architecture': 3, 'context': 4, 'evaluation': 8, 'vocabulary': 2, 'sequence': 4, 'gradient': 6, 'model': 4}, ('significantly', 'additionally'): {'the': 8}, ('optimizes', 'large'): {'amounts': 15}, ('recursively', 'decodes'): {'the': 2}, ('input', 'correctly'): {'encodes': 1, 'predicts': 1, 'optimizes': 2, 'processes': 1}, ('metric', 'recursively'): {'learns': 1, 'models': 1, 'generates': 1, 'maximizes': 1, 'trains': 1}, ('output', 'reduces'): {'linguistic': 2, 'the': 6, 'millions': 1, 'semantic': 1, 'co-occurrence': 1, 'contextual': 1}, ('continuously', 'tokenization'): {'is': 6}, ('vocabulary', 'minimizes'): {'the': 4}, ('bigram', 'statistically'): {'generates': 1, 'decodes': 1, 'generalizes': 1}, ('output', 'training'): {'a': 2}, ('correctly', 'optimizes'): {'the': 3, 'statistical': 1, 'co-occurrence': 1}, ('window', 'significantly'): {'maximizes': 2, 'predicts': 2, 'outputs': 1, 'reduces': 1, 'trains': 1, 'computes': 1, 'evaluates': 1}, ('reduces', 'linguistic'): {'features': 19}, ('text', 'meanwhile'): {'the': 7}, ('output', 'therefore'): {'the': 2}, ('system', 'maximizes'): {'the': 7, 'contextual': 1, 'token': 1, 'large': 1, 'semantic': 1, 'co-occurrence': 1, 'language': 1}, ('sequence', 'fine-tunes'): {'the': 7, 'millions': 1, 'word': 1, 'linguistic': 1}, ('function', 'processes'): {'the': 2}, ('additionally', 'backpropagation'): {'generalizes': 1, 'computes': 1, 'generates': 1, 'optimizes': 1, 'fine-tunes': 1}, ('tasks', 'efficiently'): {'in': 7, 'the': 50, 'a': 25, 'subsequently': 3, 'as': 5, 'consequently': 2, 'moreover': 2, 'nevertheless': 2, 'backpropagation': 2, 'however': 1, 'therefore': 2, 'meanwhile': 1, 'furthermore': 1, 'for': 1}, ('data', 'ensures'): {'consistent': 98}, ('decodes', 'linguistic'): {'features': 14}, ('system', 'continuously'): {'learns': 1, 'generalizes': 1, 'diverges': 1, 'predicts': 1, 'generates': 1}, ('gradient', 'converges'): {'sentence': 2, 'linguistic': 2, 'the': 2}, ('continuously', 'gradient'): {'descent': 1}, ('recursively', 'trains'): {'on': 8}, ('probabilistically', 'updates'): {'token': 1, 'word': 1, 'the': 2, 'large': 1}, ('sequentially', 'as'): {'a': 2}, ('probability', 'encodes'): {'syntactic': 2, 'millions': 1, 'the': 2, 'semantic': 1, 'large': 1, 'co-occurrence': 1}, ('model', 'converges'): {'word': 1, 'the': 11, 'statistical': 3, 'token': 1, 'semantic': 1}, ('backpropagation', 'statistically'): {'increases': 1, 'predicts': 1, 'generalizes': 1, 'minimizes': 1, 'encodes': 1}, ('gracefully', 'consequently'): {'the': 1}, ('adjusts', 'semantic'): {'meaning': 14}, ('network', 'adjusts'): {'statistical': 1, 'the': 9, 'contextual': 1, 'linguistic': 1, 'syntactic': 1, 'large': 1}, ('information', 'overfitting'): {'occurs': 3}, ('perplexity', 'evaluates'): {'the': 5, 'sentence': 1, 'syntactic': 1, 'millions': 1, 'contextual': 2}, ('sequentially', 'for'): {'example': 4}, ('trigram', 'significantly'): {'improves': 1, 'converges': 1, 'models': 1, 'computes': 1, 'reduces': 1, 'trains': 1, 'predicts': 1, 'fine-tunes': 1}, ('models', 'token'): {'sequences': 9}, ('modeling', 'meanwhile'): {'the': 1}, ('recursively', 'models'): {'the': 5}, ('continuously', 'learns'): {'from': 6}, ('word', 'moreover'): {'the': 3}, ('continuously', 'generates'): {'statistical': 1, 'the': 3, 'language': 1, 'millions': 2, 'token': 1}, ('gradually', 'adjusts'): {'the': 4, 'contextual': 2, 'statistical': 1}, ('states', 'effectively'): {'the': 9, 'a': 2, 'consequently': 1, 'gradient': 1, 'smoothing': 1}, ('prediction', 'adjusts'): {'language': 2, 'sentence': 1, 'statistical': 1, 'linguistic': 2}, ('weight', 'automatically'): {'tokenizes': 1, 'learns': 1}, ('information', 'smoothing'): {'techniques': 2}, ('memorizing', 'the'): {'training': 92}, ('vocabulary', 'computes'): {'linguistic': 2, 'token': 1, 'sentence': 1, 'word': 2, 'the': 5, 'statistical': 1}, ('text', 'increases'): {'the': 5, 'semantic': 1, 'token': 1}, ('embeddings', 'training'): {'a': 3}, ('sequences', 'accurately'): {'as': 1, 'training': 2, 'backpropagation': 1, 'the': 3, 'a': 2, 'bigram': 1, 'additionally': 1, 'subsequently': 1}, ('meaning', 'efficiently'): {'a': 6, 'the': 7, 'as': 1, 'overfitting': 1, 'for': 1, 'furthermore': 1, 'smoothing': 1}, ('embeddings', 'therefore'): {'the': 3}, ('window', 'trains'): {'on': 10}, ('efficiently', 'represents'): {'statistical': 2, 'the': 5, 'language': 2, 'co-occurrence': 1, 'word': 1}, ('information', 'continuously'): {'the': 4, 'a': 2, 'smoothing': 1}, ('successfully', 'data'): {'preprocessing': 7}, ('accurately', 'reduces'): {'the': 2, 'syntactic': 1}, ('a', 'discriminative'): {'the': 108, 'backpropagation': 4}, ('gradually', 'subsequently'): {'the': 8}, ('captures', 'semantic'): {'meaning': 10}, ('optimizer', 'increases'): {'the': 5}, ('dataset', 'decodes'): {'large': 2, 'word': 1, 'the': 4, 'syntactic': 2, 'linguistic': 1}, ('text', 'iteratively'): {'tokenizes': 1, 'fine-tunes': 1, 'a': 2, 'as': 2, 'decodes': 1, 'bigram': 1, 'the': 6, 'generates': 1, 'increases': 1, 'additionally': 1, 'cross': 1, 'reduces': 1, 'meanwhile': 1, 'backpropagation': 1, 'feeding': 1}, ('value', 'gradient'): {'descent': 3}, ('sequentially', 'tokenization'): {'is': 3}, ('size', 'recursively'): {'the': 16, 'a': 3, 'cleaning': 1, 'additionally': 1, 'gradient': 1, 'moreover': 1, 'nevertheless': 1}, ('for', 'the'): {'model': 82}, ('data', 'consequently'): {'the': 2}, ('model', 'assigns'): {'probabilities': 93}, ('the', 'activation'): {'function': 371}, ('correctly', 'cleaning'): {'and': 2}, ('tokenizer', 'adjusts'): {'the': 4, 'linguistic': 1, 'word': 1, 'large': 1}, ('window', 'models'): {'the': 3, 'word': 1, 'statistical': 1, 'syntactic': 1, 'semantic': 1, 'language': 1}, ('function', 'nevertheless'): {'the': 5}, ('text', 'transfer'): {'learning': 5}, ('meaning', 'as'): {'a': 2}, ('optimizer', 'optimizes'): {'the': 8, 'word': 1, 'large': 3, 'co-occurrence': 2, 'language': 1, 'sentence': 1}, ('gracefully', 'subsequently'): {'the': 1}, ('information', 'regularization'): {'techniques': 2}, ('terms', 'recursively'): {'backpropagation': 1, 'a': 4, 'in': 2, 'the': 6, 'data': 1}, ('optimizer', 'iteratively'): {'represents': 1, 'diverges': 1, 'trains': 1, 'learns': 1, 'fine-tunes': 1, 'improves': 1, 'increases': 1, 'decodes': 1}, ('process', 'efficiently'): {'processes': 1, 'generates': 1, 'outputs': 1, 'captures': 1, 'tokenizes': 1, 'computes': 1}, ('probability', 'computes'): {'the': 2, 'sentence': 1, 'token': 1, 'language': 1, 'word': 1, 'linguistic': 2, 'co-occurrence': 1}, ('distribution', 'successfully'): {'the': 2, 'tokenization': 1, 'data': 1, 'cleaning': 1}, ('consistent', 'input'): {'to': 98}, ('weight', 'processes'): {'the': 4, 'syntactic': 1, 'millions': 2, 'statistical': 1, 'language': 1, 'word': 1}, ('gradually', 'fine-tunes'): {'the': 1, 'word': 1, 'millions': 1}, ('to', 'the'): {'training': 98}}\n"
          ]
        }
      ]
    }
  ]
}