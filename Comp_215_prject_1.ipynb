{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPqpICXsKwrBAq2/W5GL7Av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagosanchez15/Project1-comp215/blob/main/Comp_215_prject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 comp 215\n",
        "\n",
        "**Author:** Santiago Sanchez Covarrubias\n",
        "\n",
        "**resources**: *Think python, Claude.ai*\n",
        "  - https://allendowney.github.io/ThinkPython/. Think python URL\n",
        "\n",
        "\n",
        "**Objectives**\n",
        "- The creation of a SLM capable of to predict the third word\n",
        "\n",
        "**Project description**\n",
        "\n",
        "The project will develop a SLM capable of predicting the third word.\n",
        "\n",
        "This project will be focus not only on developing the SLM but also on documenting the process.\n",
        "Starting by adding different sections, that at the end of different sections will join all the pieces together.\n",
        "\n",
        "After the SLM has been built with feeded data, the final SLM will be created by inhereting everything from the first one, the difference is tyhat this final version will not only take the feeded data through files but aslo through the Wikimedia REST API, the perfect source for thousand of wirtten texts.\n",
        "\n",
        "At the end of all the documentation the full code will be available.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4B-5Ynb7MuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string #used for punctuation signs\n",
        "from collections import Counter #used to merge and join two dictionaries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XJQVWReTwtlr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsed and clean function\n",
        "\n",
        "  - get_text:\n",
        "    - will get the text from the file\n",
        "\n",
        "  - clean_text\n",
        "    - will iterate through all the text, check if there are punctuations signs, remove and create a new list of words\n",
        "\n",
        "  - bigrams -> words\n",
        "    - check the anount aof times a word repeats after an specific word, then added to dictionary\n",
        "      \"Hello how are you\"\n",
        "      1 - (Hello how)\n",
        "      2- (how are)\n",
        "      3- (are you)\n",
        "      amount of times the second word will come after the first one\n",
        "      {\"Hello\", {\"how\": 2, \"this\": 4}} etc.\n",
        "\n",
        "\n",
        "  - trigrams -> 3 words\n",
        "    - same like bigrams but instead teh combination of 3 words\n",
        "      next two words plus the word checking such as\n",
        "      \"The castle is big and made of stone\"\n",
        "      1 - (the castle is)\n",
        "      2- (castle is big)\n",
        "      3- (is big and)\n",
        "      aount of times the next two words will come after the first one\n",
        "      {'The': {\"castle is\", 3}\n",
        "      {\"The': {\"red carpet\", 2}\n",
        "      etc, next two words following the first one there fore key can be tuple"
      ],
      "metadata": {
        "id": "_Ic4JweXDpLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean text\n",
        "two functions, clean a text from a file and another one to clean the text from a string"
      ],
      "metadata": {
        "id": "J2hEw9E_NIoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jDhAz7987LpL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text_from_file(file_name: str) -> list:\n",
        "  '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "  with open(file_name, 'r') as text: #open file given\n",
        "    return [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)] #iterate through each word and strip to get clean word\n",
        "\n",
        "assert clean_text_from_file('sample.txt')[:2] == ['hello', 'world']\n",
        "assert clean_text_from_file('sample.txt')[-1] == 'wonderful'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(string_text: str) -> list:\n",
        "  '''Returns list of word cleaned '''\n",
        "  return [word.strip(string.punctuation).lower() for word in string_text.split() if word.strip(string.punctuation)]"
      ],
      "metadata": {
        "id": "Tb73VLIR01mV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = \"Hello! my? friend is you!!!!!\"\n",
        "print(clean_text(list1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH8aKXuE19RA",
        "outputId": "0f482246-3ba1-497f-9b0d-5d4f0e66999d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'my', 'friend', 'is', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trigram\n",
        "get trigram from given word\n",
        "so for example if input is:\n",
        "hello my name is santiago\n",
        "then the output would be\n",
        "(hello, my, name), (my, name, is), (name, is, santiago)"
      ],
      "metadata": {
        "id": "wwk3vmqIABDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trigrams(list_word: list) -> list:\n",
        "  '''Returns list of trigrams '''\n",
        "\n",
        "  return list(zip(list_word[:-2], list_word[1:-1], list_word[2:]))"
      ],
      "metadata": {
        "id": "V3BYqtMYAVMB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing unit\n",
        "\n",
        "print(get_trigrams('hello my name is santiago'.split()))\n",
        "assert get_trigrams('hello my name is santiago'.split()) == [('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aSbAYqNArP9",
        "outputId": "4aa68725-add9-4d64-c718-b3ead04d0df2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge_dictionaries\n",
        "\n",
        "function that will take two dictionaries and merge the two of them adding the elements and counting the bigrams"
      ],
      "metadata": {
        "id": "cOskLr1qoZhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "  '''Returns dictionary with updated values '''\n",
        "\n",
        "  counter1, counter2 = 0,0\n",
        "\n",
        "  all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "  result = {}\n",
        "\n",
        "  for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "    counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "    counter2 = Counter(new_dict.get(key, {}))\n",
        "    result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "PYODKO_mojSR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {(\"hello\", 'how'): {\"are\": 1, \"is\": 2}, (\"apple\", 'is'): {\"a\": 1, \"healthy\": 2}, (\"apples\", \"are\"): {\"my\": 1, \"taste\": 2}}\n",
        "dict2 = {(\"hello\", 'how'): {\"are\": 3}, \"pear\": {\"yummy\": 1}}\n",
        "new_dict = merge_dictionaries(dict1, dict2)\n",
        "print(new_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01oTqBwmpOmN",
        "outputId": "33dd7963-4b9c-45b8-93f4-9cc56cce7eb1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pear': {'yummy': 1}, ('apple', 'is'): {'a': 1, 'healthy': 2}, ('apples', 'are'): {'my': 1, 'taste': 2}, ('hello', 'how'): {'are': 4, 'is': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word_frequency\n",
        "this function will take a dictionary and a given list of bigrams to update the dictionary given with the values corresponding to the frequency of the words appearance"
      ],
      "metadata": {
        "id": "oYjUE6SpYJTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency(trigrams:list) -> dict:\n",
        "  '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "  new_dict = {}\n",
        "  for key1, key2, value in trigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "    if (key1, key2) not in new_dict: new_dict[(key1, key2)] = {} #create a new key if the key doenst exist\n",
        "    if value not in new_dict[(key1, key2)]: new_dict[(key1, key2)][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "    else: new_dict[(key1, key2)][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "  return new_dict\n",
        "#try function\n",
        "\n"
      ],
      "metadata": {
        "id": "wCNE24uFZUQ-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try function above\n",
        "tuple_t = ((1,2,3), (4,3,2))\n",
        "print(word_frequency(tuple_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k1ioSL7lzKM",
        "outputId": "44930464-5ee4-433f-8287-d2fefbe3f887"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(1, 2): {3: 1}, (4, 3): {2: 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word_frequency_from_file\n",
        "\n",
        "Lets join all the functions together into a single function\n",
        "it will take a file name as a paramter and return the dictionary that will be used to feed the model"
      ],
      "metadata": {
        "id": "C_tTtTWftG2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency_from_file(file_name: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "  text = clean_text_from_file(file_name) #get the clean text as a list\n",
        "  trigrams = get_trigrams(text) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary\n"
      ],
      "metadata": {
        "id": "NinGAW10tgBG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test function\n",
        "new_dict = {}\n",
        "list_files = ['text1.txt', 'text2.txt']\n",
        "for file in list_files:\n",
        "  new_dict = word_frequency_from_file(file, new_dict)\n",
        "\n",
        "print(new_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZAbH4Q9uqkn",
        "outputId": "e159a01c-1111-476d-9f34-404dc51ef459"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('name', 'is'): {'santigo': 1}, ('hello', 'my'): {'name': 1, 'friend': 1}, ('my', 'name'): {'is': 1}, ('my', 'friend'): {'is': 1}, ('friend', 'is'): {'you': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets test the function with more complex files"
      ],
      "metadata": {
        "id": "zIprjybf57A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test function complex files\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6jmI3i5-LR",
        "outputId": "1642398f-d46c-4773-ba50-5e3af93a5151"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word_frequency_from text\n",
        "Ofcourse at this point of the project we can get the word frequency from file, bu twhat if we just want to copy and paste. well that is easy"
      ],
      "metadata": {
        "id": "3JIOmJkWy2_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freqeuncy_from_text(given_string: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "  new_list = clean_text(given_string)\n",
        "  trigrams = get_trigrams(new_list) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary"
      ],
      "metadata": {
        "id": "3VB58C0dzaSZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['The blue car drives fast. The blue truck drives slow. The red car drives carefully, but the red truck drives wildly. My friend likes the blue car. My sister likes the red truck.', 'The cat sat on the mat. The dog sat on the floor. The cat sat on the chair, and the dog sat on the bed. I saw the cat sit down. I saw the dog lie down.']\n",
        "dict1 = {}\n",
        "for text in list1:\n",
        "  dict1 = word_freqeuncy_from_text(text, dict1)\n",
        "dict1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexleW3Xz4Nw",
        "outputId": "162db8f8-13ee-418b-b24f-df788c53da06"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#what next?\n",
        "since we are able to get the frequency of the word and what comes next, we need to do a couple of more things to....\n",
        "Next fucntions will be:\n",
        "  - list of possible next word -> returns a list of key of the trigram\n",
        "\n",
        "  - get_probability -> get weight word and divide by total weight -> probability\n",
        "\n",
        "  - get_weight_word -> weight / total weight using numpy to assign weight return dicitonary key = word, value = probability\n",
        "\n",
        "  - get_word -> using NumPy pseduo-random numbers, get word based on the different possibilites\n"
      ],
      "metadata": {
        "id": "vu1uLxVdLMlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#List_possible_words\n",
        "\n",
        "returns a list of all the possible word that can be chosen independently from the weight"
      ],
      "metadata": {
        "id": "tqCy-llKQoJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_possible_words(dict_weights: dict, bigram: tuple) -> list:\n",
        "  '''Returns all possible word based on bigram '''\n",
        "\n",
        "  return list(dict_weights[bigram].keys())"
      ],
      "metadata": {
        "id": "eIHOsYwWQ3qY"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict\n",
        "get_all_possible_words(new_dict, ('on', 'the') )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGCYMZUkVilU",
        "outputId": "549c4a9c-4217-4e11-a516-446c41808252"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mat', 'floor', 'chair', 'bed']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_probability function\n",
        "based on the total of weight return the proability of the word occurring\n",
        "for example if total weight = 25 and my word occurece 5 times that 5/25 = 0.2"
      ],
      "metadata": {
        "id": "57fOI9uVYh4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probabilty(num_appearance: int, total_weight: int) -> int:\n",
        "  '''Returns probability of the word to appear '''\n",
        "  return num_appearance / total_weight"
      ],
      "metadata": {
        "id": "_6zoxrfTZN3_"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test function above\n",
        "assert round(get_probabilty(5, 140), 5) == 0.03571\n",
        "assert round(get_probabilty(0, 150), 5) == 0\n",
        "assert round(get_probabilty(10, 10), 5) == 1\n",
        "assert round(get_probabilty(20, 154), 5) == 0.12987"
      ],
      "metadata": {
        "id": "lxTSKSN8aNbD"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_total_weight\n",
        "iterate trhough each value to get the toal weight, return int of weight"
      ],
      "metadata": {
        "id": "qF41y-HngG7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_weight(dictionary : dict, key: tuple) -> int:\n",
        "  '''return total weight for given key '''\n",
        "\n",
        "  return sum((value for value in dictionary[key].values()))"
      ],
      "metadata": {
        "id": "19GVi9RWgNcy"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing unit\n",
        "\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_total_weight(dictionary, ('hello', 'how')) == 8\n",
        "assert get_total_weight(dictionary, ('i', 'am')) == 14"
      ],
      "metadata": {
        "id": "z79SZ1VbgwRy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_weighted_words\n",
        "returns list of probability of the values given, respect to the key"
      ],
      "metadata": {
        "id": "JbhfSNdYd1Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "I304cV-WblFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_words(dictionary: dict, key: tuple) -> list:\n",
        "  '''Returns a list of tuple word, dictionary '''\n",
        "\n",
        "  total_weight = get_total_weight(dictionary, key) #get total sum of the weight\n",
        "\n",
        "  #generator expression to get a list of tuples that will hold the word and the total weight\n",
        "  return list(((word, get_probabilty(weight, total_weight)) for word, weight in dictionary[key].items() ))"
      ],
      "metadata": {
        "id": "asWj4Aw8fKe5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing units\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_weighted_words(dictionary, ('hello', 'how')) == [('you', 0.625), ('are', 0.375)]\n",
        "assert get_weighted_words(dictionary, ('i', 'am')) == [('your', 0.35714285714285715), ('santiago', 0.21428571428571427), ('my', 0.42857142857142855 )]"
      ],
      "metadata": {
        "id": "iAItCbN6flG5"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#predict_word\n",
        "form the list given, return the word by given probability"
      ],
      "metadata": {
        "id": "VnG-sdGTmhKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word()"
      ],
      "metadata": {
        "id": "3zp7PWf7mrS3",
        "outputId": "f53f1dea-c45e-4730-9eb7-6921987ebb0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "expected ':' (ipython-input-841884995.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-841884995.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def predict_word()\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expected ':'\n"
          ]
        }
      ]
    }
  ]
}