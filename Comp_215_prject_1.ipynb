{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTcFQWw67JSJAOxdT7Sj6q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/santiagosanchez15/Project1-comp215/blob/main/Comp_215_prject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 1 comp 215\n",
        "\n",
        "**Author:** Santiago Sanchez Covarrubias\n",
        "\n",
        "**resources**: *Think python, Claude.ai*\n",
        "  - https://allendowney.github.io/ThinkPython/. Think python URL\n",
        "\n",
        "\n",
        "**Objectives**\n",
        "- The creation of a SLM capable of to predict the third word\n",
        "\n",
        "**Project description**\n",
        "\n",
        "The project will develop a SLM capable of predicting the third word.\n",
        "\n",
        "This project will be focus not only on developing the SLM but also on documenting the process.\n",
        "Starting by adding different sections, that at the end of different sections will join all the pieces together.\n",
        "\n",
        "After the SLM has been built with feeded data, the final SLM will be created by inhereting everything from the first one, the difference is tyhat this final version will not only take the feeded data through files but aslo through the Wikimedia REST API, the perfect source for thousand of wirtten texts.\n",
        "\n",
        "At the end of all the documentation the full code will be available.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "K4B-5Ynb7MuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string #used for punctuation signs\n",
        "from collections import Counter #used to merge and join two dictionaries\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "XJQVWReTwtlr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parsed and clean function\n",
        "\n",
        "  - get_text:\n",
        "    - will get the text from the file\n",
        "\n",
        "  - clean_text\n",
        "    - will iterate through all the text, check if there are punctuations signs, remove and create a new list of words\n",
        "\n",
        "  - bigrams -> words\n",
        "    - check the anount aof times a word repeats after an specific word, then added to dictionary\n",
        "      \"Hello how are you\"\n",
        "      1 - (Hello how)\n",
        "      2- (how are)\n",
        "      3- (are you)\n",
        "      amount of times the second word will come after the first one\n",
        "      {\"Hello\", {\"how\": 2, \"this\": 4}} etc.\n",
        "\n",
        "\n",
        "  - trigrams -> 3 words\n",
        "    - same like bigrams but instead teh combination of 3 words\n",
        "      next two words plus the word checking such as\n",
        "      \"The castle is big and made of stone\"\n",
        "      1 - (the castle is)\n",
        "      2- (castle is big)\n",
        "      3- (is big and)\n",
        "      aount of times the next two words will come after the first one\n",
        "      {'The': {\"castle is\", 3}\n",
        "      {\"The': {\"red carpet\", 2}\n",
        "      etc, next two words following the first one there fore key can be tuple"
      ],
      "metadata": {
        "id": "_Ic4JweXDpLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean text\n",
        "two functions, clean a text from a file and another one to clean the text from a string"
      ],
      "metadata": {
        "id": "J2hEw9E_NIoB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "jDhAz7987LpL"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_text_from_file(file_name: str) -> list:\n",
        "  '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "  with open(file_name, 'r') as text: #open file given\n",
        "    return [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)] #iterate through each word and strip to get clean word\n",
        "\n",
        "assert clean_text_from_file('sample.txt')[:2] == ['hello', 'world']\n",
        "assert clean_text_from_file('sample.txt')[-1] == 'wonderful'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(string_text: str) -> list:\n",
        "  '''Returns list of word cleaned '''\n",
        "  return [word.strip(string.punctuation).lower() for word in string_text.split() if word.strip(string.punctuation)]"
      ],
      "metadata": {
        "id": "Tb73VLIR01mV"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = \"Hello! my? friend is you!!!!!\"\n",
        "print(clean_text(list1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH8aKXuE19RA",
        "outputId": "1b76315a-daf8-475e-8df4-48545f8896e8"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'my', 'friend', 'is', 'you']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_bigram\n",
        "get Bigram from given word so for example if input is: hello my name is santiago then the output would be (hello, my), (my, name), (name, is), (is, santiago)"
      ],
      "metadata": {
        "id": "mQNLcVebixVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bigram(list_word: list) -> list:\n",
        "  '''Return list of bigrams '''\n",
        "\n",
        "  return list(zip(list_word[:-1], list_word[1:]))"
      ],
      "metadata": {
        "id": "_CNGk9Zti7kb"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "assert get_bigram(['hello', 'my', 'name', 'is', 'santiago']) == [('hello', 'my'), ('my', 'name'), ('name', 'is'), ('is', 'santiago')]"
      ],
      "metadata": {
        "id": "XYyJsdNhjNE8"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_trigram\n",
        "get trigram from given word\n",
        "so for example if input is:\n",
        "hello my name is santiago\n",
        "then the output would be\n",
        "(hello, my, name), (my, name, is), (name, is, santiago)"
      ],
      "metadata": {
        "id": "wwk3vmqIABDL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_trigrams(list_word: list) -> list:\n",
        "  '''Returns list of trigrams '''\n",
        "\n",
        "  return list(zip(list_word[:-2], list_word[1:-1], list_word[2:]))"
      ],
      "metadata": {
        "id": "V3BYqtMYAVMB"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing unit\n",
        "\n",
        "print(get_trigrams('hello my name is santiago'.split()))\n",
        "assert get_trigrams('hello my name is santiago'.split()) == [('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aSbAYqNArP9",
        "outputId": "58caf0b9-1a08-44b4-b12b-2fe69065e913"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('hello', 'my', 'name'), ('my', 'name', 'is'), ('name', 'is', 'santiago')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Merge_dictionaries\n",
        "\n",
        "function that will take two dictionaries and merge the two of them adding the elements and counting the bigrams"
      ],
      "metadata": {
        "id": "cOskLr1qoZhR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "  '''Returns dictionary with updated values '''\n",
        "\n",
        "  all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "  result = {}\n",
        "\n",
        "  for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "    counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "    counter2 = Counter(new_dict.get(key, {}))\n",
        "    result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "  return result\n",
        "\n"
      ],
      "metadata": {
        "id": "PYODKO_mojSR"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict1 = {(\"hello\", 'how'): {\"are\": 1, \"is\": 2}, (\"apple\", 'is'): {\"a\": 1, \"healthy\": 2}, (\"apples\", \"are\"): {\"my\": 1, \"taste\": 2}}\n",
        "dict2 = {(\"hello\", 'how'): {\"are\": 3}, \"pear\": {\"yummy\": 1}}\n",
        "new_dict = merge_dictionaries(dict1, dict2)\n",
        "print(new_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01oTqBwmpOmN",
        "outputId": "6999abff-784b-4107-af67-96ca39180bc7"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'pear': {'yummy': 1}, ('apple', 'is'): {'a': 1, 'healthy': 2}, ('apples', 'are'): {'my': 1, 'taste': 2}, ('hello', 'how'): {'are': 4, 'is': 2}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# word_frequency\n",
        "this function will take a dictionary and a given list of bigrams to update the dictionary given with the values corresponding to the frequency of the words appearance"
      ],
      "metadata": {
        "id": "oYjUE6SpYJTX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency(trigrams:list) -> dict:\n",
        "  '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "  new_dict = {}\n",
        "  for key1, key2, value in trigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "    if (key1, key2) not in new_dict: new_dict[(key1, key2)] = {} #create a new key if the key doenst exist\n",
        "    if value not in new_dict[(key1, key2)]: new_dict[(key1, key2)][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "    else: new_dict[(key1, key2)][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "  return new_dict\n",
        "#try function\n",
        "\n"
      ],
      "metadata": {
        "id": "wCNE24uFZUQ-"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#try function above\n",
        "tuple_t = ((1,2,3), (4,3,2))\n",
        "print(word_frequency(tuple_t))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0k1ioSL7lzKM",
        "outputId": "841995bb-7690-4a18-ce75-5aa14493ce86"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(1, 2): {3: 1}, (4, 3): {2: 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#word_frequency_from_file\n",
        "\n",
        "Lets join all the functions together into a single function\n",
        "it will take a file name as a paramter and return the dictionary that will be used to feed the model"
      ],
      "metadata": {
        "id": "C_tTtTWftG2h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_frequency_from_file(file_name: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "  text = clean_text_from_file(file_name) #get the clean text as a list\n",
        "  trigrams = get_trigrams(text) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary\n"
      ],
      "metadata": {
        "id": "NinGAW10tgBG"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test function\n",
        "new_dict = {}\n",
        "list_files = ['text1.txt', 'text2.txt']\n",
        "for file in list_files:\n",
        "  new_dict = word_frequency_from_file(file, new_dict)\n",
        "\n",
        "print(new_dict)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZAbH4Q9uqkn",
        "outputId": "87c0048c-cc15-4e80-dda2-8442e2e1d1a9"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{('name', 'is'): {'santigo': 1}, ('hello', 'my'): {'name': 1, 'friend': 1}, ('my', 'name'): {'is': 1}, ('my', 'friend'): {'is': 1}, ('friend', 'is'): {'you': 1}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "lets test the function with more complex files"
      ],
      "metadata": {
        "id": "zIprjybf57A4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test function complex files\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk6jmI3i5-LR",
        "outputId": "dd2e1c04-a4f5-40b8-d8d3-b97b53814fa2"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Word_frequency_from text\n",
        "Ofcourse at this point of the project we can get the word frequency from file, bu twhat if we just want to copy and paste. well that is easy"
      ],
      "metadata": {
        "id": "3JIOmJkWy2_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def word_freqeuncy_from_text(given_string: str, old_dict: dict) -> dict:\n",
        "  '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "  new_list = clean_text(given_string)\n",
        "  trigrams = get_trigrams(new_list) #get bigrams form the zip function\n",
        "  frequency = word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "  return merge_dictionaries(old_dict, frequency) #returns the updated dictionary"
      ],
      "metadata": {
        "id": "3VB58C0dzaSZ"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list1 = ['The blue car drives fast. The blue truck drives slow. The red car drives carefully, but the red truck drives wildly. My friend likes the blue car. My sister likes the red truck.', 'The cat sat on the mat. The dog sat on the floor. The cat sat on the chair, and the dog sat on the bed. I saw the cat sit down. I saw the dog lie down.']\n",
        "dict1 = {}\n",
        "for text in list1:\n",
        "  dict1 = word_freqeuncy_from_text(text, dict1)\n",
        "dict1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BexleW3Xz4Nw",
        "outputId": "a68918a9-e5c1-4185-ce03-3388c700b171"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('the', 'blue'): {'car': 2, 'truck': 1},\n",
              " ('the', 'bed'): {'i': 1},\n",
              " ('drives', 'carefully'): {'but': 1},\n",
              " ('drives', 'fast'): {'the': 1},\n",
              " ('the', 'dog'): {'sat': 2, 'lie': 1},\n",
              " ('drives', 'wildly'): {'my': 1},\n",
              " ('sit', 'down'): {'i': 1},\n",
              " ('cat', 'sat'): {'on': 2},\n",
              " ('car', 'drives'): {'fast': 1, 'carefully': 1},\n",
              " ('likes', 'the'): {'blue': 1, 'red': 1},\n",
              " ('dog', 'lie'): {'down': 1},\n",
              " ('and', 'the'): {'dog': 1},\n",
              " ('chair', 'and'): {'the': 1},\n",
              " ('red', 'car'): {'drives': 1},\n",
              " ('sat', 'on'): {'the': 4},\n",
              " ('truck', 'drives'): {'slow': 1, 'wildly': 1},\n",
              " ('down', 'i'): {'saw': 1},\n",
              " ('dog', 'sat'): {'on': 2},\n",
              " ('my', 'friend'): {'likes': 1},\n",
              " ('the', 'floor'): {'the': 1},\n",
              " ('carefully', 'but'): {'the': 1},\n",
              " ('floor', 'the'): {'cat': 1},\n",
              " ('sister', 'likes'): {'the': 1},\n",
              " ('but', 'the'): {'red': 1},\n",
              " ('my', 'sister'): {'likes': 1},\n",
              " ('the', 'mat'): {'the': 1},\n",
              " ('saw', 'the'): {'cat': 1, 'dog': 1},\n",
              " ('fast', 'the'): {'blue': 1},\n",
              " ('blue', 'car'): {'drives': 1, 'my': 1},\n",
              " ('red', 'truck'): {'drives': 1},\n",
              " ('mat', 'the'): {'dog': 1},\n",
              " ('slow', 'the'): {'red': 1},\n",
              " ('the', 'red'): {'car': 1, 'truck': 2},\n",
              " ('the', 'cat'): {'sat': 2, 'sit': 1},\n",
              " ('drives', 'slow'): {'the': 1},\n",
              " ('friend', 'likes'): {'the': 1},\n",
              " ('i', 'saw'): {'the': 2},\n",
              " ('car', 'my'): {'sister': 1},\n",
              " ('bed', 'i'): {'saw': 1},\n",
              " ('blue', 'truck'): {'drives': 1},\n",
              " ('the', 'chair'): {'and': 1},\n",
              " ('cat', 'sit'): {'down': 1},\n",
              " ('on', 'the'): {'mat': 1, 'floor': 1, 'chair': 1, 'bed': 1},\n",
              " ('wildly', 'my'): {'friend': 1}}"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#what next?\n",
        "since we are able to get the frequency of the word and what comes next, we need to do a couple of more things to....\n",
        "Next fucntions will be:\n",
        "  - list of possible next word -> returns a list of key of the trigram\n",
        "\n",
        "  - get_probability -> get weight word and divide by total weight -> probability\n",
        "\n",
        "  - get_weight_word -> weight / total weight using numpy to assign weight return dicitonary key = word, value = probability\n",
        "\n",
        "  - get_word -> using NumPy pseduo-random numbers, get word based on the different possibilites\n"
      ],
      "metadata": {
        "id": "vu1uLxVdLMlo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#List_possible_words\n",
        "\n",
        "returns a list of all the possible word that can be chosen independently from the weight"
      ],
      "metadata": {
        "id": "tqCy-llKQoJj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_all_possible_words(dict_weights: dict, bigram: tuple) -> list:\n",
        "  '''Returns all possible word based on bigram '''\n",
        "\n",
        "  return list(dict_weights[bigram].keys())"
      ],
      "metadata": {
        "id": "eIHOsYwWQ3qY"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "new_dict\n",
        "get_all_possible_words(new_dict, ('on', 'the') )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGCYMZUkVilU",
        "outputId": "f42a90db-3a7b-4498-917a-b34719d6067c"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['mat', 'floor', 'chair', 'bed']"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_probability function\n",
        "based on the total of weight return the proability of the word occurring\n",
        "for example if total weight = 25 and my word occurece 5 times that 5/25 = 0.2"
      ],
      "metadata": {
        "id": "57fOI9uVYh4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probability(num_appearance: int, total_weight: int) -> int:\n",
        "  '''Returns probability of the word to appear '''\n",
        "  return num_appearance / total_weight"
      ],
      "metadata": {
        "id": "_6zoxrfTZN3_"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test function above\n",
        "assert round(get_probability(5, 140), 5) == 0.03571\n",
        "assert round(get_probability(0, 150), 5) == 0\n",
        "assert round(get_probability(10, 10), 5) == 1\n",
        "assert round(get_probability(20, 154), 5) == 0.12987"
      ],
      "metadata": {
        "id": "lxTSKSN8aNbD"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_total_weight\n",
        "iterate trhough each value to get the toal weight, return int of weight"
      ],
      "metadata": {
        "id": "qF41y-HngG7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_total_weight(dictionary : dict, key: tuple) -> int:\n",
        "  '''return total weight for given key '''\n",
        "\n",
        "  return sum((value for value in dictionary[key].values()))"
      ],
      "metadata": {
        "id": "19GVi9RWgNcy"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Testing unit\n",
        "\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_total_weight(dictionary, ('hello', 'how')) == 8\n",
        "assert get_total_weight(dictionary, ('i', 'am')) == 14"
      ],
      "metadata": {
        "id": "z79SZ1VbgwRy"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#get_weighted_words\n",
        "returns list of probability of the values given, respect to the key"
      ],
      "metadata": {
        "id": "JbhfSNdYd1Cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "I304cV-WblFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_weighted_words(dictionary: dict, key: tuple) -> list:\n",
        "  '''Returns a list of tuple word, dictionary '''\n",
        "\n",
        "  total_weight = get_total_weight(dictionary, key) #get total sum of the weight\n",
        "\n",
        "  #generator expression to get a list of tuples that will hold the word and the total weight\n",
        "  return list(((word, get_probability(weight, total_weight)) for word, weight in dictionary[key].items() ))"
      ],
      "metadata": {
        "id": "asWj4Aw8fKe5"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#testing units\n",
        "dictionary = {('hello', \"how\"): {'you': 5, \"are\": 3}, ('i', 'am'): {'your': 5, \"santiago\": 3, \"my\": 6}}\n",
        "assert get_weighted_words(dictionary, ('hello', 'how')) == [('you', 0.625), ('are', 0.375)]\n",
        "assert get_weighted_words(dictionary, ('i', 'am')) == [('your', 0.35714285714285715), ('santiago', 0.21428571428571427), ('my', 0.42857142857142855 )]"
      ],
      "metadata": {
        "id": "iAItCbN6flG5"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#predict_word\n",
        "form the list given, return the word by given probability"
      ],
      "metadata": {
        "id": "VnG-sdGTmhKo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_word(dictionary: dict, key: tuple) -> str:\n",
        "  '''Returns string for given probability '''\n",
        "\n",
        "  if key not in dictionary: return None #handle case where input is not valid\n",
        "  words, probability = zip(*get_weighted_words(dictionary, key)) # unoack the values with * given each index to each variable\n",
        "  return str(np.random.default_rng().choice(words, p = probability))"
      ],
      "metadata": {
        "id": "3zp7PWf7mrS3"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit test\n",
        "\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "print(predict_word(new_dict, ('on', 'the')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVJAqMNBcGV4",
        "outputId": "a903c0da-def2-4731-83e3-0975b7e3c49c"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#From input to list\n",
        "get string from input and get trigram, so it can be looked later\n",
        "by the word frequency"
      ],
      "metadata": {
        "id": "tsDIMZsThjxC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_to_prediction(dictionary: dict, input: str) -> str:\n",
        "  '''get input and return prediction '''\n",
        "\n",
        "  input_clean = clean_text(input)\n",
        "  if len(input_clean) <= 1: return None #handle case where not enough information is given\n",
        "  bigram = get_bigram(input_clean)[-1] #in case the user gives more than two words only get the last two from the input\n",
        "\n",
        "  return predict_word(dictionary, bigram)\n"
      ],
      "metadata": {
        "id": "ju-SC_QjiXiM"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "new_dict = {}\n",
        "new_file_list = ['trigram_test1.txt', 'trigram_test2.txt']\n",
        "for complex_file in new_file_list:\n",
        "  new_dict = word_frequency_from_file(complex_file, new_dict)\n",
        "\n",
        "print(input_to_prediction(new_dict, ('on the')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wd08eLQhlv7I",
        "outputId": "9b0a89c3-cf49-46d3-ad01-1775cc3d5bf0"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Now what\n",
        "now that that im able to predict my thrid word, whats next, well, in that case i have first to be able to feed my SLM, since i will be limited to only the words that are saved, lets create a class that will use the functions, and will be easier to use"
      ],
      "metadata": {
        "id": "lkrcEpgngzMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class Small_Language_Model\n",
        "\n",
        "Lest join all the previous functions together and create a small language model object"
      ],
      "metadata": {
        "id": "gfl7rcwNhJWl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Small_Language_Model:\n",
        "  '''Class to predict the third word of a sentence (last one) '''\n",
        "\n",
        "  def __init__(self, name = 'model'):\n",
        "    '''Initialize attributes of the instance '''\n",
        "\n",
        "    self.name = name\n",
        "    self.dictionary_weight = {}\n",
        "\n",
        "  def __repr__(self):\n",
        "    '''print representation of model '''\n",
        "\n",
        "    return f\"{self.name} is a small languge model that holds {len(self.dictionary_weight.keys())} keys, feed the model more to have better predictions\"\n",
        "\n",
        "  def get_dict(self):\n",
        "    '''returns dictionary of weights '''\n",
        "\n",
        "    return self.dictionary_weight\n",
        "\n",
        "  #Functions to clean and parse the text\n",
        "\n",
        "  @staticmethod\n",
        "  def clean_text_from_file(file_name: str) -> list:\n",
        "    '''from a given file returns a list of strings with the texted parsed and cleaned '''\n",
        "\n",
        "    with open(file_name, 'r') as text: #open file given\n",
        "      #iterate through each word and strip to get clean word\n",
        "      return [word.strip(string.punctuation).lower()  for line in text for word in line.split() if word.strip(string.punctuation)]\n",
        "\n",
        "  @staticmethod\n",
        "  def clean_text(string_text: str) -> list:\n",
        "    '''Returns list of word cleaned '''\n",
        "\n",
        "    return [word.strip(string.punctuation).lower() for word in string_text.split() if word.strip(string.punctuation)]\n",
        "\n",
        "\n",
        "  #Functions to get trigrams and bigrams\n",
        "\n",
        "  @staticmethod\n",
        "  def get_bigram(list_word: list) -> list:\n",
        "    '''Return list of bigrams '''\n",
        "\n",
        "    return list(zip(list_word[:-1], list_word[1:]))\n",
        "\n",
        "  @staticmethod\n",
        "  def get_trigrams(list_word: list) -> list:\n",
        "    '''Returns list of trigrams '''\n",
        "\n",
        "    return list(zip(list_word[:-2], list_word[1:-1], list_word[2:]))\n",
        "\n",
        "\n",
        "  #function to merge the dictionaries\n",
        "\n",
        "  @staticmethod\n",
        "  def merge_dictionaries(old_dict: dict, new_dict: dict) -> dict:\n",
        "    '''Returns dictionary with updated values '''\n",
        "\n",
        "    all_keys = set(old_dict.keys() | new_dict.keys()) #we crate a set to get all the keys of both dicitionaries merging them\n",
        "    result = {}\n",
        "\n",
        "    for key in all_keys: #iterate thorugh they keys of both dictionaries\n",
        "      counter1 = Counter(old_dict.get(key, {})) #use Counter function to get attributes\n",
        "      counter2 = Counter(new_dict.get(key, {}))\n",
        "      result[key] = dict(counter1 + counter2) #add the attributes to a new dictionary form given key\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "  #Function to get the word frequency\n",
        "\n",
        "  @staticmethod\n",
        "  def word_frequency(trigrams:list) -> dict:\n",
        "    '''Returns a dictionary with updated frequency of words '''\n",
        "\n",
        "    new_dict = {}\n",
        "    for key1, key2, value in trigrams: #iterate trhough every element in the list of bigrams tuples\n",
        "      if (key1, key2) not in new_dict: new_dict[(key1, key2)] = {} #create a new key if the key doenst exist\n",
        "      if value not in new_dict[(key1, key2)]: new_dict[(key1, key2)][value] = 1 #give a value of 1 if the value doesnt exist\n",
        "      else: new_dict[(key1, key2)][value] += 1 #update the value once the word is found\n",
        "\n",
        "\n",
        "    return new_dict\n",
        "\n",
        "  def word_frequency_from_file(self, file_name: str):\n",
        "    '''Updates dictionary of frequencies from a given file '''\n",
        "\n",
        "    text = self.clean_text_from_file(file_name) #get the clean text as a list\n",
        "    trigrams = self.get_trigrams(text) #get bigrams form the zip function\n",
        "    frequency = self.word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "    self.dictionary_weight = self.merge_dictionaries(self.dictionary_weight, frequency) #returns the updated dictionary\n",
        "\n",
        "  def word_freqeuncy_from_text(self, given_string: str):\n",
        "    '''Updates dictionary of frequencies from a given text '''\n",
        "\n",
        "    new_list = self.clean_text(given_string)\n",
        "    trigrams = self.get_trigrams(new_list) #get bigrams form the zip function\n",
        "    frequency = self.word_frequency(trigrams) #get a new dictioanry of frequencies\n",
        "    self.dictionary_weight = self.merge_dictionaries(self.dictionary_weight, frequency) #returns the updated dictionary\n",
        "\n",
        "\n",
        "  #Function of possible outcomes\n",
        "\n",
        "\n",
        "  def get_all_possible_words(self, bigram: tuple) -> list:\n",
        "    '''Returns all possible word based on bigram '''\n",
        "\n",
        "    return list(self.dictionary_weight[bigram].keys())\n",
        "\n",
        "\n",
        "  #Probability functions\n",
        "\n",
        "  @staticmethod\n",
        "  def get_probability(num_appearance: int, total_weight: int) -> int:\n",
        "    '''Returns probability of the word to appear '''\n",
        "    return num_appearance / total_weight\n",
        "\n",
        "  def get_total_weight(self, key: tuple) -> int:\n",
        "    '''return total weight for given key '''\n",
        "\n",
        "    return sum((value for value in self.dictionary_weight[key].values()))\n",
        "\n",
        "  def get_weighted_words(self, key: tuple) -> list:\n",
        "    '''Returns a list of tuple word, dictionary '''\n",
        "\n",
        "    total_weight = self.get_total_weight(key) #get total sum of the weight\n",
        "\n",
        "    #generator expression to get a list of tuples that will hold the word and the total weight\n",
        "    return list(((word, self.get_probability(weight, total_weight)) for word, weight in self.dictionary_weight[key].items() ))\n",
        "\n",
        "\n",
        "  #Functions to predict the third word\n",
        "\n",
        "\n",
        "  def input_to_prediction(self, key: tuple) -> str:\n",
        "    '''Returns string for given probability '''\n",
        "\n",
        "    if key not in self.dictionary_weight: return None #handle case where input is not valid\n",
        "    words, probability = zip(*self.get_weighted_words(key)) # unoack the values with * given each index to each variable\n",
        "    return str(np.random.default_rng().choice(words, p = probability))\n",
        "\n",
        "  def predict_word(self, input: str) -> str:\n",
        "    '''get input and return prediction '''\n",
        "\n",
        "    input_clean = self.clean_text(input)\n",
        "    if len(input_clean) <= 1: return None #handle case where not enough information is given\n",
        "    bigram = self.get_bigram(input_clean)[-1] #in case the user gives more than two words only get the last two from the input\n",
        "\n",
        "    return self.input_to_prediction( bigram)\n"
      ],
      "metadata": {
        "id": "stoDPgfzmps0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#unit testing\n",
        "\n",
        "chatgpt = Small_Language_Model('Guerra')\n",
        "#Remember to add this files to the notebook in order to run the following code\n",
        "files = [\n",
        "    'feeding_and_evaluating_models.txt',\n",
        "    'neural_network_fundamentals.txt',\n",
        "    'probability_and_statistics.txt',\n",
        "    'text_preprocessing_nlp.txt',\n",
        "    'training_language_models.txt',\n",
        "    'the_model_who_learned_to_speak.txt',\n",
        "    'hello_how_the_team_spoke.txt'\n",
        "    ]\n",
        "\n",
        "for _ in files:\n",
        "  chatgpt.word_frequency_from_file(_)\n",
        "\n",
        "print(chatgpt)\n",
        "print(chatgpt.predict_word('santiago hello how'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8X6K4gaVqHQI",
        "outputId": "59bcd68f-26f6-4b3b-a758-34da1991af70"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Guerra is a small languge model that holds 7325 keys, feed the model more to have better predictions\n",
            "did\n"
          ]
        }
      ]
    }
  ]
}